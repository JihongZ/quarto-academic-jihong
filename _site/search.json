[
  {
    "objectID": "posts/2017-11-11-lognormal-simulation/index.html",
    "href": "posts/2017-11-11-lognormal-simulation/index.html",
    "title": "Simulation of Lognormal distribution",
    "section": "",
    "text": "This post is a try about how yo simulate lognormal distribution in R. Lognormal distribution is used a lot in cumulative data (e.x. counting), which is very similar with normal distribution except x should be larger than 0. For instance, the number of schools, the number of students. But I always have no idea about how to parameterized this distribution. I’ll update this post as I learn more about lognormal distribution…"
  },
  {
    "objectID": "posts/2017-11-11-lognormal-simulation/index.html#simulate-lognomal-distibution",
    "href": "posts/2017-11-11-lognormal-simulation/index.html#simulate-lognomal-distibution",
    "title": "Simulation of Lognormal distribution",
    "section": "Simulate lognomal distibution",
    "text": "Simulate lognomal distibution\n\nSimulation Study 1\nThis study is to simulate lognormal density distribution based on mean and sd of depedent variable (Y). My simulated mean of y is 891, and sd is 490, N (sample size) is 200000. Then use the formular below:\nmu  = log(m^2/phi) # log mean\nsigma = sqrt(log(1+v/m^2)) # log sd\nIt could calculate the log mean and log standard deviation for lognormal distribution.\nset.seed(20171108)\n\n#### Give Y mean and Y sd, simluate lognormal distribution data.\nm = 891 # geometric mean\nsd = 490 # geometric sd\nv = sd ^ 2\nphi = sqrt(v + m^2) \n\nmu    = log(m^2/phi) # log mean\nsigma = sqrt(log(1+v/m^2)) # log sd\n  \n\ny <- rlnorm(n = 200000, mu, sigma) %>% round(0)\nm.sim <- mean(y) # should be close to 891\nsd.sim <- sd(y) # should be close to 490\n\nrow1 <- c(m, mu,m.sim)\nrow2 <- c(sd, sigma,sd.sim)\ntable <- rbind(row1, row2)\ncolnames(table) <- c(\"Original\", \"Log\", \"Simulated\")\nrownames(table)  <- c(\"Mean\", \"SD\")\nkable(table) \nThis is the original, log and simulated mean and sd. It could be easily found that simulated ones are very closed to original.\n\n\n\n\nOriginal\nLog\nSimulated\n\n\n\n\nMean\n891\n6.660225\n891.1468\n\n\nSD\n490\n0.514041\n490.4396\n\n\n\nplot(density(y))\nFrom the density plot below, we can see the mean of X is also close to 891."
  },
  {
    "objectID": "posts/2019-01-10-visuliaztion-of-item-information-curves-in-r/index.html",
    "href": "posts/2019-01-10-visuliaztion-of-item-information-curves-in-r/index.html",
    "title": "Visuliaztion of Item Information Curves In R",
    "section": "",
    "text": "This blog is to show a new way to display item information curves using ggridges package. The ridge plot could show the IIF plots very clear when you have a large number of items.\n\nggplot(item_information_all %>% filter(item %in% 17:22)) +\n  aes(x = factor, y = item, height = info, \n      group = item, color = as.factor(item), \n      fill = as.factor(item)) +\n  ggridges::geom_ridgeline(alpha = 0.75) +\n  ggtitle(\"Peer Social Capital: Information Functions\")  +\n  theme_ridges()"
  },
  {
    "objectID": "posts/2019–11-21-rethink-statistical-model/2019–11-21-rethink-statistical-model.html",
    "href": "posts/2019–11-21-rethink-statistical-model/2019–11-21-rethink-statistical-model.html",
    "title": "Some Thoughts After Reading ",
    "section": "",
    "text": "It is a long history to use statistical models to figure out what is true? What is false? People found that comparing to prove what is true, prove what is false or falsifying the hypothesis (falsification) is more straightforward. This is because even thought you found thousands of millions of cases that the hypothesis is true (“Swans are white”), it does not guarantee this hypothesis is true. However, only one case that the hypothesis is not true (“A Swan is black”) is needed to prove it wrong. Thus, scientists seek to propose a hypothesis and then falsify it.\nAnother problem related to the falsification is that hypothesis is not model. That is to say, a NULL hypothesis could have several possible process models. These process models may or may not correspond to several statistical models. If we find a statistical model that match the samples. It only indicates it could be come from several process models. These process models may or may not come from the NULL hypothesis. As the author said:\n\nAny given statistical model (M) may correspond to more than one process model (P).\nAny given hypothesis (H) may correspond to more than one process model (P).\nAny given statistical model (M) may correspond to more than one hypothesis (H).\n\nThe traditional approach is to take the “neutral” model as a null hypothesis (“Item Response is not correlated among each other”), if the data (alternative model) are not sufficiently similar to the expectation under the null (NULL model), then we say that we “reject” the null hypothesis. Another explanation is we only have one model based NULL hypothesis but we potentially have a large number of model based on non-NULL hypothesis. Some of these non-NULL hypothesis may have similar model with the one based on NULL hypothesis. If we do not think carefully, we may reject the non-NULL hypothesis rather than NULL hypothesis.\nWhat can be done? The author try to encourage use to “search for a different description of the evidence, a description under which the processes look different.” For example, use different model fit indices in factor analysis instead of one because those model fit may depict different process models and different description of the evidence."
  },
  {
    "objectID": "posts/2018-02-11-Academic-Writing/index.html",
    "href": "posts/2018-02-11-Academic-Writing/index.html",
    "title": "Academic Writing",
    "section": "",
    "text": "This post is aimed to remind myself how to write articles with Academic Writing Style. The original article is from http://libguides.usc.edu/writingguide/academicwriting."
  },
  {
    "objectID": "posts/2018-02-11-Academic-Writing/index.html#i.-the-big-picture",
    "href": "posts/2018-02-11-Academic-Writing/index.html#i.-the-big-picture",
    "title": "Academic Writing",
    "section": "I. The Big Picture",
    "text": "I. The Big Picture\nUnlike fiction or journalistic writing, the overall structure of academic writing is formal and logical. It must be cohesive and possess a logically organized flow of ideas; this means that the various parts are connected to form a unified whole. There should be narrative links between sentences and paragraphs so the readers is able to follow your argument and all sources are properly cited. The introduction should include a description of how the rest of the paper is organized."
  },
  {
    "objectID": "posts/2018-02-11-Academic-Writing/index.html#ii.-the-tone",
    "href": "posts/2018-02-11-Academic-Writing/index.html#ii.-the-tone",
    "title": "Academic Writing",
    "section": "II. The Tone",
    "text": "II. The Tone\nThe overall one refers to the attitude conveyed in a piece of writing. Throughout your paper, it is important that you present the arguments of others fairly and with an appropriate narrative tone. When presenting a position or argument that you disagree with, describe the argument accurately and without loaded or biased language (I have use “the researchers failed to…”). In academic writing, the author is expected to investigate the research problem from an authoritative point of view. You should, therefore, state the strengths of your arguments confidently, using language that is neutral, not confrontational or dismissive."
  },
  {
    "objectID": "posts/2018-02-11-Academic-Writing/index.html#iii.-diction措辞",
    "href": "posts/2018-02-11-Academic-Writing/index.html#iii.-diction措辞",
    "title": "Academic Writing",
    "section": "III. Diction（措辞）",
    "text": "III. Diction（措辞）\nDiction refers to the choice of words you use. Awareness of the words you use is important because words that have almost the same denotation can have very different connotations (字义相同，含义未必相同). This is particularly true in academic writing because words and terminology can evolve a nuanced meaning that describes a particular idea, concept, or phenomenon derived from the epistemological culture of that discipline. Therefore, use concrete words [not general] that convey a specific meaning. If this cannot be done without confusing the reader, then you need to explain what you mean within the context of how that word is used within a discipline."
  },
  {
    "objectID": "posts/2018-02-11-Academic-Writing/index.html#iv.-the-language",
    "href": "posts/2018-02-11-Academic-Writing/index.html#iv.-the-language",
    "title": "Academic Writing",
    "section": "IV. The language",
    "text": "IV. The language\nThe investigation of research problems in the social sciences is often complex and multi-dimensional. Therefore, it is important that you use unambiguous language. Well-structured paragraphs and clear topic sentences enable a reader to follow your line of thinking without difficulty. Your language should be concise, formal, and express precisely what you want it to mean. Avoid vague expressions that are not specific or precise enough for the reader to derive exact meaning [“they”, “we”, “people”, “the organization”, etc.], abbreviations like “i.e.” [“in other words”] or ‘e.g.’ [“for example”], and the use of unspecific determinate words [“super”, “very”, “incredible”]."
  },
  {
    "objectID": "posts/2018-02-11-Academic-Writing/index.html#v.-punctuation",
    "href": "posts/2018-02-11-Academic-Writing/index.html#v.-punctuation",
    "title": "Academic Writing",
    "section": "V. Punctuation",
    "text": "V. Punctuation"
  },
  {
    "objectID": "posts/2019-04-19-make-a-game-in-r/index.html",
    "href": "posts/2019-04-19-make-a-game-in-r/index.html",
    "title": "Make a Game in R",
    "section": "",
    "text": "Finally, I created the following shiny app:\n\nlibrary(nessy)\nlibrary(shinyjs)\n\njscode <- \"shinyjs.closeWindow = function() { window.close(); }\"\nui <- cartridge(\n  title = \"{Memorize the Names!}\",\n  subtitle = \"Do you have some names to memorize in few minutes? Try this game!\",\n  container_with_title(\n    title = \"Names you want to memorize (i.e. Jonathan, Lesa)\"\n  ),\n  container_with_title(\n    title = \"Add a Name\",\n    text_input(id = \"name1\", label = \"Name\", placeholder = \"Jonathan Templin\"),\n    text_input(id = \"key\", label = \"Keys\", placeholder = \"Iowa/DCM\"),\n    htmlOutput(\"namelist\"),\n    button_primary(id = \"add\", \"Add\")\n  ),\n  button_success(id = \"play\", \"Play the Game\"),\n  useShinyjs(),\n  extendShinyjs(text = jscode, functions = c(\"closeWindow\")),\n  button_error(id = \"close\", \"Close Window\"),\n  \n  # Game pages\n  uiOutput(\"gamepage\")\n)\n\n\nserver <- function(input, output, session) {\n  names <- reactiveValues(\n    oldnames = \"\",\n    allnames = NULL,\n    allkeys = NULL\n  )\n  \n  observeEvent(input$add, {\n    names$oldnames = paste(names$oldnames, \"<br>\", input$name1, \"  <==>  \", input$key)\n    names$allnames = c(names$allnames, input$name1)\n    names$allkeys = c(names$allkeys, input$key)\n    output$namelist <- renderText(names$oldnames)\n  })\n  \n  observeEvent(input$play, {\n    selectedkey <- sample(names$allkeys, 1)\n    selectedname <- names$allnames[names$allkeys == selectedkey]\n    output$gamepage <- renderUI({\n      container_with_title(\n        paste(\"Key:\", selectedkey),\n        text_input(id = \"guessname\", label = \"Guess a Name\", placeholder = \"Jonathan\")\n      )\n    })\n  })\n\n\n  observeEvent(input$close, {\n    js$closeWindow()\n    stopApp()\n  })\n  \n}\n\nshiny::shinyApp(ui, server)\n\nThe game is like this:"
  },
  {
    "objectID": "posts/2018-03-10-my-new-shiny-app-cut-score-consistency/2018-03-10-my-new-shiny-app-cut-score-consistency.html",
    "href": "posts/2018-03-10-my-new-shiny-app-cut-score-consistency/2018-03-10-my-new-shiny-app-cut-score-consistency.html",
    "title": "My New Shiny App Cut Score Consistency",
    "section": "",
    "text": "knitr::include_app(\"https://jihongz.shinyapps.io/Cutscore-1/\", height = 1200)"
  },
  {
    "objectID": "posts/2017-11-10-Linking_simulation/index.en.html",
    "href": "posts/2017-11-10-Linking_simulation/index.en.html",
    "title": "Simulation Study of Linking using mirt",
    "section": "",
    "text": "This simulation study is to show how to do IRT Linking Process using mirt R Package. The simulation data includes 2 forms - Form A and Form B. These 2 forms are simulated based on 2 groups of individual, one group has 0 mean trait, another has 0.25 mean trait. Both groups have same sd."
  },
  {
    "objectID": "posts/2017-11-10-Linking_simulation/index.en.html#look-at-the-data",
    "href": "posts/2017-11-10-Linking_simulation/index.en.html#look-at-the-data",
    "title": "Simulation Study of Linking using mirt",
    "section": "Look at the data",
    "text": "Look at the data\nFirst of all, have a look at the data\n\nlibrary(mirt)\nlibrary(tidyverse)\nlibrary(knitr)\n### Read in Raw data from Form A:\ndat <- read.csv(file=\"FormA.csv\")\nglimpse(dat)\n\nRows: 5,000\nColumns: 64\n$ X   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,…\n$ V1  <dbl> -0.79498, -0.05589, 0.62650, -1.26832, 0.74921, 1.00922, -0.19147,…\n$ V2  <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ V3  <int> 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, …\n$ V4  <int> 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, …\n$ V5  <int> 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, …\n$ V6  <int> 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, …\n$ V7  <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, …\n$ V8  <int> 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, …\n$ V9  <int> 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, …\n$ V10 <int> 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, …\n$ V11 <int> 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, …\n$ V12 <int> 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, …\n$ V13 <int> 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, …\n$ V14 <int> 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, …\n$ V15 <int> 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, …\n$ V16 <int> 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, …\n$ V17 <int> 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ V18 <int> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, …\n$ V19 <int> 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, …\n$ V20 <int> 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, …\n$ V21 <int> 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ V22 <int> 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ V23 <int> 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, …\n$ V24 <int> 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, …\n$ V25 <int> 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ V26 <int> 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, …\n$ V27 <int> 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, …\n$ V28 <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, …\n$ V29 <int> 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, …\n$ V30 <int> 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, …\n$ V31 <int> 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, …\n$ V32 <int> 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, …\n$ V33 <int> 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, …\n$ V34 <int> 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, …\n$ V35 <int> 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ V36 <int> 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ V37 <int> 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, …\n$ V38 <int> 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, …\n$ V39 <int> 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, …\n$ V40 <int> 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, …\n$ V41 <int> 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ V42 <int> 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ V43 <int> 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, …\n$ V44 <int> 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, …\n$ V45 <int> 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, …\n$ V46 <int> 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, …\n$ V47 <int> 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, …\n$ V48 <int> 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ V49 <int> 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, …\n$ V50 <int> 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, …\n$ V51 <int> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ V52 <int> 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, …\n$ V53 <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ V54 <int> 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ V55 <int> 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, …\n$ V56 <int> 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, …\n$ V57 <int> 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, …\n$ V58 <int> 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, …\n$ V59 <int> 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, …\n$ V60 <int> 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, …\n$ V61 <int> 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, …\n$ V62 <int> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, …\n$ V63 <int> 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, …"
  },
  {
    "objectID": "posts/2017-11-10-Linking_simulation/index.en.html#plot-the-density-of-true-theta-of-group-a",
    "href": "posts/2017-11-10-Linking_simulation/index.en.html#plot-the-density-of-true-theta-of-group-a",
    "title": "Simulation Study of Linking using mirt",
    "section": "Plot the density of true \\theta of Group A",
    "text": "Plot the density of true \\theta of Group A\nFrom the density function, mu_{\\theta} is 0, sd_{\\theta} is 1.\n\nplot(density(dat$V1), main = \"Group A True Trait Density\", \n     xlab=expression(theta) )"
  },
  {
    "objectID": "posts/2017-11-10-Linking_simulation/index.en.html#ctt-table",
    "href": "posts/2017-11-10-Linking_simulation/index.en.html#ctt-table",
    "title": "Simulation Study of Linking using mirt",
    "section": "CTT Table",
    "text": "CTT Table\nCTT table could provide a brief description of table. 2 key valables in the table is item difficulty (item.diff) calculated by item means P(y=1) and item discrimination (item.disc), which is item-total correlation.\nClean data\nBy cleaning, data has 60 items including 50 unique item (from item1 to item50) and 10 common items (from item51 to item60). The sample size is 5000.\n\ndat_cali <- dat %>% select(V3:V52, V54:V63)\ncolnames(dat_cali) <- paste0(\"item\",1:60)\nN <- nrow(dat_cali)\nn <- ncol(dat_cali)\n\nClassical Test Theory\nThen calculate the CTT table for Form A. The item discrimination and difficulty could be compared between Form A and Form B. Because the relationship between trait and total score is non-linear, so there is effect of shrinkage.\n\n# item stats\n## item discrimnation\nitem.disc <- apply(dat_cali, 2, function(x) cor(x, rowSums(dat_cali, na.rm = TRUE)))\n\n## item difficulty\nitem.diff <- colMeans(dat_cali)\n\n## item response frequency\nitem.freq <- reduce(lapply(dat_cali, table), bind_rows)\n\nCTT <- cbind(item.disc, item.diff, item.freq)\n\nkable(CTT, digits = 3, caption = \"CTT Table for Form A\")\n\n\nCTT Table for Form A\n\n\nitem.disc\nitem.diff\n0\n1\n\n\n\nitem1\n0.365\n0.761\n1197\n3803\n\n\nitem2\n0.464\n0.833\n835\n4165\n\n\nitem3\n0.457\n0.539\n2305\n2695\n\n\nitem4\n0.471\n0.524\n2380\n2620\n\n\nitem5\n0.385\n0.221\n3893\n1107\n\n\nitem6\n0.400\n0.563\n2183\n2817\n\n\nitem7\n0.261\n0.457\n2717\n2283\n\n\nitem8\n0.264\n0.365\n3176\n1824\n\n\nitem9\n0.331\n0.560\n2198\n2802\n\n\nitem10\n0.505\n0.431\n2843\n2157\n\n\nitem11\n0.306\n0.354\n3228\n1772\n\n\nitem12\n0.528\n0.560\n2199\n2801\n\n\nitem13\n0.362\n0.550\n2251\n2749\n\n\nitem14\n0.427\n0.761\n1196\n3804\n\n\nitem15\n0.433\n0.241\n3793\n1207\n\n\nitem16\n0.377\n0.458\n2710\n2290\n\n\nitem17\n0.524\n0.545\n2275\n2725\n\n\nitem18\n0.351\n0.578\n2112\n2888\n\n\nitem19\n0.429\n0.509\n2455\n2545\n\n\nitem20\n0.330\n0.307\n3465\n1535\n\n\nitem21\n0.399\n0.403\n2984\n2016\n\n\nitem22\n0.418\n0.609\n1957\n3043\n\n\nitem23\n0.356\n0.354\n3232\n1768\n\n\nitem24\n0.460\n0.670\n1651\n3349\n\n\nitem25\n0.388\n0.507\n2465\n2535\n\n\nitem26\n0.209\n0.310\n3451\n1549\n\n\nitem27\n0.242\n0.476\n2618\n2382\n\n\nitem28\n0.495\n0.502\n2492\n2508\n\n\nitem29\n0.441\n0.481\n2593\n2407\n\n\nitem30\n0.450\n0.731\n1344\n3656\n\n\nitem31\n0.601\n0.399\n3006\n1994\n\n\nitem32\n0.396\n0.682\n1588\n3412\n\n\nitem33\n0.584\n0.613\n1933\n3067\n\n\nitem34\n0.489\n0.557\n2216\n2784\n\n\nitem35\n0.467\n0.759\n1203\n3797\n\n\nitem36\n0.312\n0.367\n3166\n1834\n\n\nitem37\n0.410\n0.778\n1109\n3891\n\n\nitem38\n0.443\n0.571\n2143\n2857\n\n\nitem39\n0.519\n0.755\n1224\n3776\n\n\nitem40\n0.280\n0.327\n3365\n1635\n\n\nitem41\n0.413\n0.582\n2088\n2912\n\n\nitem42\n0.338\n0.395\n3024\n1976\n\n\nitem43\n0.430\n0.634\n1830\n3170\n\n\nitem44\n0.348\n0.382\n3088\n1912\n\n\nitem45\n0.370\n0.530\n2351\n2649\n\n\nitem46\n0.286\n0.337\n3314\n1686\n\n\nitem47\n0.456\n0.403\n2985\n2015\n\n\nitem48\n0.340\n0.397\n3014\n1986\n\n\nitem49\n0.310\n0.291\n3544\n1456\n\n\nitem50\n0.435\n0.357\n3214\n1786\n\n\nitem51\n0.283\n0.821\n895\n4105\n\n\nitem52\n0.272\n0.324\n3382\n1618\n\n\nitem53\n0.474\n0.531\n2347\n2653\n\n\nitem54\n0.298\n0.336\n3318\n1682\n\n\nitem55\n0.427\n0.546\n2271\n2729\n\n\nitem56\n0.471\n0.667\n1667\n3333\n\n\nitem57\n0.410\n0.470\n2652\n2348\n\n\nitem58\n0.483\n0.433\n2834\n2166\n\n\nitem59\n0.363\n0.232\n3841\n1159\n\n\nitem60\n0.376\n0.666\n1670\n3330"
  },
  {
    "objectID": "posts/2017-11-10-Linking_simulation/index.en.html#final-calibration-of-form-a",
    "href": "posts/2017-11-10-Linking_simulation/index.en.html#final-calibration-of-form-a",
    "title": "Simulation Study of Linking using mirt",
    "section": "Final Calibration of Form A",
    "text": "Final Calibration of Form A\nModel Specification\n\nSPECS <- mirt.model('F = 1-60\n                    PRIOR = (1-60, a1, lnorm, 0, 1),\n                    (1-60,  d,  norm, 0, 1),\n                    (1-60,  g,  norm, -1.39,1)')\nmod_A3PL <- mirt(data=dat_cali, model=SPECS, itemtype='3PL')\nparms_a <- coef(mod_A3PL, simplify=TRUE, IRTpars = TRUE)$items\n\n\na_A <- parms_a[,1] \nb_A <- parms_a[,2] \nc_A <- parms_a[,3] \ntheta_A <- fscores(mod_A3PL,method=\"EAP\",\n                   full.scores=TRUE, full.scores.SE=TRUE,\n                   scores.only=TRUE)\n\nUsing 3-PL for irt model of form A. Extracting the cofficients (a, b, c) of IRT. The model-implied theta was outputed, whose mean is 0.1314938\nThe plot below suggest that SE is low when theta is close to mean, but low theta and high theta has large SE.\n\nplot(theta_A[,1],theta_A[,2])"
  },
  {
    "objectID": "posts/2017-11-10-Linking_simulation/index.en.html#final-calibration-of-form-a-1",
    "href": "posts/2017-11-10-Linking_simulation/index.en.html#final-calibration-of-form-a-1",
    "title": "Simulation Study of Linking using mirt",
    "section": "Final Calibration of Form A",
    "text": "Final Calibration of Form A\nModel Specification of B\n\nSPECS2 <- mirt.model('F = 1-60\n                    PRIOR = (1-60, a1, lnorm, 0, 1),\n                    (1-60,  d,  norm, 0, 1),\n                    (1-60,  g,  norm, -1.39,1)')\nmod_B3PL <- mirt(data=dat_cali2, model=SPECS, itemtype='3PL')\nparms_b <- coef(mod_B3PL, simplify=TRUE, IRTpars = TRUE)$items\n\n\na_B <- parms_b[,1] \nb_B <- parms_b[,2] \nc_B <- parms_b[,3] \ntheta_B <- fscores(mod_B3PL,method=\"EAP\",\n                   full.scores=TRUE, full.scores.SE=TRUE,\n                   scores.only=TRUE)\nhead(theta_B, 20) %>% kable(digits = 3, caption = \"Model-implied Theta of B\")\n\n\nModel-implied Theta of B\n\nF\nSE_F\n\n\n\n0.933\n0.214\n\n\n0.193\n0.220\n\n\n-0.783\n0.293\n\n\n0.865\n0.208\n\n\n-0.233\n0.261\n\n\n-0.217\n0.239\n\n\n0.890\n0.215\n\n\n1.369\n0.232\n\n\n-0.875\n0.306\n\n\n-0.411\n0.266\n\n\n1.091\n0.223\n\n\n-0.638\n0.261\n\n\n-1.253\n0.321\n\n\n-0.784\n0.261\n\n\n0.436\n0.228\n\n\n0.135\n0.211\n\n\n-1.841\n0.491\n\n\n-0.491\n0.259\n\n\n0.065\n0.225\n\n\n-0.339\n0.240"
  },
  {
    "objectID": "posts/2017-11-10-Linking_simulation/index.en.html#b-plot",
    "href": "posts/2017-11-10-Linking_simulation/index.en.html#b-plot",
    "title": "Simulation Study of Linking using mirt",
    "section": "b-plot",
    "text": "b-plot\nThe relationship between b parameters of A and B reflect the latent traits of A and B:\n\n\\theta_{A} = \\theta_{B} - 0.25 \\\\\n\\sigma_A^2 = \\sigma_B^2\n thus, b_B -b_A should also be -0.25. the estimated difference of b is calculate by the mean of b parametes of Form A’s common items and that of Form B’s common items, which is -0.2756443. Thus, it is very close to difference of true traits.\n\n### b-plot\nplot(b_A[51:60],b_B[51:60],\n     main=paste0(\"r =\", round(cor(b_A[51:60],b_B[51:60]),5)), \n     xlab = \"b_A\",\n     ylab = \"b_B\"\n     )\n\n\n\n# mean(b_B[51:60])-mean(b_A[51:60])"
  },
  {
    "objectID": "posts/2017-11-10-Linking_simulation/index.en.html#a-plot",
    "href": "posts/2017-11-10-Linking_simulation/index.en.html#a-plot",
    "title": "Simulation Study of Linking using mirt",
    "section": "a-plot",
    "text": "a-plot\nBecause \\theta_B - \\theta_A = 0.25, so a parametes are: \na_A / a_B = 1\n\nThe true ratio of (means of) a parameters is 1.016284, which is very close to 1. SD of A and B are both close to 1.\n\n### a-plot\nplot(a_A[51:60],a_B[51:60],\n     main=round(cor(a_A[51:60],a_B[51:60]),5)\n     )\n\n\n\n# mean(a_A[51:60]) / mean(a_B[51:60]) \n\n\n#SDs of b-values across forms\nSD_bA <- sd(b_A[51:60])\nSD_bB <- sd(b_B[51:60])\n\nMean_bA <- mean(b_A[51:60])\nMean_bB <- mean(b_B[51:60])"
  },
  {
    "objectID": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html",
    "href": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html",
    "title": "Introduction to Latent Attribute Network Analysis",
    "section": "",
    "text": "Network analysis is a very useful tool. This post show how to visualize the latent attribute network in Diagnostic Classification Modeling(DCM). There are a ton of R package could be used to visualize network structure."
  },
  {
    "objectID": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html#data-preparation",
    "href": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html#data-preparation",
    "title": "Introduction to Latent Attribute Network Analysis",
    "section": "Data Preparation",
    "text": "Data Preparation\nI will use a simulated hierachial data from CDM package. The node.list depicts the traget nodes and starting nodes. Those information could be extracted from the Q^{T}Q square matrix, in which Q is the Q matrix of the model.\nAs shown below, there are 6 latent attributes including A1, A2, A3, B1, C1, C2. The A attributes share common items and the C attributes share common items but B attribute does not share common items with other attributes. The numbers in each cell represents the number of items shared by the pair of attributes. The number of common items will be used for the weights of network edges.\n\ndata(\"data.cdm10\")\nq.matrix <- data.cdm10$q.matrix\nt(q.matrix) %*% q.matrix\n\n   A1 A2 A3 B1 C1 C2\nA1  6  4  2  0  0  0\nA2  4  4  2  0  0  0\nA3  2  2  2  0  0  0\nB1  0  0  0  3  0  0\nC1  0  0  0  0  6  3\nC2  0  0  0  0  3  3\n\n## prepare the edge and node table based on t(Q)%*%Q\nedge.list = tibble(from = c(1,1,2,2,3,3,5,6), \n                   to = c(2,3,1,3,1,2,6,5), \n                   weight = c(4,2,4,2,2,2,3,3))\nnode.list = tibble(label = c(\"A1\", \"A2\", \"A3\", \"B1\", \"C1\", \"C2\")) %>% rowid_to_column(\"id\")"
  },
  {
    "objectID": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html#network-package",
    "href": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html#network-package",
    "title": "Introduction to Latent Attribute Network Analysis",
    "section": "\nNetwork package",
    "text": "Network package\n\n## Network package\nlibrary(network)\nroutes_work <- network(x = edge.list, vertex.attr = node.list, \n                       matrix.type = \"edgelist\", ignore.eval = FALSE)\nplot(routes_work, vertex.cex = 3, mode = \"circle\")"
  },
  {
    "objectID": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html#igraph-package",
    "href": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html#igraph-package",
    "title": "Introduction to Latent Attribute Network Analysis",
    "section": "\nigraph package",
    "text": "igraph package\n\n## igraph package \ndetach(package:network)\nrm(routes_work)\nlibrary(igraph)\nroutes_igraph <- graph_from_data_frame(d = edge.list, vertices = node.list, directed = TRUE)\nplot(routes_igraph, edge.arrow.size = 0.5, layout = layout_with_graphopt)"
  },
  {
    "objectID": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html#tidygraph-and-ggraph",
    "href": "posts/2019-10-20-introduction-to-latent-attribute-network-analysis/index.en.html#tidygraph-and-ggraph",
    "title": "Introduction to Latent Attribute Network Analysis",
    "section": "\ntidygraph and ggraph\n",
    "text": "tidygraph and ggraph\n\n\nlibrary(tidygraph)\nlibrary(ggraph)\nroutes_tidy <- tbl_graph(nodes = node.list, edges = edge.list, directed = FALSE)\n\n\nggraph(routes_tidy, layout = \"graphopt\") + \n  geom_node_point() +\n  geom_edge_link(aes(width = weight), alpha = 0.8) + \n  scale_edge_width(range = c(0.2, 2)) +\n  geom_node_text(aes(label = label), repel = TRUE) +\n  labs(edge_width = \"Number of Common Items\") +\n  theme_graph()\n\n\n\n\n\n### Linear Layout\nggraph(routes_tidy, layout = \"linear\") + \n  geom_edge_arc(aes(width = weight), alpha = 0.8) + \n  scale_edge_width(range = c(0.2, 2)) +\n  geom_node_text(aes(label = label)) +\n  labs(edge_width = \"Number of Common Items\") +\n  theme_graph()"
  },
  {
    "objectID": "posts/2022-04-29-power-analysis-for-sem/index.en.html",
    "href": "posts/2022-04-29-power-analysis-for-sem/index.en.html",
    "title": "Power Analysis for Structural Equation Modeling",
    "section": "",
    "text": "Wang and Rhemtulla (2021) argued that there’re two ways of determining sample size planning in SEM: (1) traditional rule of thumbs, (2) power analysis for SEM based on parameter effect size and model misspecification. To be more specific, two ways of determining sample size planning in SEM are:\n\nRules of thumbs based absolute minimum sample size: N = 100 or N = 200\nModel Complexities based relative sample size: N = 5-10 or N = 3-6 per estimated parameters\n\nThese two ways of determining minimum sample sizes may not agree with each other and have few theoretical or empirical research support. According to the objective of hypothesis test in SEM, there are two distinct kinds of power: (1) the power of detecting model misspecification, (2) and the power of determining specific effects within the model (i.e., whether one latent variable predicts another). In this tutorial, I called the former one global power and latter one local power since the global power analyzes the model-level effect size of misfit while the local power tests the effect size of a particular model parameter.\nGlobal Power\nAs mentioned above, global power is a test quantifying the degree of confidence of the hypothesis test of model misspecification. There are many fit indices for power analysis for model misspecification including:\n\nSatorra and Saris’s (1985) $\\chi^2$ likelihood-ratio test\nMacCallum et al.’s (1996) root-mean-square error of approximation (RMSEA) tests\n\nFor the first test, I recommend using WebPower, a free web tool, to calculate global power based on Chi-square likelihood-ratio test (LRT). The test examines the misspecification by comparing the user model to the null model with the hypothesis that the hypothesized model is same as the null model. Most of cases will reject the hypothesis. WebPower tests the global power of SEM based on chi-square likelihood ratio test.\n\n\n\n\nChi-square LR test\n\n\n\n\nInput the chi-square test with 480.82 and vary the sample size from N=1 to N=300, we found N = 5 is enough sample size for power up to 1. Thus, normally SEM based on Chi-square LRT to null model has very low bar for misspecification. In this case, perhaps doubling the sample size (N $\\times$ 2 = 261 $\\times$ 2 = 522) is a more reasonable rule of thumb of minimum sample size.\nLocal Power\nWang and Rhemtulla (2021) recommend a Monte Carlo simulation approach to calculate power for detecting a target effect in SEM and introduced pwrSEM, a Shiny web app to estimate the power of parameter in SEM.\nLet’s take one mixture Confirmatory factor analysis with known classes (time = 0, time = 1) for example. The goal is to estimate the power of time effects on five latent constructs with sample size (N = 256).\nThe model has been fitted to the data using lavaan package beforehand. After opening up the shiny app, we can copy and paste the model syntax from lavaan to the app. Then the model specification will be visualized as following:\n\n\n\n\nModel Specification\n\n\n\n\nWithin this example model, InR, IdR, IGR, IER, ER are five factors measured twice. Time is a indicator variable where time = 0 represents pre-test and time = 1 represents post-test.\nThe next step is to input the model syntax and corresponding parameter estimates generated by $lavaan$:\n\n\n\n\nParameter estimates by lavaan\n\n\n\n\nThen, check the effects needed to be examined. In this case, the five time effects on ER, IER, IGR, IdR, and InR.\nThe local powers of five time effects on latent factors are as:\n\n\n\n\nLocal Power with sample size 256\n\n\n\n\nWe can vary our sample size to test how many sample sizes required for the target power of LnR regressed on Time (for example, if the goal of regression coefficient is .9, we slowly increase the sample size from 300 to 500). I tried two sample size in this case:\n\n\n\n\n\nLocal power with N = 300\n\n\n\n\n\n\nLocal power with N = 500\n\n\n\n\n\nAs the figures shown, based on MCMC simulation, sample size N = 300 is expected to increase the power of time effect on InR (InR ~~ time) to value 0.81 while N = 500 will increase the power to value 0.9, which is enough power for single regression coefficient effect. However, with such moderately large sample size, other time effects on ER, IRT, IGR, IdR (i.e., ER ~~ time) still stay at a low level because of the lower estimated effect size.\nThus, from this experiment, we can conclude that to make the power of time effect on latent variable InR up to 0.9, at lease around 300~500 samples are required.\nConclusion\nTo summarize, in this post, I illustrated two types of power: (1) local power (2) global power, and how they can be calculated using pwrSEM and WebPower correspondingly. It should be noted that, they are not the only software in the market. Another newly published software is semPower R package (see Jobst, Bader, and Moshagen 2021 for details), which can also be used to provide local power based on RMSEA.\nLocal power determines the minimum sample sizes for one specific effect in SEM. Global power determines the minimum sample sizes needed for testing model misspecification. Global power will give rise to different results depending on the model misfit indices chosen. As for local power, it is important to decide on which effect needed to be examined in the model.\nDiscussion\nThere are few guidelines about how and what to report local power and global power in SEM literature. Global power seems a common thing to report for all SEM paper since all SEM research need to deal with model misspecification before drawing any conclusion. Local power, on the other hand, is necessary when one effect within SEM model is of most interest and core of the study. Some may argue that power in SEM is not important as long as the model fit of SEM is acceptable. However, the acceptance of model-data fit cannot guarantee that the sample size meet the requirement of detecting specific effect. In other words, there may be some sort of false positive rate when reporting significance test in small sample setting. More research needed to investigate the relationship between power and local misfit indices to understand this problem. Please let me know your thoughts in comments below.\n\n\n\n\nReference\n\nJobst, Lisa J., Martina Bader, and Morten Moshagen. 2021. “A Tutorial on Assessing Statistical Power and Determining Sample Size for Structural Equation Models.” Psychological Methods, No Pagination Specified–. https://doi.org/10.1037/met0000423.\n\n\nWang, Y. Andre, and Mijke Rhemtulla. 2021. “Power Analysis for Parameter Estimation in Structural Equation Modeling: A Discussion and Tutorial.” Advances in Methods and Practices in Psychological Science 4 (1): 2515245920918253. https://doi.org/10.1177/2515245920918253."
  },
  {
    "objectID": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html",
    "href": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html",
    "title": "[Workshop] Creating Academic Blog via R",
    "section": "",
    "text": "Michael Clark has a great workshop in his blog introducing distill package. I suggest readers check it out first."
  },
  {
    "objectID": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html#requirement",
    "href": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html#requirement",
    "title": "[Workshop] Creating Academic Blog via R",
    "section": "Requirement",
    "text": "Requirement\nFollowing software is necessary to replicate the steps in this post:\n\nGithub account\nRstudio and R\n\ndistill R package\n\nTo get started with Github, please refer to the official website. To install distill package, run install.packages(\"distill\") in your R console."
  },
  {
    "objectID": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html#procedure",
    "href": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html#procedure",
    "title": "[Workshop] Creating Academic Blog via R",
    "section": "Procedure",
    "text": "Procedure\nTo create a website with the URL <username.github.io>, create the directory name with same name and same Github repo name. For example, my github repo name is “jihongz.github.io”, and it is published in http://jihongz.github.io.\n\n\n\n\nFlowchart for creating website\n\n\n\n\nTo have your personal website, you need to have all require files for the website. The basic files for Github Pages based website with distill includes:\n\n_site.yml\nindex.Rmd\n.nojekyll\n_posts\n\n\n\nExample of file structure used in my github website"
  },
  {
    "objectID": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html#new-post",
    "href": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html#new-post",
    "title": "[Workshop] Creating Academic Blog via R",
    "section": "New Post",
    "text": "New Post\nTo create a new post, use distill::create_post() function with the name of the post. The function will create a new directory “2022-XX-XX-post-name” in the _posts folder in which there exists a Rmd file with same name. The Rmd file will be your content of the new post.\n\ndistill::create_post(title = \"Tutorial of creating personal blog using distill package and Github Pages\")\n\n\n\nFiles in your post folder\n\n\nOpen the Rmd file and make sure the header of your Rmd file is like this:\n---\ntitle: \"[Tutorial] Creating Academic Blog\"\ndescription: |\n  This post reviews the procedure of creating Github Pages Website  using distill package and Github Pages in a step-to-step way.\nauthor:\n  - name: Zhang Jihong\n    url: {}\ndate: 2022-04-24\noutput:\n  distill::distill_article:\n    self_contained: false\n---\nAfter editting the Rmd file, knit the fill and then build website using Build Website button in the Build pane of Rstudio.\n\n\nThe Build button in Rstudio\n\n\nIt will then pop up your updated website in a window.\n\n\nPreview of updated website\n\n\nHowever, the website is not published yet. To publish the website, upload the files to Github. Following is a example of pushing the local files to the Github server via command line.\n\ngit add *\ngit commit -m \"create a new post\"\ngit push\n\nSettings of Github Repo\nGo to the Github Repo > Settings > Pages\n\n\nGithub Settings\n\n\nIn the webpage, choose _docs and you will see your website is published.\n\n\nchange settings"
  },
  {
    "objectID": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html#reference",
    "href": "posts/2022-04-24-tutorial-of-creating-personal-blog-using-distill-package-and-github-pages/index.en.html#reference",
    "title": "[Workshop] Creating Academic Blog via R",
    "section": "Reference",
    "text": "Reference\nLearn more about using Distill at https://rstudio.github.io/distill."
  },
  {
    "objectID": "posts/2019-02-19-Lasso-Regression-With-glmnet/index.en.html",
    "href": "posts/2019-02-19-Lasso-Regression-With-glmnet/index.en.html",
    "title": "Lasso Regression Example using glmnet package in R",
    "section": "",
    "text": "More details please refer to the link below: (https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html#lin)\nThis post shows how to use glmnet package to fit lasso regression and how to visualize the output. The description of data is shown in here."
  },
  {
    "objectID": "posts/2019-02-19-Lasso-Regression-With-glmnet/index.en.html#visualize-the-coefficients",
    "href": "posts/2019-02-19-Lasso-Regression-With-glmnet/index.en.html#visualize-the-coefficients",
    "title": "Lasso Regression Example using glmnet package in R",
    "section": "Visualize the coefficients",
    "text": "Visualize the coefficients\n\nplot(fit)\n\n\n\n\nLabel the path\n\nplot(fit, label = TRUE)\n\n\n\n\nThe summary table below shows from left to right the number of nonzero coefficients (DF), the percent (of null) deviance explained (%dev) and the value of \\lambda (Lambda).\nWe can get the actual coefficients at a specific \\lambda whin the range of sequence:\n\ncoeffs <- coef(fit, s = 0.1) \ncoeffs.dt <- data.frame(name = coeffs@Dimnames[[1]][coeffs@i + 1], coefficient = coeffs@x) \n\n# reorder the variables in term of coefficients\ncoeffs.dt[order(coeffs.dt$coefficient, decreasing = T),]\n\n          name   coefficient\n1  (Intercept)  3.010501e+00\n7          hfa  4.634502e-01\n12         aro  2.139111e-01\n9          inc  1.298769e-01\n6       convul  9.284738e-02\n16         whz  9.018865e-02\n14         afe  8.749033e-02\n10         lcw  7.538421e-02\n15        absu  5.758727e-02\n13         qcr  2.952464e-02\n11         str  2.298848e-02\n3         temp  9.842032e-03\n5           rr  7.309241e-03\n8          hfe  4.870858e-03\n2         wght -3.138053e-05\n4          age -8.724823e-03\n\n\nAlso, it can allow people to make predictions at specific \\lambda with new input data:\n\nnx = matrix(rnorm(nrow(dt$X)*ncol(dt$X)), nrow = nrow(dt$X), ncol = ncol(dt$X))\npred <- predict(fit, newx = nx, s = c(0.1, 0.05)) \nhead(pred, 20)\n\n            s1         s2\n [1,] 3.097967  1.1490660\n [2,] 3.121528  1.8672064\n [3,] 3.481338  2.0824025\n [4,] 3.513677  1.9860360\n [5,] 3.214442  1.7452629\n [6,] 2.490538  0.6267712\n [7,] 2.469592  0.9068895\n [8,] 2.720040  1.2436652\n [9,] 3.849610  1.9736908\n[10,] 3.033293  1.1007648\n[11,] 2.842930  1.0094204\n[12,] 3.027152  1.5992459\n[13,] 3.094639  0.7926862\n[14,] 2.082463 -1.1104287\n[15,] 3.612934  1.1337165\n[16,] 3.122380  1.8367326\n[17,] 2.133454  1.5344259\n[18,] 3.207939  0.4061563\n[19,] 3.138387  1.1810681\n[20,] 2.241477 -0.6124045\n\n\ncv.glmnet is the function to do cross-validation here.\n\nX <- dt$X\ny <- dt$y\ncv.fit <- cv.glmnet(X, y)\n\nPlotting the object gives the selected \\lambda and corresponding Mean-Square Error.\n\nplot(cv.fit)\n\n\n\n\nWe can view the selected \\lambda’s and the corresponding coefficients, For example,\n\ncv.fit$lambda.min\n\n[1] 0.02751064\n\ncv.fit$lambda.1se\n\n[1] 0.08401352\n\n\nlambda.min returns the value of \\lambda that gives minimum mean cross-validated error. The other \\lambda saved is lambda.lse, which gives the most regularized model such that error is within one standard error of the minimum. To use that, we only need to replace lambda.min with lambda.lse above.\n\n# create a function to transform coefficient of glmnet and cvglmnet to data.frame\ncoeff2dt <- function(fitobject, s) {\n  coeffs <- coef(fitobject, s) \n  coeffs.dt <- data.frame(name = coeffs@Dimnames[[1]][coeffs@i + 1], coefficient = coeffs@x) \n\n  # reorder the variables in term of coefficients\n  return(coeffs.dt[order(coeffs.dt$coefficient, decreasing = T),])\n}\n\ncoeff2dt(fitobject = cv.fit, s = \"lambda.min\") %>% head(20)\n\n          name coefficient\n19         str 0.624028697\n30         whz 0.552566043\n10         hfa 0.520301406\n9       convul 0.367161468\n24         aro 0.305231265\n32      puskin 0.246791663\n12         fde 0.204677903\n26         afe 0.162886449\n16         inc 0.142234777\n34         oab 0.132001767\n1  (Intercept) 0.126502256\n11         hfe 0.109667313\n4         temp 0.084079719\n18         lcw 0.075124732\n31        smi2 0.051082663\n25         qcr 0.048926715\n17         sr1 0.019747399\n28         crs 0.014597356\n20         gru 0.008735240\n7           rr 0.007203584\n\n\n\ncoeffs.table <- coeff2dt(fitobject = cv.fit, s = \"lambda.min\")\nggplot(data = coeffs.table) +\n  geom_col(aes(x = name, y = coefficient, fill = {coefficient > 0})) +\n  xlab(label = \"\") +\n  ggtitle(expression(paste(\"Lasso Coefficients with \", lambda, \" = 0.0275\"))) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")"
  },
  {
    "objectID": "posts/2019-02-19-Lasso-Regression-With-glmnet/index.en.html#elastic-net",
    "href": "posts/2019-02-19-Lasso-Regression-With-glmnet/index.en.html#elastic-net",
    "title": "Lasso Regression Example using glmnet package in R",
    "section": "Elastic net",
    "text": "Elastic net\nAs an example, we can set \\alpha=0.2\n\nfit2 <- glmnet(X, y, alpha = 0.2, weights = c(rep(1, 716), rep(2, 100)), nlambda = 20)\n\nprint(fit2, digits = 3)\n\n\nCall:  glmnet(x = X, y = y, weights = c(rep(1, 716), rep(2, 100)), alpha = 0.2,      nlambda = 20) \n\n   Df  %Dev Lambda\n1   0  0.00 3.2500\n2   7 14.02 2.0000\n3  12 26.98 1.2300\n4  13 33.81 0.7590\n5  18 38.03 0.4670\n6  23 41.35 0.2880\n7  29 43.24 0.1770\n8  39 45.05 0.1090\n9  47 46.17 0.0672\n10 52 46.82 0.0414\n11 57 47.15 0.0255\n12 58 47.29 0.0157\n13 60 47.35 0.0097\n14 60 47.38 0.0060\n15 64 47.39 0.0037\n16 65 47.39 0.0023\n17 66 47.40 0.0014\n18 66 47.40 0.0009\n19 66 47.40 0.0005\n\n\nAccording to the default internal settings, the computations stop if either the fractional change in deviance down the path is less than 10^{-5} or the fraction of explained deviance reaches 0.999.\n\nplot(fit2, xvar = \"lambda\", label = TRUE)\n\n\n\n# plot against %deviance\nplot(fit2, xvar = \"dev\", label = TRUE)\n\n\n\n\n\npredict(fit2, newx = X[1:5, ], type = \"response\", s = 0.03)\n\n           s1\n[1,] 3.170055\n[2,] 4.869413\n[3,] 4.255960\n[4,] 5.018313\n[5,] 2.945014"
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html",
    "href": "posts/2017-11-08-sem-homework/index.html",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "",
    "text": "This is one of my homework in Structural Equation Modeling in Fall 2017. Dr. Templin provided a excelent example showing how to perform Confirmatory Factor Analysis (CFA) using Lavaan Package. I elaborated each step as following."
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html#background",
    "href": "posts/2017-11-08-sem-homework/index.html#background",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "0. Background",
    "text": "0. Background\nCFA on Attitude towards Inclusive Education Survey (N = 507)\nThe affective dimension of attitudes subscale includes 6 items on a 6-point likert scale (1 = Strongly Agree, 6 = Strongly Disagree), measuring teachers’ feelings and emotions associated with inclusive education:\n\nI get frustrated when I have difficulty communicating with students with a disability.\nI get upset when students with a disability cannot keep up with the day-to-day curriculum in my classroom.\nI get irritated when I am unable to understand students with a disability.\nI am uncomfortable including students with a disability in a regular classroom with other students without a disability.\nI am disconcerted that students with a disability are included in the regular classroom, regardless of the severity of the disability.\nI get frustrated when I have to adapt the curriculum to meet the individual needs of all students.\n\nThe sample size (N) is 507, which includes 6 males and 501 females. I used one-factor model as first step. All items are loaded on one general factor - affective attitude towards inclusive education. Higher response score means more positive attitude towards inclusive education.\n\ndat <- read.csv(\"AttitudeForInclusiveEducation.csv\")\n# head(dat)\ndat2 <- dat %>% select(X,Aff.1:Aff.6)\ncolnames(dat2) <- c(\"PersonID\", paste0(\"Aff\",1:6))"
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html#descriptive-statistics",
    "href": "posts/2017-11-08-sem-homework/index.html#descriptive-statistics",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "1. Descriptive Statistics",
    "text": "1. Descriptive Statistics\nThe descriptive statistics for all items are provided below. It appears that item 4 is the least difficult item as it has the highest mean (\\mu = 4.189, sd = 1.317); item 5 is the most difficult item as it has lowest mean score (\\mu = 3.604, sd = 1.423). All responses for each item range from 1 to 6 (1 = Strongly agree, 6 = Strongly disagree). Thus, all categories are responded. In term of item discrimination, as item 3 has the largest standard deviation (sd = 1.364) and item 6 has the smallest, item 3 has highest discrimination whearas item 6 has lowest in CTT.\n\n\n\n\n   \n    vars \n    n \n    mean \n    sd \n    median \n    trimmed \n    mad \n    min \n    max \n    range \n    skew \n    kurtosis \n    se \n  \n\n\n PersonID \n    1 \n    507 \n    254.000 \n    146.503 \n    254 \n    254.000 \n    188.290 \n    1 \n    507 \n    506 \n    0.000 \n    -1.207 \n    6.506 \n  \n\n Aff1 \n    2 \n    507 \n    3.765 \n    1.337 \n    4 \n    3.779 \n    1.483 \n    1 \n    6 \n    5 \n    -0.131 \n    -0.927 \n    0.059 \n  \n\n Aff2 \n    3 \n    507 \n    3.635 \n    1.335 \n    4 \n    3.636 \n    1.483 \n    1 \n    6 \n    5 \n    -0.026 \n    -0.963 \n    0.059 \n  \n\n Aff3 \n    4 \n    507 \n    3.493 \n    1.364 \n    3 \n    3.472 \n    1.483 \n    1 \n    6 \n    5 \n    0.124 \n    -0.969 \n    0.061 \n  \n\n Aff4 \n    5 \n    507 \n    4.189 \n    1.317 \n    4 \n    4.287 \n    1.483 \n    1 \n    6 \n    5 \n    -0.589 \n    -0.327 \n    0.058 \n  \n\n Aff5 \n    6 \n    507 \n    3.604 \n    1.423 \n    4 \n    3.590 \n    1.483 \n    1 \n    6 \n    5 \n    0.000 \n    -0.939 \n    0.063 \n  \n\n Aff6 \n    7 \n    507 \n    4.018 \n    1.313 \n    4 \n    4.061 \n    1.483 \n    1 \n    6 \n    5 \n    -0.356 \n    -0.733 \n    0.058 \n  \n\n\n\nItem-total correlation table was provided below. All item-total correlation coefficients are higher than 0.7, which suggests good internal consistence. Item 1 has lowest item-total correlation (r = 0.733, sd = 1.337).\n\n\n\nItem-total Correlation Table\n \n   \n    n \n    raw.r \n    std.r \n    r.cor \n    r.drop \n    mean \n    sd \n  \n\n\n Aff1 \n    507 \n    0.733 \n    0.735 \n    0.652 \n    0.611 \n    3.765 \n    1.337 \n  \n\n Aff2 \n    507 \n    0.835 \n    0.836 \n    0.806 \n    0.753 \n    3.635 \n    1.335 \n  \n\n Aff3 \n    507 \n    0.813 \n    0.812 \n    0.771 \n    0.718 \n    3.493 \n    1.364 \n  \n\n Aff4 \n    507 \n    0.789 \n    0.790 \n    0.742 \n    0.689 \n    4.189 \n    1.317 \n  \n\n Aff5 \n    507 \n    0.774 \n    0.769 \n    0.702 \n    0.658 \n    3.604 \n    1.423 \n  \n\n Aff6 \n    507 \n    0.836 \n    0.838 \n    0.805 \n    0.755 \n    4.018 \n    1.313 \n  \n\n\n\nSample Correlation Matrix\nAccording to Pearson Correlation Matrix below, we can see all items have fairly high pearson correlation coefficients ranging from 0.44 to 0.72. This provides the evidence of dimensionality. Item 2 and item 3 has highest correlation coefficient(r_{23} = 0.717). The lowest correlations lies between item 1 and item 4 as well as item 1 and item 5.\n\ncor(dat2[2:7]) %>% round(3) %>% kable(caption = \"Pearson Correlation Matrix\")\n\n\n\nPearson Correlation Matrix\n \n   \n    Aff1 \n    Aff2 \n    Aff3 \n    Aff4 \n    Aff5 \n    Aff6 \n  \n\n\n Aff1 \n    1.000 \n    0.590 \n    0.525 \n    0.448 \n    0.411 \n    0.538 \n  \n\n Aff2 \n    0.590 \n    1.000 \n    0.717 \n    0.534 \n    0.553 \n    0.602 \n  \n\n Aff3 \n    0.525 \n    0.717 \n    1.000 \n    0.505 \n    0.527 \n    0.608 \n  \n\n Aff4 \n    0.448 \n    0.534 \n    0.505 \n    1.000 \n    0.609 \n    0.682 \n  \n\n Aff5 \n    0.411 \n    0.553 \n    0.527 \n    0.609 \n    1.000 \n    0.577 \n  \n\n Aff6 \n    0.538 \n    0.602 \n    0.608 \n    0.682 \n    0.577 \n    1.000 \n  \n\n\n\n\nSample Mean and Variance\n\nmeans <- dat2[,2:7] %>% \n  summarise_all(funs(mean)) %>% round(3) %>% t() %>% as.data.frame()\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\nsds <- dat2[,2:7] %>% \n  summarise_all(funs(sd)) %>% round(3) %>% t() %>% as.data.frame()\ntable1 <- cbind(means,sds)\n\ncolnames(table1) <- c(\"Mean\", \"SD\")\ntable1\n\n      Mean    SD\nAff1 3.765 1.337\nAff2 3.635 1.335\nAff3 3.493 1.364\nAff4 4.189 1.317\nAff5 3.604 1.423\nAff6 4.018 1.313\n\n\nSample Item Response Distributions\nThose items did not exactly match normal distribution but acceptable.\n# stack data\ndat2_melted <- dat2 %>% gather(key, value,Aff1:Aff6) %>% arrange(PersonID)\n\n# plot by variable\nggplot(dat2_melted, aes(value)) + \n  geom_histogram(aes(y=..density..), colour=\"black\", fill=\"white\", binwidth = 1) +\n  geom_density(alpha=.2, fill=\"#FF6666\") +\n  scale_x_continuous(breaks = 1:6) +\n  facet_wrap(~ key)\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead."
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html#estimation-with-cfa",
    "href": "posts/2017-11-08-sem-homework/index.html#estimation-with-cfa",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "3. Estimation with CFA",
    "text": "3. Estimation with CFA\nOne-factor Model\nOne-factor model was conducted as first step. The model has one latent facor - affective attitude and six indicators. In general, one-factor model does not provide great model fit except SRMR. The test statistics for chi-square is 75.835 (p < 0.05). CFI is 0.929, which larger than 0.95 suggests good model fit. RMSEA is 0.121, which lower than 0.05 suggest good model fit. SRMR is 0.04, which lower than 0.08. The standardized factor loadings range from 0.66 to 0.8. All factor loadings are significant at the level of alpha equals 0.05.\n\nmodel1.syntax <- '\n  AA =~ Aff1 + Aff2 + Aff3 + Aff4 + Aff5 + Aff6\n'\nmodel1 <- cfa(model1.syntax, data = dat2,std.lv = TRUE, mimic = \"mplus\", estimator = \"MLR\")\nsummary(model1, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6.13 ended normally after 14 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations                           507\n  Number of missing patterns                         1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               115.410      75.834\n  Degrees of freedom                                 9           9\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.522\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1573.730     960.267\n  Degrees of freedom                                15          15\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.639\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.932       0.929\n  Tucker-Lewis Index (TLI)                       0.886       0.882\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.934\n  Robust Tucker-Lewis Index (TLI)                            0.891\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4492.146   -4492.146\n  Scaling correction factor                                  1.138\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -4434.440   -4434.440\n  Scaling correction factor                                  1.266\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                9020.291    9020.291\n  Bayesian (BIC)                              9096.404    9096.404\n  Sample-size adjusted Bayesian (SABIC)       9039.270    9039.270\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.153       0.121\n  90 Percent confidence interval - lower         0.129       0.101\n  90 Percent confidence interval - upper         0.178       0.142\n  P-value H_0: RMSEA <= 0.050                    0.000       0.000\n  P-value H_0: RMSEA >= 0.080                    1.000       1.000\n                                                                  \n  Robust RMSEA                                               0.149\n  90 Percent confidence interval - lower                     0.120\n  90 Percent confidence interval - upper                     0.181\n  P-value H_0: Robust RMSEA <= 0.050                         0.000\n  P-value H_0: Robust RMSEA >= 0.080                         1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.040       0.040\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  AA =~                                                                 \n    Aff1              0.886    0.055   16.183    0.000    0.886    0.663\n    Aff2              1.078    0.046   23.284    0.000    1.078    0.808\n    Aff3              1.066    0.055   19.499    0.000    1.066    0.783\n    Aff4              0.968    0.061   15.934    0.000    0.968    0.736\n    Aff5              1.004    0.055   18.291    0.000    1.004    0.706\n    Aff6              1.057    0.049   21.644    0.000    1.057    0.805\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Aff1              3.765    0.059   63.455    0.000    3.765    2.818\n   .Aff2              3.635    0.059   61.382    0.000    3.635    2.726\n   .Aff3              3.493    0.060   57.741    0.000    3.493    2.564\n   .Aff4              4.189    0.058   71.689    0.000    4.189    3.184\n   .Aff5              3.604    0.063   57.057    0.000    3.604    2.534\n   .Aff6              4.018    0.058   68.948    0.000    4.018    3.062\n    AA                0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Aff1              1.000    0.081   12.285    0.000    1.000    0.560\n   .Aff2              0.617    0.066    9.283    0.000    0.617    0.347\n   .Aff3              0.719    0.089    8.089    0.000    0.719    0.387\n   .Aff4              0.794    0.095    8.390    0.000    0.794    0.459\n   .Aff5              1.014    0.090   11.226    0.000    1.014    0.501\n   .Aff6              0.605    0.068    8.898    0.000    0.605    0.351\n    AA                1.000                               1.000    1.000\n\n\nLocal Misfit for One-factor Model\nBy looking into local misfit with residual variance-covariance matrix we can get the clues to improve the model. According to the model residuals, item 4 has relatively high positive residual covariance with item 5 and item 6. It suggests that the one-factor model underestimates the correlations among item 4, item 5 and item 6. In other words, another latent factor may be needed to explain the strong relations among item 4, 5, 6 which cannot be explained by a general Affective attitude factor.\nMoreover, modification indices below also suggest that adding the error covariances among item 4, 5 and 6 will improve chi-square much better.\nThus, I decided to add one more factor - AAE. AAE was labeled as affective attitude towards educational environment which indicated by item 4, 5, 6. The other latent factor - AAC which was indicated by item 1, 2, 3 was labeled as Affective Attitude towards communication.\n\nresid(model1)$cov %>% kable(caption = \"Normalized Residual Variance-Covariance Matrix\",digits = 3)\n\n\n\nNormalized Residual Variance-Covariance Matrix\n \n   \n    Aff1 \n    Aff2 \n    Aff3 \n    Aff4 \n    Aff5 \n    Aff6 \n  \n\n\n Aff1 \n    0.000 \n    0.095 \n    0.011 \n    -0.070 \n    -0.109 \n    0.006 \n  \n\n Aff2 \n    0.095 \n    0.000 \n    0.153 \n    -0.106 \n    -0.034 \n    -0.085 \n  \n\n Aff3 \n    0.011 \n    0.153 \n    0.000 \n    -0.128 \n    -0.051 \n    -0.041 \n  \n\n Aff4 \n    -0.070 \n    -0.106 \n    -0.128 \n    0.000 \n    0.168 \n    0.155 \n  \n\n Aff5 \n    -0.109 \n    -0.034 \n    -0.051 \n    0.168 \n    0.000 \n    0.015 \n  \n\n Aff6 \n    0.006 \n    -0.085 \n    -0.041 \n    0.155 \n    0.015 \n    0.000 \n  \n\n\n\nmodificationindices(model1, standardized = TRUE,sort. = TRUE) %>% slice(1:10) %>% kable(caption = \"Modification Indices\", digits = 3)\n\n\n\nModification Indices\n \n lhs \n    op \n    rhs \n    mi \n    epc \n    sepc.lv \n    sepc.all \n    sepc.nox \n  \n\n\n Aff2 \n    ~~ \n    Aff3 \n    55.906 \n    0.319 \n    0.319 \n    0.479 \n    0.479 \n  \n\n Aff4 \n    ~~ \n    Aff6 \n    45.674 \n    0.279 \n    0.279 \n    0.403 \n    0.403 \n  \n\n Aff4 \n    ~~ \n    Aff5 \n    25.673 \n    0.243 \n    0.243 \n    0.270 \n    0.270 \n  \n\n Aff3 \n    ~~ \n    Aff4 \n    24.228 \n    -0.214 \n    -0.214 \n    -0.283 \n    -0.283 \n  \n\n Aff2 \n    ~~ \n    Aff6 \n    22.494 \n    -0.194 \n    -0.194 \n    -0.318 \n    -0.318 \n  \n\n Aff2 \n    ~~ \n    Aff4 \n    21.303 \n    -0.193 \n    -0.193 \n    -0.276 \n    -0.276 \n  \n\n Aff1 \n    ~~ \n    Aff2 \n    11.974 \n    0.153 \n    0.153 \n    0.195 \n    0.195 \n  \n\n Aff1 \n    ~~ \n    Aff5 \n    7.918 \n    -0.145 \n    -0.145 \n    -0.144 \n    -0.144 \n  \n\n Aff1 \n    ~~ \n    Aff4 \n    4.309 \n    -0.096 \n    -0.096 \n    -0.108 \n    -0.108 \n  \n\n Aff3 \n    ~~ \n    Aff6 \n    4.018 \n    -0.084 \n    -0.084 \n    -0.128 \n    -0.128 \n  \n\n\n\n\nTwo-factor Model\nThe neccessity of adding another factor was tested by specifying a two-factor model.\nIn term of model fit indices, it appears that the global model fit indices are great with two-factor model (CFI = 0.986; RMSEA = 0.058; SRMR = 0.022). Ideally, two latent factors could be labeled as moderately correlated aspects of attitudes towards inclusive education. Thus, the first factor (AAC) could be labeled as how teachers feel about communicating with students with disability. The second (AAE) could be labeled as how teachers feel about evironment of inclusive education. All standardized factor loadings are statistically significant ranging from 0.676 to 0.865. The factor correlation between 2 factors is high (r = 0.838,p = 0.00).\n\nmodel2.syntax <- '\n  AAC =~ Aff1 + Aff2 + Aff3\n  AAE =~ Aff4 + Aff5 + Aff6\n'\nmodel2 <- cfa(model2.syntax, data = dat2, std.lv = TRUE, mimic = \"mplus\", estimator = \"MLR\")\nsummary(model2, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6.13 ended normally after 19 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        19\n\n  Number of observations                           507\n  Number of missing patterns                         1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                32.332      21.512\n  Degrees of freedom                                 8           8\n  P-value (Chi-square)                           0.000       0.006\n  Scaling correction factor                                  1.503\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1573.730     960.267\n  Degrees of freedom                                15          15\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.639\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.984       0.986\n  Tucker-Lewis Index (TLI)                       0.971       0.973\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.987\n  Robust Tucker-Lewis Index (TLI)                            0.975\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4450.606   -4450.606\n  Scaling correction factor                                  1.166\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -4434.440   -4434.440\n  Scaling correction factor                                  1.266\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                8939.212    8939.212\n  Bayesian (BIC)                              9019.554    9019.554\n  Sample-size adjusted Bayesian (SABIC)       8959.246    8959.246\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.077       0.058\n  90 Percent confidence interval - lower         0.051       0.034\n  90 Percent confidence interval - upper         0.106       0.082\n  P-value H_0: RMSEA <= 0.050                    0.046       0.268\n  P-value H_0: RMSEA >= 0.080                    0.475       0.068\n                                                                  \n  Robust RMSEA                                               0.071\n  90 Percent confidence interval - lower                     0.036\n  90 Percent confidence interval - upper                     0.108\n  P-value H_0: Robust RMSEA <= 0.050                         0.148\n  P-value H_0: Robust RMSEA >= 0.080                         0.375\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.022       0.022\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  AAC =~                                                                \n    Aff1              0.903    0.055   16.357    0.000    0.903    0.676\n    Aff2              1.153    0.042   27.771    0.000    1.153    0.865\n    Aff3              1.117    0.051   22.079    0.000    1.117    0.820\n  AAE =~                                                                \n    Aff4              1.047    0.053   19.604    0.000    1.047    0.796\n    Aff5              1.036    0.053   19.366    0.000    1.036    0.728\n    Aff6              1.107    0.044   25.112    0.000    1.107    0.844\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  AAC ~~                                                                \n    AAE               0.838    0.028   29.829    0.000    0.838    0.838\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Aff1              3.765    0.059   63.455    0.000    3.765    2.818\n   .Aff2              3.635    0.059   61.382    0.000    3.635    2.726\n   .Aff3              3.493    0.060   57.741    0.000    3.493    2.564\n   .Aff4              4.189    0.058   71.689    0.000    4.189    3.184\n   .Aff5              3.604    0.063   57.057    0.000    3.604    2.534\n   .Aff6              4.018    0.058   68.948    0.000    4.018    3.062\n    AAC               0.000                               0.000    0.000\n    AAE               0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Aff1              0.970    0.083   11.753    0.000    0.970    0.543\n   .Aff2              0.449    0.057    7.860    0.000    0.449    0.253\n   .Aff3              0.607    0.084    7.244    0.000    0.607    0.327\n   .Aff4              0.635    0.085    7.504    0.000    0.635    0.367\n   .Aff5              0.950    0.090   10.539    0.000    0.950    0.470\n   .Aff6              0.497    0.061    8.191    0.000    0.497    0.288\n    AAC               1.000                               1.000    1.000\n    AAE               1.000                               1.000    1.000\n\n\nLocal Misfit for two-factor model\nThe local misfit indices for two-factor model also suggest that the model fits data well. The largest normalized residuals is 1.215. Modification indices suggest that add covariance between item 5 and item 6. These local misfit is not theoretically defensible. Thus, the final model is two-factor model.\n\nresid(model2)$cov %>% kable(caption = \"Normalized Residual Variance-Covariance Matrix\",digits = 3)\n\n\n\nNormalized Residual Variance-Covariance Matrix\n \n   \n    Aff1 \n    Aff2 \n    Aff3 \n    Aff4 \n    Aff5 \n    Aff6 \n  \n\n\n Aff1 \n    0.000 \n    0.010 \n    -0.053 \n    -0.005 \n    -0.003 \n    0.105 \n  \n\n Aff2 \n    0.010 \n    0.000 \n    0.014 \n    -0.075 \n    0.048 \n    -0.016 \n  \n\n Aff3 \n    -0.053 \n    0.014 \n    0.000 \n    -0.076 \n    0.050 \n    0.049 \n  \n\n Aff4 \n    -0.005 \n    -0.075 \n    -0.076 \n    0.000 \n    0.056 \n    0.019 \n  \n\n Aff5 \n    -0.003 \n    0.048 \n    0.050 \n    0.056 \n    0.000 \n    -0.070 \n  \n\n Aff6 \n    0.105 \n    -0.016 \n    0.049 \n    0.019 \n    -0.070 \n    0.000 \n  \n\n\n\nmodificationindices(model2, standardized = TRUE,sort. = TRUE) %>% slice(1:10) %>% kable(caption = \"Modification Indices\", digits = 3)\n\n\n\nModification Indices\n \n lhs \n    op \n    rhs \n    mi \n    epc \n    sepc.lv \n    sepc.all \n    sepc.nox \n  \n\n\n Aff5 \n    ~~ \n    Aff6 \n    16.894 \n    -0.224 \n    -0.224 \n    -0.326 \n    -0.326 \n  \n\n AAC \n    =~ \n    Aff4 \n    16.893 \n    -0.578 \n    -0.578 \n    -0.439 \n    -0.439 \n  \n\n Aff1 \n    ~~ \n    Aff6 \n    7.064 \n    0.108 \n    0.108 \n    0.155 \n    0.155 \n  \n\n Aff4 \n    ~~ \n    Aff5 \n    5.977 \n    0.128 \n    0.128 \n    0.164 \n    0.164 \n  \n\n AAC \n    =~ \n    Aff6 \n    5.976 \n    0.368 \n    0.368 \n    0.280 \n    0.280 \n  \n\n Aff1 \n    ~~ \n    Aff3 \n    5.093 \n    -0.112 \n    -0.112 \n    -0.146 \n    -0.146 \n  \n\n AAE \n    =~ \n    Aff2 \n    5.093 \n    -0.362 \n    -0.362 \n    -0.272 \n    -0.272 \n  \n\n Aff3 \n    ~~ \n    Aff4 \n    4.045 \n    -0.077 \n    -0.077 \n    -0.124 \n    -0.124 \n  \n\n Aff2 \n    ~~ \n    Aff3 \n    3.160 \n    0.119 \n    0.119 \n    0.228 \n    0.228 \n  \n\n AAE \n    =~ \n    Aff1 \n    3.160 \n    0.236 \n    0.236 \n    0.176 \n    0.176"
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html#path-diagrams",
    "href": "posts/2017-11-08-sem-homework/index.html#path-diagrams",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "4. Path Diagrams",
    "text": "4. Path Diagrams\n#semPlot::semPaths(model2, what = \"est\")"
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html#reliability",
    "href": "posts/2017-11-08-sem-homework/index.html#reliability",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "5. Reliability",
    "text": "5. Reliability\nTo get the estimates of reliabilities, Omega coefficients were calculated for each factor(\\Omega_{AAC} = 0.832, p < 0.01; \\Omega_{AAE} = 0.830, p < 0.01).\n\nmodel03SyntaxOmega = \"\n  # AAC loadings (all estimated)\n  AAC =~ L1*Aff1 + L2*Aff2 + L3*Aff3\n  \n  # AAE loadings (all estimated)\n  AAE =~ L4*Aff4 + L5*Aff5 + L6*Aff6\n  \n  # Unique Variances:\n  Aff1 ~~ E1*Aff1; Aff2 ~~ E2*Aff2; Aff3 ~~ E3*Aff3; Aff4 ~~ E4*Aff4; Aff5 ~~ E5*Aff5; Aff6 ~~ E6*Aff6; \n  \n  \n  # Calculate Omega Reliability for Sum Scores:\n  OmegaAAC := ((L1 + L2 + L3)^2) / ( ((L1 + L2 + L3)^2) + E1 + E2 + E3)\n  OmegaAAE := ((L4 + L5 + L6)^2) / ( ((L4 + L5 + L6)^2) + E4 + E5 + E6)\n\"\n\nmodel03EstimatesOmega = sem(model = model03SyntaxOmega, data = dat2, estimator = \"MLR\", mimic = \"mplus\", std.lv = TRUE)\nsummary(model03EstimatesOmega, fit.measures = FALSE, rsquare = FALSE, standardized = FALSE, header = FALSE)\n\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  AAC =~                                              \n    Aff1      (L1)    0.903    0.055   16.357    0.000\n    Aff2      (L2)    1.153    0.042   27.771    0.000\n    Aff3      (L3)    1.117    0.051   22.079    0.000\n  AAE =~                                              \n    Aff4      (L4)    1.047    0.053   19.604    0.000\n    Aff5      (L5)    1.036    0.053   19.366    0.000\n    Aff6      (L6)    1.107    0.044   25.112    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  AAC ~~                                              \n    AAE               0.838    0.028   29.829    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .Aff1              3.765    0.059   63.455    0.000\n   .Aff2              3.635    0.059   61.382    0.000\n   .Aff3              3.493    0.060   57.741    0.000\n   .Aff4              4.189    0.058   71.689    0.000\n   .Aff5              3.604    0.063   57.057    0.000\n   .Aff6              4.018    0.058   68.948    0.000\n    AAC               0.000                           \n    AAE               0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .Aff1      (E1)    0.970    0.083   11.753    0.000\n   .Aff2      (E2)    0.449    0.057    7.860    0.000\n   .Aff3      (E3)    0.607    0.084    7.244    0.000\n   .Aff4      (E4)    0.635    0.085    7.504    0.000\n   .Aff5      (E5)    0.950    0.090   10.539    0.000\n   .Aff6      (E6)    0.497    0.061    8.191    0.000\n    AAC               1.000                           \n    AAE               1.000                           \n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    OmegaAAC          0.832    0.016   51.512    0.000\n    OmegaAAE          0.830    0.017   49.000    0.000"
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html#factor-scores-and-distributions",
    "href": "posts/2017-11-08-sem-homework/index.html#factor-scores-and-distributions",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "6. Factor Scores and Distributions",
    "text": "6. Factor Scores and Distributions\nThe AAC factor scores have an estimated mean of 0 with a variance of 0.88 due to the effect of the prior distribution. The SE for each person’s AAC factor score is 0.347; 95% confidence interval for AAC factor score is Score \\pm 2*0.347 = Score \\pm 0.694. The AAE factor scores have an estimated mean of 0 with a variance of 0.881 due to the effect of the prior distribution. The SE for each person’s AAC factor score is 0.357; 95% confidence interval for AAC factor score is Score \\pm 2*0.357 = Score \\pm 0.714.\nFactor Realiability for AAC is 0.892 and factor realibility for AAE is 0.887. Both factor reliability are larger than omega.\nThe resulting distribution of the EAP estimates of factor score as shown in Figure 1. Figure 2 shows the predicted response for each item as a linear function of the latent factor based on the estimated model parameters. As shown, for AAE factor, the predicted item response goes above the highest response option just before a latent factor score of 2 (i.e., 2 SDs above the mean), resulting in a ceiling effect for AAE factor, as also shown in Figure 1.\nThe extent to which the items within each factor could be seen as exchangeable was then examined via an additional set of nested model comparisons, as reported in Table 1 (for fit) and Table 2 (for comparisons of fit). Two-factor has better model fit than one-facor model. Moreover, according to chi-square difference test, two-factor is significantly better than one-factor in model fit.\n\n\n      AAC       AAE \n0.8925361 0.8867031"
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html#figures",
    "href": "posts/2017-11-08-sem-homework/index.html#figures",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "7. Figures",
    "text": "7. Figures\nFigure 1 : Factor Score Distribution\n\n\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\n\n\n\n\n\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\n\n\n\n\n\nFigure 2 : Expected Item Response Plots"
  },
  {
    "objectID": "posts/2017-11-08-sem-homework/index.html#tables",
    "href": "posts/2017-11-08-sem-homework/index.html#tables",
    "title": "How to use Lavaan for Confirmatory Factor Analysis",
    "section": "8. Tables",
    "text": "8. Tables\nTable 1: Model Fit Statistics Using MLR\n\n\n\n\n\n   \n    # Items \n    # Parameters \n    Scaled Chi-Square \n    Chi-Square Scale Factor \n    DF \n    p-value \n    CFI \n    RMSEA \n    RMSEA Lower \n    RMSEA Upper \n    RMSEA p-value \n  \n\n\n One-Factor \n    6 \n    18 \n    75.834 \n    1.522 \n    9 \n    0.000 \n    0.927 \n    0.9 \n    0.000 \n    0.05 \n    1.000 \n  \n\n Two-Factor \n    6 \n    19 \n    21.512 \n    1.503 \n    8 \n    0.006 \n    0.979 \n    0.9 \n    0.046 \n    0.05 \n    0.475 \n  \n\n\n\n\nTable 2: Model Comparisons\n\n\n\n\n\n   \n    Df \n    Chisq diff \n    Df diff \n    Pr(>Chisq) \n  \n\n One-Factor vs. Two-Factor \n    9 \n    49.652 \n    1 \n    0 \n  \n\n\n\nTable 3: Model Estimates\n\n\n\n\n\n\n\nUnstandardized\nStandardized\n\n\n   \n    Estimate \n    SE \n    Estimate \n  \n\n\nForgiveness Factor Loadings\n\n Item 1 \n    0.903 \n    0.055 \n    0.676 \n  \n\n Item 2 \n    1.153 \n    0.042 \n    0.865 \n  \n\n Item 3 \n    1.117 \n    0.051 \n    0.820 \n  \nNot Unforgiveness Factor Loadings\n\n Item 4 \n    1.047 \n    0.053 \n    0.796 \n  \n\n Item 5 \n    1.036 \n    0.053 \n    0.728 \n  \n\n Item 6 \n    1.107 \n    0.044 \n    0.844 \n  \nFactor Covariance\n\n Factor Covariance \n    0.838 \n    0.028 \n    0.838 \n  \nItem Intercepts\n\n Item 1 \n    3.765 \n    0.059 \n    2.818 \n  \n\n Item 2 \n    3.635 \n    0.059 \n    2.726 \n  \n\n Item 3 \n    3.493 \n    0.060 \n    2.564 \n  \n\n Item 4 \n    4.189 \n    0.058 \n    3.184 \n  \n\n Item 5 \n    3.604 \n    0.063 \n    2.534 \n  \n\n Item 6 \n    4.018 \n    0.058 \n    3.062 \n  \nItem Unique Variances\n\n Item 1 \n    0.970 \n    0.083 \n    0.543 \n  \n\n Item 2 \n    0.449 \n    0.057 \n    0.253 \n  \n\n Item 3 \n    0.607 \n    0.084 \n    0.327 \n  \n\n Item 4 \n    0.635 \n    0.085 \n    0.367 \n  \n\n Item 5 \n    0.950 \n    0.090 \n    0.470 \n  \n\n Item 6 \n    0.497 \n    0.061 \n    0.288"
  },
  {
    "objectID": "posts/2020-05-25-study-notes-gt-package-and-format-table/index.en.html",
    "href": "posts/2020-05-25-study-notes-gt-package-and-format-table/index.en.html",
    "title": "Study Notes: gt package and format table",
    "section": "",
    "text": "A introduction about gt package is here"
  },
  {
    "objectID": "posts/2020-05-25-study-notes-gt-package-and-format-table/index.en.html#basics-of-gt",
    "href": "posts/2020-05-25-study-notes-gt-package-and-format-table/index.en.html#basics-of-gt",
    "title": "Study Notes: gt package and format table",
    "section": "Basics of gt\n",
    "text": "Basics of gt\n\nA basic gt table can be created as so\n\ndata(\"iris\")\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\niris %>% \n  head() %>% \n  gt()\n\n\n\n\n\n\nSepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n      Species\n    \n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\n\nYou can add row names (rowname_col argument) and add group names (groupname_col argument) into the table:\n\niris %>% \n  arrange(desc(Sepal.Length)) %>% # 6 types of iris with largest sepal length\n  mutate(Rank = paste0(\"ID\", 1:nrow(.))) %>% \n  head(20) %>% \n  gt(groupname_col = \"Species\", \n     rowname_col = \"Rank\")\n\n\n\n\n\n\n\n      Sepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n    \n\n\nvirginica\n    \n\nID1\n7.9\n3.8\n6.4\n2.0\n\n\nID2\n7.7\n3.8\n6.7\n2.2\n\n\nID3\n7.7\n2.6\n6.9\n2.3\n\n\nID4\n7.7\n2.8\n6.7\n2.0\n\n\nID5\n7.7\n3.0\n6.1\n2.3\n\n\nID6\n7.6\n3.0\n6.6\n2.1\n\n\nID7\n7.4\n2.8\n6.1\n1.9\n\n\nID8\n7.3\n2.9\n6.3\n1.8\n\n\nID9\n7.2\n3.6\n6.1\n2.5\n\n\nID10\n7.2\n3.2\n6.0\n1.8\n\n\nID11\n7.2\n3.0\n5.8\n1.6\n\n\nID12\n7.1\n3.0\n5.9\n2.1\n\n\nID15\n6.9\n3.2\n5.7\n2.3\n\n\nID16\n6.9\n3.1\n5.4\n2.1\n\n\nID17\n6.9\n3.1\n5.1\n2.3\n\n\nID19\n6.8\n3.0\n5.5\n2.1\n\n\nID20\n6.8\n3.2\n5.9\n2.3\n\n\nversicolor\n    \n\nID13\n7.0\n3.2\n4.7\n1.4\n\n\nID14\n6.9\n3.1\n4.9\n1.5\n\n\nID18\n6.8\n2.8\n4.8\n1.4\n\n\n\n\n\n\nNext, the boarder could be added into the table:\n\niris %>% \n  arrange(desc(Sepal.Length)) %>% # 6 types of iris with largest sepal length\n  mutate(Rank = paste0(\"ID\", 1:nrow(.))) %>% \n  head(20) %>% \n  gt(groupname_col = \"Species\", \n     rowname_col = \"Rank\") %>% \n  ########################### \n  # Below is changed\n  ###########################\n  tab_style( # tab_style to change style of cells, \n    # cells_borders provides the formatting\n    # locations tells it where add black borders to all column labels\n    style = list(\n      cell_borders(\n        sides = \"left\",\n        color = \"black\",\n        weight = px(1.2)\n      )\n    ),\n    locations = list(\n      cells_body(\n        columns = colnames(iris)\n      )\n    )\n  ) %>% \n  # Add botton line below the column names\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = \"bottom\",\n        color = \"black\",\n        weight = px(3)\n      )\n    ),\n    locations = list(\n      cells_column_labels(\n        columns = gt::everything()\n      )\n    )\n  )\n\n\n\n\n\n\n\n      Sepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n    \n\n\nvirginica\n    \n\nID1\n7.9\n3.8\n6.4\n2.0\n\n\nID2\n7.7\n3.8\n6.7\n2.2\n\n\nID3\n7.7\n2.6\n6.9\n2.3\n\n\nID4\n7.7\n2.8\n6.7\n2.0\n\n\nID5\n7.7\n3.0\n6.1\n2.3\n\n\nID6\n7.6\n3.0\n6.6\n2.1\n\n\nID7\n7.4\n2.8\n6.1\n1.9\n\n\nID8\n7.3\n2.9\n6.3\n1.8\n\n\nID9\n7.2\n3.6\n6.1\n2.5\n\n\nID10\n7.2\n3.2\n6.0\n1.8\n\n\nID11\n7.2\n3.0\n5.8\n1.6\n\n\nID12\n7.1\n3.0\n5.9\n2.1\n\n\nID15\n6.9\n3.2\n5.7\n2.3\n\n\nID16\n6.9\n3.1\n5.4\n2.1\n\n\nID17\n6.9\n3.1\n5.1\n2.3\n\n\nID19\n6.8\n3.0\n5.5\n2.1\n\n\nID20\n6.8\n3.2\n5.9\n2.3\n\n\nversicolor\n    \n\nID13\n7.0\n3.2\n4.7\n1.4\n\n\nID14\n6.9\n3.1\n4.9\n1.5\n\n\nID18\n6.8\n2.8\n4.8\n1.4"
  },
  {
    "objectID": "posts/2022-05-20-visualization-for-nsf-grant-on-bayesian-cognitive-diagnosis/index.en.html",
    "href": "posts/2022-05-20-visualization-for-nsf-grant-on-bayesian-cognitive-diagnosis/index.en.html",
    "title": "NSF Grant on Bayesian Cognitive Diagnosis",
    "section": "",
    "text": "The NSF grant awards can be easily searched via NSF website. Check Active Awards and type “Bayesian & Cognitive Diagnosis” into the search box. Two things I’m really interested in: (1) Who as Principal Investigator (PI) obtained most NSF awards? (2) Which institute obtained most NSF awards?"
  },
  {
    "objectID": "posts/2022-05-20-visualization-for-nsf-grant-on-bayesian-cognitive-diagnosis/index.en.html#who-get-most-awards",
    "href": "posts/2022-05-20-visualization-for-nsf-grant-on-bayesian-cognitive-diagnosis/index.en.html#who-get-most-awards",
    "title": "NSF Grant on Bayesian Cognitive Diagnosis",
    "section": "Who get most awards",
    "text": "Who get most awards\n\npi_amount <- awards |> \n  select(PI = PrincipalInvestigator, Org = Organization, Amount = AwardedAmountToDate, Title) |> \n  filter(PI!=\"\") |> \n  mutate(Org = str_replace_all(Org, pattern = \" -DO NOT USE\", \"\")) |> \n  mutate(Amount = str_replace_all(Amount, pattern = \"[\\\\$\\\\,]\", \"\")) |> \n  mutate(Amount = as.numeric(Amount)) |> \n  mutate(Title = str_replace(Title, \"    \", \" \")) |> \n  mutate(Title = str_replace(Title, \"NCRN-MN: \", \"\")) |> \n  mutate(Title = str_replace(Title, \"Collaborative Research: \", \"\")) |> \n  mutate(Title = str_replace(Title, \"CAREER: \", \"\")) |> \n  mutate(Title = sub(x = Title, pattern = '(?<=.{85})', replacement = '\\n', perl = TRUE)) |> \n  mutate(Title = str_replace(Title, \"^ \", \"\")) |> \n  mutate(PI = paste0(PI, \"\\n\", Org))\n\npi_amount_p <- pi_amount |> \n  group_by(PI) |> \n  summarise(\n    Amount_sum = sum(Amount),\n    Award_num = n(),\n    Title = Title[1]\n  ) |> \n  mutate(PI = fct_reorder(PI, Amount_sum)) |> \n  arrange(desc(PI)) |> \n  head(50) |>  # top 100 \n  mutate(Highlight = c(rep(1, 10), rep(0, 40)),\n         rank = row_number()) |> \n  mutate(labels = paste0(round(Amount_sum/ 1e6, 1), \" M\"))\n\nggplot(pi_amount_p) +\n  geom_col(aes(x = PI, y = Amount_sum, fill = factor(Highlight))) +\n  # geom_text(aes(x = PI, y = 0, label = labels), hjust = 1, size = 3) +\n  geom_text(aes(x = PI, y = 0, label = Title), hjust = 0, size = 3, alpha = 0.8) +\n  scale_y_continuous(labels = scales::label_number(suffix = \" M\", scale = 1e-6), limits = c(NA, 4500000)) +\n  # scale_x_discrete(labels = PI, breaks = PI) +\n  scale_fill_manual(values = c(\"darkblue\", \"red\")) +\n  labs(title = \"NSF Social Economic Sciences: Top 50 PIs most amount of awards\\nfunded (2021-2022)\", \n       subtitle = \"Bayesian Cognitive Diagnosis\",\n       caption = 'SEARCH: \"Bayesian Cognitive Diagnosis\"\\nSource:https://nsf.gov/awardsearch',\n       x = \"PI & Orgnization\", y = \"Total Amount of Awards\") +\n  coord_flip() +\n  ggdark::dark_theme_gray() +\n  theme(legend.position = \"\", text = element_text(size = 10), title = element_text(hjust = -0.1))"
  },
  {
    "objectID": "posts/2023-06-26-moving-to-quarto/index.html",
    "href": "posts/2023-06-26-moving-to-quarto/index.html",
    "title": "Moving my website to Quarto",
    "section": "",
    "text": "Since June 25, 2023, I start to move my website from hugo/rmarkdown/blogdown/wowchemy to quarto website. It is difficult to explain why I spend so much time on that. Perhaps because some reasons same as other bloggers:\n(1) Quarto is the next generation of rmarkdown.\n(2) Quarto is independent with R or Rstudio.\n(3) Quarto has a clean file tree for website building.\n(4) Quarto has cleaner command than hugo (i.e., `quarto publish netlify` for publishing website etc.).\nThis blog serves as a note how I customize quarto website bit by bit. It will not be a comprehensive tutorial (much online resources exists) but contain be some tricks."
  },
  {
    "objectID": "posts/2023-06-26-moving-to-quarto/index.html#useful-links",
    "href": "posts/2023-06-26-moving-to-quarto/index.html#useful-links",
    "title": "Moving my website to Quarto",
    "section": "Useful links",
    "text": "Useful links\n\nQuarto official documentation is always the best place to starts with.\n\n\n\n\n\n\n\nNicola Rennie’s blog is very inspiring. Nice font setting and background. I feel like Hugo Apéro is the best hugo theme in the market.\n\n\n\n\n\n\nYihui’s blog. As the creator of blogdown, Yihui talked about why not transfer to Quarto :P I am a old player of hugo/blogdown, but I am not good at customizing the website from the scratch. Thus, quarto suits my needs very well. For those who is very experienced at JS, hugo is still a better choice.\n\n\n\n\n\n\nFrank Harrel’s blog: R workflow."
  },
  {
    "objectID": "posts/2023-06-26-moving-to-quarto/index.html#tricks-of-quarto",
    "href": "posts/2023-06-26-moving-to-quarto/index.html#tricks-of-quarto",
    "title": "Moving my website to Quarto",
    "section": "Tricks of Quarto",
    "text": "Tricks of Quarto\n1. Code highlighting\nThe very first trick is using format > html > code-fold: true settings in YAML metadata in _quarto.yml (global) or .qmd (local) to hide the code block as |> Code, like:\n\n⌘+CkableExtra::kbl(head(iris)) |> \n  kableExtra::kable_styling(\n    html_font = \"Maven Pro\",\n    bootstrap_options = c('striped', 'hover'),\n    font_size = 10, full_width = TRUE)\n\n\n\n\n Sepal.Length \n    Sepal.Width \n    Petal.Length \n    Petal.Width \n    Species \n  \n\n\n 5.1 \n    3.5 \n    1.4 \n    0.2 \n    setosa \n  \n\n 4.9 \n    3.0 \n    1.4 \n    0.2 \n    setosa \n  \n\n 4.7 \n    3.2 \n    1.3 \n    0.2 \n    setosa \n  \n\n 4.6 \n    3.1 \n    1.5 \n    0.2 \n    setosa \n  \n\n 5.0 \n    3.6 \n    1.4 \n    0.2 \n    setosa \n  \n\n 5.4 \n    3.9 \n    1.7 \n    0.4 \n    setosa \n  \n\n\n\n\nNote that the code block can be numbered and added with a left border using code-block-bg: true and code-block-border-left: \"#31BAE9\"\nCode block now also can be shown with language #| echo: fenced. As the code chunk shown below, {r} is explicitly presented. I don’t hate #| as the new way of chuck option setup but when I test the code chuck, I found there is a space between #| and option keys. For example, it should be #| echo: fenced rather than #|echo:fenced. Otherwise, quarto will ignore chunk options.\n\n```{r}\n#| eval: false\n#| code-fold: false\nkableExtra::kbl(head(iris)) |> \n  kableExtra::kable_styling(\n    html_font = \"Maven Pro\",\n    bootstrap_options = c('striped', 'hover'),\n    font_size = 10, full_width = TRUE)\n```\n\n\n⌘+C```{python}\n#| eval: false\n#| code-fold: show\nimport numpy as np\niris = np.array(iris)\n```"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#outline",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#outline",
    "title": "Dissertation Defence",
    "section": "Outline",
    "text": "Outline\n\n\nBackground (5 minutes)\nPerformance measures (5 minutes)\nSimulation study (15 minutes)\nEmpirical study (10 minutes)\nConclusion (5 minutes)\nDiscussion (5 minutes)"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#research-motivation",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#research-motivation",
    "title": "Dissertation Defence",
    "section": "Research Motivation",
    "text": "Research Motivation\n\nQ-matrix is usually determined by expert judgement, so there can be uncertainty about some of its elements. Model selection methods are necessary to select the model with the “correct” Q-matrix.\nPrevious model selection methods such as information criterion and Bayes Factors are not flexible regarding checking specific aspects of data\n\nPosterior predictive checking (PPC)\nAdvantages of PPC\n\nPPC is a flexible tool and implemented in most Bayesian software.\n\nDrawbacks of PPC\n\nPPC is not fully Bayesian since it doesn’t take the uncertainty of observed data into account\nPPC uses data twice\n\n\nModel comparison approach for Bayesian psychometric models are not well investigated. Use global fit to evaluate fit and then use local misfit detect method to find local misfit. Then repeat it until model fits."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#research-objectives",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#research-objectives",
    "title": "Dissertation Defence",
    "section": "Research Objectives",
    "text": "Research Objectives\n\nTo construct a novel PPMC method using limited-information model fit indices in Bayesian LCDM\nSimulation study: to determine the performance of the proposed method under different conditions and compare it to previous model checking methods\nEmpirical study: to investigate the utility of PPMC with limited-information model fit indices in real settings"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#overview-proposed-approach",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#overview-proposed-approach",
    "title": "Dissertation Defence",
    "section": "Overview: Proposed Approach",
    "text": "Overview: Proposed Approach\n\n\n\n\nflowchart LR\n  style C fill:#99ff99,stroke:#333,stroke-width:2px\n  style K fill:#99ff99,stroke:#333,stroke-width:2px\n  \n  style H fill:#ff99cc,stroke:#333,stroke-width:2px\n  style M fill:#ff99cc,stroke:#333,stroke-width:2px\n  \n  style E fill:#f9f,stroke:#333,stroke-width:2px\n  style F fill:#f9f,stroke:#333,stroke-width:2px\n  style G fill:#f9f,stroke:#333,stroke-width:2px\n  \n  Z[(Data)] --> A & E & I\n\n  subgraph Model 1\n  A[LCDM 1] -->|Bayesian \\n estimate| B(Posterior\\n Distribution)\n  B -->|sample| C(Posterior \\n Predictive \\n M2 fa:fa-star)\n  C --> D{{KS Test}}\n  D --> H[KS-PP-M2 fa:fa-star]\n  end\n\n  subgraph Reference: BayesNet Model\n  E[BayesNet] --> |Bayesian \\n estimate| F(Posterior \\n Distribution)\n  F -->|sample| G(Posterior \\n Predictive \\n M2 fa:fa-star)\n  end\n  G --> D & L\n\n  subgraph Model 2\n  I[LCDM 2] -->|Bayesian \\n estimate| J(Posterior\\n Distribution)\n  J -->|sample| K(Posterior \\n Predictive \\n M2 fa:fa-star)\n  K --> L{{KS Test}}\n  L --> M[KS-PP-M2 fa:fa-star]\n  end\n\n  H & M --> N{Decision}"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#performance-measures",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#performance-measures",
    "title": "Dissertation Defence",
    "section": "Performance measures",
    "text": "Performance measures\n\nCognitive diagnostic index - item/test discrimination index\nPosterior predictive M2 - absolute fit\nKS-PP-M2 and InfoCrit (AIC/BIC/DIC/WAIC) - relative fit\n\n\nHow many information items contains to discriminate people with different attribute profiles?"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#research-questions",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#research-questions",
    "title": "Dissertation Defence",
    "section": "Research Questions",
    "text": "Research Questions\n\nIs the proposed method appropriate for detecting model-data misfit with varied degree of Q-matrix misspecification\nCompared to information criteria, does the proposed approach have higher true positive rate (TPR) when selecting the correct model?\nHow does the overall discrimination power indicated by Cognitive Diagnostic Index affects the performance of the proposed method in selecting the model with best Q-matrix?"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#simulation-settings",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#simulation-settings",
    "title": "Dissertation Defence",
    "section": "Simulation Settings",
    "text": "Simulation Settings\n\nGenerate simulated data sets under the LCDM framework with two main factors:\n\nsample size: 200 draws from 1000 to 2000\nattribute correlation: {0.25, 0.5}\n400 conditions in total\n\n30 items and 5 attributes\nLatent attributes: mastery status of attributes for each individual are determined by cutting attribute scores. Item parameters are randomly sampled.\n\nBased on attribute correlation, continuous attribute scores are first generated for each sample.\nThen continuous attribute scores are dichonomized by cutting the scores with the cutting scores\nFinally. observed item responses are generated with attribute status and corresponding item parameters"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#analysis-models",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#analysis-models",
    "title": "Dissertation Defence",
    "section": "Analysis Models",
    "text": "Analysis Models\n\n\n\nBayesian Network model\nData generation model - LCDM\nModel with 3 items (10%) underspecify attributes\nModel with 6 items (20%) underspecify attributes\nModel with 3 items (10%) misspecify attributes\nModel with 6 items (20%) misspecify attributes\n\n\nQ-matrix\n\n\n\n\n\nCorrect model\n\n\n\n\n\n\n\n10% underspecify\n\n\n\n\n\n\n\n20% underspecify\n\n\n\n\n\n\n\n10% misspecify\n\n\n\n\n\n\n\n20% misspecify"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#mcmc-settings",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#mcmc-settings",
    "title": "Dissertation Defence",
    "section": "MCMC settings",
    "text": "MCMC settings\n\nAll Bayesian models are estimated using blatent R package in R version 3.6\n4 MCMC with 4000 iterations with first 1000 discarded\nPrior distribution are set up by default of blatent.\nAll parameters estimation converged with PSRF < 1.1"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#summary-of-posterior-predictive-m2-500-draws",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#summary-of-posterior-predictive-m2-500-draws",
    "title": "Dissertation Defence",
    "section": "Summary of Posterior Predictive M2 (500 draws)",
    "text": "Summary of Posterior Predictive M2 (500 draws)\n\n\n\n\n\n\n\nTable 1:  Mean and SD of Posterior Predictive M2 for Models across conditions \n  \n  \n    \n      \n      BayesNet\n      Correct1\n      \n        Underspecified Qmatrix\n      \n      \n        Incorrect specified Qmatrix\n      \n    \n    \n      10%\n      20%\n      10%\n      20%\n    \n  \n  \n    \n      Skill Correlation is .25\n    \n    [1000,1250)\n23.23(1.94)\n21.49(2.08)\n28.92(3.19)\n33.51(3.97)\n27.92(3.36)\n30.02(3.49)\n    [1250,1500)\n30.48(3.13)\n29.03(2.90)\n40.88(6.60)\n48.82(8.19)\n39.66(5.47)\n42.73(5.95)\n    [1500,1750)\n39.36(3.82)\n38.30(4.15)\n57.56(8.70)\n69.60(10.70)\n53.99(8.13)\n58.41(9.03)\n    [1750,2000)\n48.96(3.09)\n49.55(3.65)\n75.40(10.02)\n90.90(11.19)\n68.45(7.70)\n75.26(9.15)\n    \n      Skill Correlation is .50\n    \n    [1000,1250)\n24.83(2.97)\n24.07(2.95)\n32.25(5.36)\n36.69(5.78)\n32.59(5.58)\n34.44(5.43)\n    [1250,1500)\n34.24(3.70)\n33.72(3.58)\n47.70(6.60)\n54.91(7.26)\n47.04(6.00)\n49.96(5.94)\n    [1500,1750)\n43.38(3.11)\n45.76(3.96)\n63.14(7.27)\n74.70(9.73)\n65.10(7.17)\n69.42(8.05)\n    [1750,2000)\n55.54(3.48)\n60.55(4.74)\n94.06(10.59)\n111.40(12.80)\n90.52(9.36)\n97.18(10.01)\n  \n  \n  \n    \n      1 Bold font: The model with smallest average values of PP-M2.\n    \n  \n\n\n\n\n\nThis table presents the posterior predictive M2 results for all six models across different conditions. Upper tables is for skill correlation equals to .25. Lower table is for .5\nFor all condition, BayesNet model and Correct model have best average absolute model fit. As sample size goes above 1700, BayesNet model is best model. Higher level of Q-matrix misspecification will worsen model fit."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#path-plot-for-pp-m2",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#path-plot-for-pp-m2",
    "title": "Dissertation Defence",
    "section": "Path plot for PP-M2",
    "text": "Path plot for PP-M2\n\nTitle: Path Plot for Average Posterior Predictive M2"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#findings",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#findings",
    "title": "Dissertation Defence",
    "section": "Findings",
    "text": "Findings\n\nThe correct model and the BayesNet model have lowest PP-M2 (best fit).\n\nWhen sample size is relatively small, the correct model slightly fit better than the BayesNet;\nWhen sample size is relatively large, the BayesNet fits better than the correct model\n\nAs sample size increases, the difference of PP-M2 among models gets larger. In other words, the PP-M2 has asymptotically more power detecting misfit.\nThe BayesNet model has least uncertainty of model predictive accuracy in term of variations of average PP-M2\nAs more items misspecify/underspecify attributes in Q-matrix, the PP-M2 gets higher."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#compare-ks-pp-m2-to-other-methods",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#compare-ks-pp-m2-to-other-methods",
    "title": "Dissertation Defence",
    "section": "Compare KS-PP-M2 to other methods",
    "text": "Compare KS-PP-M2 to other methods\n\n\n\n\n\n\n\nTable 2:  Mean and SD of Model Selection Indices By Models across conditions \n  \n  \n    \n      \n      Models\n      \n        Information Criterion1,2\n      \n      KS-PP-M2\n    \n    \n      DIC\n      WAIC\n      AIC\n      BIC\n    \n  \n  \n    \n      Skill Correlation is .25\n    \n    Correct\nModel 1\n44,301(8,816)\n44,303(8,817)\n44,387(8,812)\n45,291(8,846)\n0.18(0.04)\n    Underspecified\nModel 2:\n 10%\n44,869(8,931)\n44,872(8,932)\n44,961(8,927)\n45,865(8,961)\n0.66(0.14)\n    Underspecified\nModel 3:\n 20%\n45,400(9,028)\n45,406(9,030)\n45,500(9,024)\n46,404(9,058)\n0.83(0.10)\n    Misspecified\nModel 4:\n 10%\n44,842(8,905)\n44,845(8,907)\n44,932(8,902)\n45,805(8,934)\n0.60(0.13)\n    Misspecified\nModel 5:\n 20%\n45,110(8,952)\n45,113(8,953)\n45,188(8,949)\n45,997(8,979)\n0.70(0.12)\n    \n      Skill Correlation is .50\n    \n    Correct\nModel 1\n45,607(9,219)\n45,612(9,221)\n45,699(9,215)\n46,614(9,250)\n0.33(0.11)\n    Underspecified\nModel 2:\n 10%\n46,152(9,341)\n46,159(9,342)\n46,250(9,337)\n47,165(9,372)\n0.75(0.13)\n    Underspecified\nModel 3:\n 20%\n46,659(9,448)\n46,668(9,450)\n46,763(9,444)\n47,677(9,479)\n0.86(0.10)\n    Misspecified\nModel 4:\n 10%\n46,172(9,326)\n46,178(9,327)\n46,268(9,322)\n47,150(9,356)\n0.75(0.13)\n    Misspecified\nModel 5:\n 20%\n46,403(9,373)\n46,409(9,374)\n46,485(9,369)\n47,304(9,401)\n0.80(0.10)\n  \n  \n  \n    \n      1 Bold: The model with smallest average value of model selection indice.\n    \n    \n      2 Information Criterion & KS-PP-M2: lower values better model fit\n    \n  \n\n\n\n\n\nThis table shows the average values of fit indices across 200 conditions. All fit indices shows correct model has lowest values, which means best model fit."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#true-positive-rate",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#true-positive-rate",
    "title": "Dissertation Defence",
    "section": "True Positive Rate:",
    "text": "True Positive Rate:\n\nTrue Positive Rates of choosing correct model\n\nThis table represents the average TPR for KS-PP-M2 and four information criteria for each sample size and two levels of attribute correlation.\nAll approaches have 100% power choosing the correct model among five analysis models."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#effects-of-cognitive-diagnostic-index",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#effects-of-cognitive-diagnostic-index",
    "title": "Dissertation Defence",
    "section": "Effects of Cognitive Diagnostic Index",
    "text": "Effects of Cognitive Diagnostic Index"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#effects-of-cognitive-diagnostic-index-cont.",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#effects-of-cognitive-diagnostic-index-cont.",
    "title": "Dissertation Defence",
    "section": "Effects of Cognitive Diagnostic Index (Cont.)",
    "text": "Effects of Cognitive Diagnostic Index (Cont.)\n\n\nThe figure shows the relationship between KS-PP-M2 along with Cognitive Diagnostic Index. As cognitive diagnostic index of data sets increase, KS-PP-M2 for each analysis models are quite stable.\nThe trend of KS-PP-M2 is also proven by regression model of CDI and models. Mean centered CDI has no signitifcant effect on KS-PP-M2 values."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#conclusion-simulation-study",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#conclusion-simulation-study",
    "title": "Dissertation Defence",
    "section": "Conclusion (Simulation study)",
    "text": "Conclusion (Simulation study)\n\nPosterior predictive M2 statistics showed the Bayesian Network model and the correct model have best model fit.\nSimilar to information criteria, KS-PP-M2 can select data generation model from models with Q-matrix misspecification\nHigher Q-matrix misspecification, KS-PP-M2 has higher values, which suggest worse model fit.\nCompared to other methods, KS-PP-M2 has same power of selecting the better model and detecting Q-matrix misspecification under all conditions.\nCDI (test-level discrimination power) has insignificant effect on the fit statistics of the proposed method."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#research-questions-1",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#research-questions-1",
    "title": "Dissertation Defence",
    "section": "Research Questions",
    "text": "Research Questions\n\nHow the proposed approach can be used for the model selection in real settings?\nIs the performance of the proposed approach comparable to other IC methods?"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#design",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#design",
    "title": "Dissertation Defence",
    "section": "Design",
    "text": "Design\n\nThe Examination for Certificate of Proficiency in English (ECPE) data was used as the example data.\nOne reference model and two analysis models: (1) three-dimensional model (the best fitted model in Templin & Hoffman, 2013); (2) two-dimensional model with randomly generated Q-matrix.\nMeasures: (1) absolute fit: PP-M2, (2) relative fit: KS-PP-M2, DIC and WAIC"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#data-and-settings",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#data-and-settings",
    "title": "Dissertation Defence",
    "section": "Data and Settings",
    "text": "Data and Settings\n\nECPE data has 2,922 test takers and 28 items.\nBayesian estimation were used with 2000 iterations and 1000 discarded burn-ins.\nPrior distribution setups are by default of blatent package"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#density-plot-of-posterior-predictive-m2",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#density-plot-of-posterior-predictive-m2",
    "title": "Dissertation Defence",
    "section": "Density Plot of Posterior predictive M2",
    "text": "Density Plot of Posterior predictive M2\n\nNote: solid line (the BayesNet model); dotted model (the three-dimension model); dashed line (the two-dimension model)."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#model-selection-indices",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#model-selection-indices",
    "title": "Dissertation Defence",
    "section": "Model Selection Indices",
    "text": "Model Selection Indices\n\nNote: Model 1 (three dimensional model); Model 2 (two dimensional model)."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#findings-emprical-study",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#findings-emprical-study",
    "title": "Dissertation Defence",
    "section": "Findings (Emprical study)",
    "text": "Findings (Emprical study)\n\nAccording to the graphical checking of PP-M2, the BayesNet model is the best-fitting model, then followed by the three-dimensional model. The two-dimensioanl model has worst model fit.\nDIC, WAIC, KS-PP-M2 all suggested that the three-dimensional model is better than the two-dimensional model.\nKS-PP-M2 suggested that neither the three-dimensional model and the two-dimensional model have close model fit with BayesNet model."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#conclusion",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#conclusion",
    "title": "Dissertation Defence",
    "section": "Conclusion",
    "text": "Conclusion\n\nIn both simulation and empirical study, posterior predictive M2 suggest BayesNet models and data generation model have close model fit statistics.\nKS statistics for posterior predictive M2 (KS-PP-M2) has same power detecting Q-matrix misspecification with other IC methods according TPR.\nDiscrimination power of data has insignificant relationship with the proposed model checking indices\nKS-PP-M2 provides graphical checking for the variation of model fit indices."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#discussion",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#discussion",
    "title": "Dissertation Defence",
    "section": "Discussion",
    "text": "Discussion\n\nWhen comparing multiple models, varied model selection methods are recommended to report.\nIn Bayesian analysis, AIC/BIC are not fully Bayesian. They are not recommended in Bayesian framework. DIC has problems such as it may produce negative estimates of the effective number of parameters in a model and it is not defined for model with discrete parameters.\nWAIC is fully Bayesian and asymptotically equal to Bayesian cross-validation. LOO is also based on cross-validation approach.\nKS-PP-M2 approach is full Bayesian and provide uncertainty of the observed data.\nKS-PP-M2 could be a relative fit and posterior predictive M2 is a absolute fit.\nKS-PP-M2 is based on the BayesNet model\nKS-PP-M2 does not relied on likelihood function.\nKS-PP-M2 takes advatages of limited-information and potentially works for data with missing data."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#reference",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#reference",
    "title": "Dissertation Defence",
    "section": "Reference",
    "text": "Reference\n\n\nGelman, A., & Hill, J. (2006). Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-information-criterion",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-information-criterion",
    "title": "Dissertation Defence",
    "section": "Supplement: Information Criterion",
    "text": "Supplement: Information Criterion\n\nDIC / WAIC\n\nDIC is a somewhat Bayesian version of AIC that makes two changes, replacing the maximum likelihood estimate \\(\\theta\\) with the posterior mean and replacing k with a data-based bias correction.1\n\n\nWAIC is a more fully Bayesian approach for estimating the out-of-sample expectation, starting with the computed log pointwise posterior predictive density and then adding a correction for effective number of parameters to adjust for overfitting.\n\n\n\nDIC does not the whole posterior information and does not provide uncertainty of fit statistics.\nWAIC provides uncertainty (SE) and is popular but is not flexible to test certain aspects of data.\nPosterior predictive checking is flexible but not full Bayesian. It also has some theoretical issue.\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for Bayesian models. Statistics and Computing, 24(6), 997–1016. https://doi.org/10.1007/s11222-013-9416-2"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-ii-posterior-predictive-check",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-ii-posterior-predictive-check",
    "title": "Dissertation Defence",
    "section": "Supplement II: Posterior predictive check",
    "text": "Supplement II: Posterior predictive check\n\nSimulating replicated data under the fitted model and then comparing these to the observed data (Gelman & Hill, 2006, p. 158)\n\nAims:\n\ncheck local and global model-fit for some aspects of data they’re interested in\nprovide graphical evidence about model fit"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-iii-using-the-data-twice",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-iii-using-the-data-twice",
    "title": "Dissertation Defence",
    "section": "Supplement III: “using the data twice”",
    "text": "Supplement III: “using the data twice”\nOne critique of posterior predictive check is it uses the data twice (Blei, 2011), which means data is not only used for estimating the model but also for checking if the model fits to the data.\n\nThis is a bad idea, because it violates the likelihood principle.\nA typical way in statistics and machine learning literature:\n\nValidate the model on external data\n\nFor first solution, methods include cross-validation approach,"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-iv-model-selection-problem-exist-when",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-iv-model-selection-problem-exist-when",
    "title": "Dissertation Defence",
    "section": "Supplement IV: Model Selection Problem exist when",
    "text": "Supplement IV: Model Selection Problem exist when\n\n\nmultiple alternative models existed\nuncertaity of dimensionality\nQ-matrix misspecification\n\n\n\nThe proposed method aims to provide a fully Bayesian model selection approach or relative fit indice. This study will only focus on Q-matrix detection in model selection."
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-v-factors-of-model-selection-indices",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-v-factors-of-model-selection-indices",
    "title": "Dissertation Defence",
    "section": "Supplement V: Factors of Model selection indices",
    "text": "Supplement V: Factors of Model selection indices\n\nIn fully Bayesian framework, the posterior inference is a comparison between prior information and data. When sample size is small, the posterior information is controlled by prior information which diminish the difference of models.\n\n\nSample size\nDiscrimination information\nQ-matrix\nModel structure"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-vi-fit-measures",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-vi-fit-measures",
    "title": "Dissertation Defence",
    "section": "Supplement VI: Fit Measures",
    "text": "Supplement VI: Fit Measures\nPosterior Predictive M2\n\nM2 is a limited-information statistics which calculated up-to second probabilities of item responses.\n\nM2 more robust than full-information fit statistics in small sample sizes.\nPP-M2 is M2 values conditional on posterior information. Lower average values suggest better model fit.\nCognitive diagnostic Index"
  },
  {
    "objectID": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-vii-ks-statistics",
    "href": "posts/2022-10-23-thesis-defense/thesis_defense_slides.html#supplement-vii-ks-statistics",
    "title": "Dissertation Defence",
    "section": "Supplement VII: KS Statistics",
    "text": "Supplement VII: KS Statistics\n\n\n\n\nMean of reference distribution:\n\n\n\n\n\nMean of target distribution:\n\n\n\n\nAdd another model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThesis Defence 2022"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTITLE: A novel method for model selection in Bayesian Diagnostic Classification Modeling\n\n\n\nOct 23, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nData visualization using ggplot2\n\n\n\nMay 21, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nMay 12, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nShowcase current software used for power analysis of Structural Equation Modeling\n\n\n\nApr 29, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis post reviews the procedure of creating Github Pages Website using distill package and Github Pages in a step-to-step way.\n\n\n\nApr 24, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nJul 6, 2021\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nJan 31, 2021\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nMay 25, 2020\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nOct 20, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nMay 20, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nApr 19, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nFeb 22, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nFeb 19, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nSep 12, 2018\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nSep 11, 2018\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nSep 4, 2018\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nMar 10, 2018\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nNov 23, 2017\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nNov 16, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 12, 2017\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nOct 19, 2017\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html",
    "href": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html",
    "title": "A Conversation between R and Python on Data Analysis and Machine Learning",
    "section": "",
    "text": "When I play with machine learning using python and R, I keep wondering whether I can combine R and Python code in a better way, such as using R for data cleaning/visualization and Python for machine learning. Online resources for PyTorch are basically written using python code. However, I always struggle with pandas and numpy but prefer tidyverse for data cleaning, and data manipulation. That’s why I write this blog. I will start with the Pytorch tensor manipulation and import Pytorch tensor into R, then talk about mixing R/python data analysis with R/python visualization."
  },
  {
    "objectID": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html#pytorch-tensor",
    "href": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html#pytorch-tensor",
    "title": "A Conversation between R and Python on Data Analysis and Machine Learning",
    "section": "PyTorch Tensor",
    "text": "PyTorch Tensor\nLet’s first get familiar with data manipulation using PyTorch. First, torch.zeors(R, C) function can create a zero tensor with the size of R by C.\n\n⌘+C```{python, echo = \"fenced\"}\nimport torch\n\nz = torch.zeros(5, 3)\nprint(z)\n```\n\n>> tensor([[0., 0., 0.],\n>>         [0., 0., 0.],\n>>         [0., 0., 0.],\n>>         [0., 0., 0.],\n>>         [0., 0., 0.]])\n\n\nSimilarly, torch.ones(R, C) creates a tensor filled with ones with the size of R by C with dtype=torch.int16 argument can coverting elements into integer.\n\n⌘+C```{python}\ni = torch.ones((5,3), dtype=torch.int16)\nprint(i)\n```\n\n>> tensor([[1, 1, 1],\n>>         [1, 1, 1],\n>>         [1, 1, 1],\n>>         [1, 1, 1],\n>>         [1, 1, 1]], dtype=torch.int16)\n\n\nWe can generate random numbers to tensor using torch.rand(R, C). It’s recommended to set up a random seed using torch.manual_seed(seed_num) to make sure we can replicate our random tensor.\n\n⌘+C```{python}\ntorch.manual_seed(1729)\nr1 = torch.rand(2, 2)\nprint(f'A random tensor:\\n {r1}')\n```\n\n>> <torch._C.Generator object at 0x1118f0cf0>\n>> A random tensor:\n>>  tensor([[0.3126, 0.3791],\n>>         [0.3087, 0.0736]])\n\n\n\n⌘+C```{python}\nb = torch.arange(4 * 5 * 6).view(4, 5, 6)\nprint(f\"A sequence of number arraged to 4 matrix of the size 5 X 6: \\n{b}\\n\" )\n```\n\n>> A sequence of number arraged to 4 matrix of the size 5 X 6: \n>> tensor([[[  0,   1,   2,   3,   4,   5],\n>>          [  6,   7,   8,   9,  10,  11],\n>>          [ 12,  13,  14,  15,  16,  17],\n>>          [ 18,  19,  20,  21,  22,  23],\n>>          [ 24,  25,  26,  27,  28,  29]],\n>> \n>>         [[ 30,  31,  32,  33,  34,  35],\n>>          [ 36,  37,  38,  39,  40,  41],\n>>          [ 42,  43,  44,  45,  46,  47],\n>>          [ 48,  49,  50,  51,  52,  53],\n>>          [ 54,  55,  56,  57,  58,  59]],\n>> \n>>         [[ 60,  61,  62,  63,  64,  65],\n>>          [ 66,  67,  68,  69,  70,  71],\n>>          [ 72,  73,  74,  75,  76,  77],\n>>          [ 78,  79,  80,  81,  82,  83],\n>>          [ 84,  85,  86,  87,  88,  89]],\n>> \n>>         [[ 90,  91,  92,  93,  94,  95],\n>>          [ 96,  97,  98,  99, 100, 101],\n>>          [102, 103, 104, 105, 106, 107],\n>>          [108, 109, 110, 111, 112, 113],\n>>          [114, 115, 116, 117, 118, 119]]])\n\n\nArithmetic operations\n\n⌘+C```{python}\nones = torch.ones(2, 3)\nprint(f\"First tensor: \\n{ones}\\n\")\n\ntwos = torch.ones(2, 3) * 2 # multiple each element by 2\nprint(f\"Second tensor: \\n{twos}\\n\")\n\nthrees = ones + twos # addition allowed when shapes of two tensors are similar\nprint(f\"Third tensor: \\n{threes}\\n\")\n```\n\n>> First tensor: \n>> tensor([[1., 1., 1.],\n>>         [1., 1., 1.]])\n>> \n>> Second tensor: \n>> tensor([[2., 2., 2.],\n>>         [2., 2., 2.]])\n>> \n>> Third tensor: \n>> tensor([[3., 3., 3.],\n>>         [3., 3., 3.]])\n\n\nMore examples of the matrix operations:\n\n⌘+C```{python}\ntorch.manual_seed(1729)\na = (torch.rand(2, 2) - 0.5) * 2\nprint(f'A random matrix: \\n{a}\\n')\n\na_abs = torch.abs(a) # Absolute values for elements\nprint(f'A absolute matrix: \\n{a_abs}\\n')\n\na_asin = torch.asin(a) # trigonometric functions\nprint(f'Inverse sine of r: \\n{a_asin}\\n')\n\na_det = torch.det(a) # Determinant and singular value decomposition\nprint(f'Determinant of r: \\n{a_det}\\n')\na_svd = torch.svd(a) \nprint(f'Singlular value decomposition of r: \\n{a_svd}\\n')\n\na_std_mean = torch.std_mean(a) # Statistical and aggregate operations:\nprint(f'Average and standard deviation of r: \\n{a_std_mean}\\n')\na_max = torch.max(a)\nprint(f'Maximum value of r: \\n{a_max}\\n')\n```\n\n>> <torch._C.Generator object at 0x1118f0cf0>\n>> A random matrix: \n>> tensor([[-0.3748, -0.2418],\n>>         [-0.3827, -0.8528]])\n>> \n>> A absolute matrix: \n>> tensor([[0.3748, 0.2418],\n>>         [0.3827, 0.8528]])\n>> \n>> Inverse sine of r: \n>> tensor([[-0.3842, -0.2442],\n>>         [-0.3927, -1.0214]])\n>> \n>> Determinant of r: \n>> 0.22711339592933655\n>> \n>> Singlular value decomposition of r: \n>> torch.return_types.svd(\n>> U=tensor([[-0.3909, -0.9204],\n>>         [-0.9204,  0.3909]]),\n>> S=tensor([1.0111, 0.2246]),\n>> V=tensor([[ 0.4933,  0.8699],\n>>         [ 0.8699, -0.4933]]))\n>> \n>> Average and standard deviation of r: \n>> (tensor(0.2678), tensor(-0.4630))\n>> \n>> Maximum value of r: \n>> -0.24180912971496582\n\n\nlistwise computation\n\n⌘+C```{python}\na_totalSum = torch.sum(a)\nprint(f'global sum of r: \\n{a_totalSum}\\n')\n\na_rowSum = torch.sum(a, dim=1, keepdim=True)\nprint(f'row sums of r: \\n{a_rowSum}\\n')\n\na_colSum = torch.sum(a, dim=0, keepdim=True)\nprint(f'column sums of r: \\n{a_colSum}\\n')\n```\n\n>> global sum of r: \n>> -1.852110505104065\n>> \n>> row sums of r: \n>> tensor([[-0.6166],\n>>         [-1.2355]])\n>> \n>> column sums of r: \n>> tensor([[-0.7575, -1.0946]])"
  },
  {
    "objectID": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html#import-tensor-to-r",
    "href": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html#import-tensor-to-r",
    "title": "A Conversation between R and Python on Data Analysis and Machine Learning",
    "section": "Import tensor to R",
    "text": "Import tensor to R\nIf you install torch package in R. You probably found that Pytorch’s tensor object can be called directly in R as torch.Tensor.\n\n⌘+C```{r}\na_inR = py$a\nclass(a_inR)\n```\n\n>> [1] \"torch.Tensor\"          \"torch._C._TensorBase\"  \"python.builtin.object\"\n\n\nUnfortunately, it does not allow you to manipulate this tensor object directly using R function. For example, if you do matrix operation, it will pop up error message.\n\n⌘+C```{r, error=TRUE}\na_inR * 2\n```\n\n>> Error in a_inR * 2: non-numeric argument to binary operator\n\n\nHowever, you can use python method in R style (change . to $) as long as you load reticulate package. Like:\n\n⌘+C```{r, error=TRUE}\na_inR$shape\na_inR$data\n```\n\n>> torch.Size([2, 2])\n>> tensor([[-0.3748, -0.2418],\n>>         [-0.3827, -0.8528]])\n\n\nCan we import PyTorch tensor to R and employ R to do some dirty works, and then export it back to python? The answer is Yes (partially). We can try out this workflow: tensor -> np.ndarray -> R matrix -> …(some manipulation) -> np.ndarray -> tensor (see diagram below). I’m not sure if it is worthy nor it is even plausible for more complicated tensor class. Note that it may make the memory stores at least three copies of the data. More experiments needed for such work. For more information about arrays in R and python, please refer to the reticulate manual.\n\n\n\n\n\ngraph LR;\n    tensor-->|np$array|np.ndarray;\n    np.ndarray-->|py_to_r|R.matrix;\n    R.matrix -->|some data manipulation|R.matrix;\n    R.matrix-->|r_to_py|np.ndarray;\n    np.ndarray-->|torch$from_numpy|tensor;\n\n\n\n\n\n\n\n\n\n⌘+C```{r}\nnp <- import(\"numpy\", convert=FALSE)\na_data_inR = py_to_r(np$array(a_inR$data))\na_data_inR_revised = a_data_inR * 2\na_inR # original python object in R\na_data_inR_revised # revised matrix in R\n```\n\n>> tensor([[-0.3748, -0.2418],\n>>         [-0.3827, -0.8528]])\n>>            [,1]       [,2]\n>> [1,] -0.7496002 -0.4836183\n>> [2,] -0.7653229 -1.7056797\n\n\n\n⌘+C```{r}\ntorch <- import(\"torch\", convert=FALSE)\na_inR$data = torch$from_numpy(a_data_inR_revised)\na_inR\n```\n\n>> tensor([[-0.7496, -0.4836],\n>>         [-0.7653, -1.7057]], dtype=torch.float64)"
  },
  {
    "objectID": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html#mixture-of-r-and-python-visualization",
    "href": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html#mixture-of-r-and-python-visualization",
    "title": "A Conversation between R and Python on Data Analysis and Machine Learning",
    "section": "Mixture of R and Python: visualization",
    "text": "Mixture of R and Python: visualization\nAs mentioned above, the reticulate R package provides an R interface to Python modules, classes, and functions, which allows us to extend our graphical toolbox to all packages/modules of R and Python. Currently, we can use three methods of data visualization via mixing R code and Python code:\n\nR data + Python matlibplot module\nPython data + Python Vega-Altair module + R output\nPython data + R ggplot2 package\n\nLet’s try them out one by one. First, take iris data in R for example:\n\n⌘+C```{r}\nlibrary(tidyverse)\nlibrary(kableExtra)\niris_dat = iris[1:3]\niris_mat = matrix(unlist(iris_dat), nrow = nrow(iris), ncol = ncol(iris_dat))\ndim(iris_mat)\n```\n\n>> [1] 150   3\n\n\nThe column sums of iris are c(876.5, 458.6, 564.7) and the row sums of first 5 rows of iris are c(10, 9.3, 9.2, 9.2, 10).\n\n⌘+C```{r}\nglue::glue('Columns Sums: {colSums(iris_mat)}')\nglue::glue('Row Sums: {rowSums(iris_mat[1:5, ])}')\n```\n\n>> Columns Sums: 876.5\n>> Columns Sums: 458.6\n>> Columns Sums: 563.7\n>> Row Sums: 10\n>> Row Sums: 9.3\n>> Row Sums: 9.2\n>> Row Sums: 9.2\n>> Row Sums: 10\n\n\nIn Python chunk code of Rmarkdown, we can call data in R using r.{dataname}, in which {dataname} is the object name in R. Note that do not define r in python, otherwise r not longer become the R environment. Now we can load the R data frame in python. Please check reticulate package for more information about the rules of conversation between R and Python.\n\n⌘+C```{python}\nimport torch\nimport numpy as np\niris_ndarray = np.array(r.iris_mat)\niris_tensor = torch.from_numpy(iris_ndarray)\ntorch.sum(iris_tensor, dim=0, keepdim=True)\ntorch.sum(iris_tensor[:5,], dim=1, keepdim=True)\n```\n\n>> tensor([[876.5000, 458.6000, 563.7000]], dtype=torch.float64)\n>> tensor([[10.0000],\n>>         [ 9.3000],\n>>         [ 9.2000],\n>>         [ 9.2000],\n>>         [10.0000]], dtype=torch.float64)\n\n\nIn Edgar Anderson’s Iris data, we can model a prediction model given the measurements in centimeters of sepal length/width, petal length/width and the three types of species: Iris setosa, versicolor, and virginica. Each type contains 50 samples. The very first question is then “can we train a machine learning algorithm to predict whether one belongs to Setosa/Versicolor/Virginica given four characteristics?” We can fit a multinomial regression to test statistical hypotheses of the characteristics’ differences among three species:\n\n⌘+C```{r}\nlibrary(nnet)\nlibrary(MASS)\nlibrary(broom)\nlibrary(kableExtra)\niris_new = iris |> \n  mutate(Species = relevel(Species, \"virginica\"))\n## A multinominal logistic regression with Species-setosa as reference group\ncapture.output(multinomial_fit <- nnet::multinom(Species ~ . + 0, data = iris_new, \n                                                 model = TRUE),file =\"/dev/null\")\n## Print the coefficient table\nkbl(tidy(multinomial_fit, exponentiate = FALSE), digits = 2, \n    booktabs = TRUE, align = \"c\",\n    caption = \"Coefficients of multinominal logistic regression\",\n    col.names = c(\"DV\", \"IV\", \"b(logit)\", \"SE\", \"t.value\", \"p.value\")) |>\n  kable_material_dark(full_width = F, html_font = \"Maven Pro\") |> \n  kable_styling(bootstrap_options = c(\"condensed\", \"hover\"))\n```\n\n\n\nCoefficients of multinominal logistic regression\n \n DV \n    IV \n    b(logit) \n    SE \n    t.value \n    p.value \n  \n\n\n setosa \n    Sepal.Length \n    8.11 \n    106.99 \n    0.08 \n    0.94 \n  \n\n setosa \n    Sepal.Width \n    13.13 \n    157.28 \n    0.08 \n    0.93 \n  \n\n setosa \n    Petal.Length \n    -18.55 \n    76.14 \n    -0.24 \n    0.81 \n  \n\n setosa \n    Petal.Width \n    -13.70 \n    34.79 \n    -0.39 \n    0.69 \n  \n\n versicolor \n    Sepal.Length \n    6.33 \n    2.48 \n    2.55 \n    0.01 \n  \n\n versicolor \n    Sepal.Width \n    6.62 \n    2.53 \n    2.62 \n    0.01 \n  \n\n versicolor \n    Petal.Length \n    -8.44 \n    3.47 \n    -2.43 \n    0.02 \n  \n\n versicolor \n    Petal.Width \n    -10.28 \n    3.46 \n    -2.97 \n    0.00 \n  \n\n\n\n\nAs shown in the table, it seems that multinominal logistic regression suggests none of the four features can significantly differentiate species but this could be misleading. This is because there are underlying correlations between sepal width/length and petal width/length. Next step is we can use matplotlib module to explore the relationships among four characteristics.\n\n⌘+C```{python, out.width = \"80%\", out.height = \"100%\", dpi = 200, fig.retina = 1}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport random\nimport seaborn\n\nseaborn.set(style='whitegrid'); seaborn.set_context('talk')\n\nfrom sklearn.datasets import load_iris\niris_data = load_iris()\n\nn_samples, n_features = iris_data.data.shape\n\ndef Show_Diagram(x_label,y_label,title):\n    plt.figure(figsize=(10,8))\n    plt.scatter(iris_data.data[:,x_label], iris_data.data[:,y_label], c=iris_data.target, cmap=cm.viridis, alpha = 0.5, label = iris_data.target_names)\n    plt.xlabel(iris_data.feature_names[x_label]); plt.ylabel(iris_data.feature_names[y_label]); plt.title(title)\n    plt.legend(('setosa', 'versicolor', 'virginica'))\n    plt.show();x_label = 2;y_label=3;title='Petal'\n\nShow_Diagram(0,1,'Sepal')\nShow_Diagram(2,3,'Petal')\n```\n\n\n\n\n\n\n\nAlternatively, we can use python data and module Vega-Altair to compile a interactive graphical object to a json file (.to_json()). Then we can plot it in R using as_vegaspec function.\n\n⌘+C```{python compile}\n# import altair with an abbreviated alias\nimport altair as alt\nimport pandas as pd\nlabel_dict = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n        \niris = pd.DataFrame(\n    data= np.c_[iris_data['data'], iris_data['target']],\n    columns= iris_data['feature_names'] + ['target']\n    )\niris['target'] = iris['target'].replace(label_dict)\n\nchart1 = alt.Chart(iris).mark_point().encode(\n  alt.X('sepal length (cm):Q').scale(domain=(4,9)),\n  alt.Y('sepal width (cm):Q').scale(domain=(1.5,5)),\n  alt.Color('target:N').scale(scheme='dark2'),\n  alt.Shape('target:N')\n).interactive()\nvw = chart1.to_json()\n```\n\n\n\n⌘+C```{r display}\nas_vegaspec(py$vw)\n```\n\n\n\n\n\nAlternatively, we can use ggplot2 R package + python data to plot the scatter plots, which I prefer.\n\n⌘+C```{r}\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nlibrary(dplyr)\n## A function to convert python iris to R version of iris\ntidy_python_data <- function(iris_from_python) {\n  dat <- iris_from_python$data\n  dat <- apply(dat, 2, as.numeric)\n  colnames(dat) <- iris_from_python$feature_names\n  Species = as.character(factor(iris_from_python$target, labels = iris_from_python$target_names))\n  dat = as.data.frame(cbind(dat, Species = Species))\n  dat <- dat |> \n    mutate(across(-Species, \\(x) as.numeric(x)))\n  dat\n}\n```\n\n\n\n⌘+C```{r}\nlibrary(emojifont)\niris_from_python = tidy_python_data(iris_from_python = py$iris_data)\nggplot(iris_from_python) +\n  geom_point(aes(x = `sepal length (cm)`, y = `sepal width (cm)`, color = Species, shape = Species), size = 2, alpha = 0.8) +\n  labs(title = 'Sepal', caption = 'Love you Melody  ♥ !') +\n  scale_color_brewer(palette = 'Dark2')\n```\n\n\n\n\n\n⌘+C```{r}\nggplot(iris_from_python) +\n  geom_point(aes(x = `petal length (cm)`, y = `petal width (cm)`, color = Species, shape = Species), size = 2, alpha = 0.8) +\n  labs(title = 'Petal', caption = 'Love you Melody  ♥ !') +\n  scale_color_brewer(palette = 'Dark2')\n```\n\n\n\n\nIt appears that its hard to differentiate versicolor with verginica in terms of sepal and petal but setosa is more smaller in petal width/length and sepal length but relative long sepal width."
  },
  {
    "objectID": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html#pure-r-torch-for-r",
    "href": "posts/2023-06-20-pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning/index.en.html#pure-r-torch-for-r",
    "title": "A Conversation between R and Python on Data Analysis and Machine Learning",
    "section": "Pure R: torch for R",
    "text": "Pure R: torch for R\nAlternatively, there is a R package called torch, which is built directly on top of libtorch, a C++ library that provides the tensor-computation and automatic-differentiation capabilities. However, to the date I wrote this post, the version of torch is 0.11.0, which suggests that the package is still far from well developed.\n\n⌘+C```{r}\nlibrary(torch)\nlibrary(luz)\nlibrary(torchvision)\n# torch_tensor(1, device = 'cpu')\n```"
  },
  {
    "objectID": "posts/2019-05-20-nobel-prizes-visualization/index.en.html",
    "href": "posts/2019-05-20-nobel-prizes-visualization/index.en.html",
    "title": "Which Country own the most Liberty Nobel Prizes? France? Ireland?",
    "section": "",
    "text": "Load Packages\ntidyverse package include some very useful tools such as ggplot2, tidyr and dplyr.\n\nlibrary(tidyverse)\nlibrary(LaCroixColoR)\nlibrary(ggthemes)\nlibrary(ggimage)\n\nggimage package was used to add country flags to ggplot layer. LaCroixColoR package used for selecting different colors.\nData\nImport the data.\n\nnobel_winners <- read_csv(\"data_2019-05-14.csv\",\n                          col_types = \"dccccdccDccccccDcc\")\nstr(nobel_winners)\n\nspc_tbl_ [969 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ prize_year          : num [1:969] 1901 1901 1901 1901 1901 ...\n $ category            : chr [1:969] \"Chemistry\" \"Literature\" \"Medicine\" \"Peace\" ...\n $ prize               : chr [1:969] \"The Nobel Prize in Chemistry 1901\" \"The Nobel Prize in Literature 1901\" \"The Nobel Prize in Physiology or Medicine 1901\" \"The Nobel Peace Prize 1901\" ...\n $ motivation          : chr [1:969] \"\\\"in recognition of the extraordinary services he has rendered by the discovery of the laws of chemical dynamic\"| __truncated__ \"\\\"in special recognition of his poetic composition, which gives evidence of lofty idealism, artistic perfection\"| __truncated__ \"\\\"for his work on serum therapy, especially its application against diphtheria, by which he has opened a new ro\"| __truncated__ NA ...\n $ prize_share         : chr [1:969] \"1/1\" \"1/1\" \"1/1\" \"1/2\" ...\n $ laureate_id         : num [1:969] 160 569 293 462 463 1 161 571 294 464 ...\n $ laureate_type       : chr [1:969] \"Individual\" \"Individual\" \"Individual\" \"Individual\" ...\n $ full_name           : chr [1:969] \"Jacobus Henricus van 't Hoff\" \"Sully Prudhomme\" \"Emil Adolf von Behring\" \"Jean Henry Dunant\" ...\n $ birth_date          : Date[1:969], format: \"1852-08-30\" \"1839-03-16\" ...\n $ birth_city          : chr [1:969] \"Rotterdam\" \"Paris\" \"Hansdorf (Lawice)\" \"Geneva\" ...\n $ birth_country       : chr [1:969] \"Netherlands\" \"France\" \"Prussia (Poland)\" \"Switzerland\" ...\n $ gender              : chr [1:969] \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ organization_name   : chr [1:969] \"Berlin University\" NA \"Marburg University\" NA ...\n $ organization_city   : chr [1:969] \"Berlin\" NA \"Marburg\" NA ...\n $ organization_country: chr [1:969] \"Germany\" NA \"Germany\" NA ...\n $ death_date          : Date[1:969], format: \"1911-03-01\" \"1907-09-07\" ...\n $ death_city          : chr [1:969] \"Berlin\" \"Châtenay\" \"Marburg\" \"Heiden\" ...\n $ death_country       : chr [1:969] \"Germany\" \"France\" \"Germany\" \"Switzerland\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   prize_year = col_double(),\n  ..   category = col_character(),\n  ..   prize = col_character(),\n  ..   motivation = col_character(),\n  ..   prize_share = col_character(),\n  ..   laureate_id = col_double(),\n  ..   laureate_type = col_character(),\n  ..   full_name = col_character(),\n  ..   birth_date = col_date(format = \"\"),\n  ..   birth_city = col_character(),\n  ..   birth_country = col_character(),\n  ..   gender = col_character(),\n  ..   organization_name = col_character(),\n  ..   organization_city = col_character(),\n  ..   organization_country = col_character(),\n  ..   death_date = col_date(format = \"\"),\n  ..   death_city = col_character(),\n  ..   death_country = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\nunique(nobel_winners$category)\n\n[1] \"Chemistry\"  \"Literature\" \"Medicine\"   \"Peace\"      \"Physics\"   \n[6] \"Economics\" \n\n\ntribble function allows to create a table by columns. ~country will generate a new columns.\n\ndf_countrycode <-\n  tribble(~country, ~code, \n          \"United States of America\", \"US\",\n          \"Germany\", \"DE\",\n          \"United Kingdom\", \"GB\",\n          \"France\", \"FR\",\n          \"Japan\", \"JP\",\n          \"Netherlands\", \"NL\",\n          \"Sweden\", \"SE\",\n          \"Russia\", \"RU\",\n          \"Canada\", \"CA\",\n          \"Austria\", \"AT\",\n          \"Spain\", \"ES\",\n          \"Denmark\", \"DK\",\n          \"Ireland\", \"IE\",\n          \"Italy\", \"IT\"\n          )\n\nTables\npull() function is similar to use [] to return the value of one column.\n\ncountries <- \n  nobel_winners %>% \n  filter(category == \"Literature\") %>% \n  count(birth_country, sort = T) %>% \n  head(n = 10) %>% # Top 10 countries\n  pull(birth_country)\n\nAdding some columns such as the total number of Liberty Prizes (n_prize), the first year of prize, the last year and the cumulative prizes.\n\nnobel_countries <- \n  nobel_winners %>% \n  filter(birth_country %in% countries, category == \"Literature\") %>% \n  select(prize_year, birth_country) %>% \n  arrange(prize_year) %>% \n  group_by(birth_country) %>% \n  mutate(n_prize = n(),\n         first_prize = min(prize_year),\n         last_prize = max(prize_year),\n         cum = row_number()\n  ) %>% \n  ungroup()\nnobel_countries\n\n# A tibble: 58 × 6\n   prize_year birth_country n_prize first_prize last_prize   cum\n        <dbl> <chr>           <int>       <dbl>      <dbl> <int>\n 1       1901 France             11        1901       2014     1\n 2       1904 France             11        1901       2014     2\n 3       1904 Spain               5        1904       1989     1\n 4       1909 Sweden              7        1909       2011     1\n 5       1915 France             11        1901       2014     3\n 6       1916 Sweden              7        1909       2011     2\n 7       1917 Denmark             4        1917       1944     1\n 8       1917 Denmark             4        1917       1944     2\n 9       1921 France             11        1901       2014     4\n10       1922 Spain               5        1904       1989     2\n# … with 48 more rows\n\n\n\nnobel_countries <- \n  nobel_countries %>% \n  filter(cum == 1) %>% \n  mutate(cum = 0) %>% \n  bind_rows(nobel_countries) %>% \n  arrange(prize_year, cum) %>% \n  mutate(birth_country = fct_reorder(birth_country, n_prize, .desc = TRUE))\nnobel_countries\n\n# A tibble: 68 × 6\n   prize_year birth_country n_prize first_prize last_prize   cum\n        <dbl> <fct>           <int>       <dbl>      <dbl> <dbl>\n 1       1901 France             11        1901       2014     0\n 2       1901 France             11        1901       2014     1\n 3       1904 Spain               5        1904       1989     0\n 4       1904 Spain               5        1904       1989     1\n 5       1904 France             11        1901       2014     2\n 6       1909 Sweden              7        1909       2011     0\n 7       1909 Sweden              7        1909       2011     1\n 8       1915 France             11        1901       2014     3\n 9       1916 Sweden              7        1909       2011     2\n10       1917 Denmark             4        1917       1944     0\n# … with 58 more rows\n\n\n\nfirst_last_nobel <- \n  nobel_countries %>% \n  select(birth_country, n_prize, first_prize, last_prize) %>% \n  mutate(birth_country = as.character(birth_country)) %>% \n  distinct() %>% \n  left_join(df_countrycode, by=c(\"birth_country\" = \"country\"))\nfirst_last_nobel\n\n# A tibble: 10 × 5\n   birth_country            n_prize first_prize last_prize code \n   <chr>                      <int>       <dbl>      <dbl> <chr>\n 1 France                        11        1901       2014 FR   \n 2 Spain                          5        1904       1989 ES   \n 3 Sweden                         7        1909       2011 SE   \n 4 Denmark                        4        1917       1944 DK   \n 5 Ireland                        3        1923       1969 IE   \n 6 Italy                          5        1926       1997 IT   \n 7 Germany                        4        1929       1972 DE   \n 8 United States of America       9        1930       2016 US   \n 9 United Kingdom                 6        1932       2005 GB   \n10 Russia                         4        1933       1970 RU   \n\n\nPlot\n\npp1 <- ggplot(nobel_countries) +\n  aes(x = prize_year, y = cum, group = birth_country) +\n  geom_line(aes(color = birth_country)) +\n  geom_point(data = first_last_nobel, y = 0,\n             aes(x = first_prize, color =birth_country)) +\n  geom_flag(data = first_last_nobel, size = 0.03, asp= 2,\n            aes(x= last_prize, y = n_prize, image = code)) +\n  scale_color_manual(values = lacroix_palette(\"PassionFruit\", n = 10, type = \"continuous\")) +\n  scale_y_continuous(limits = c(NA, 12), breaks = c(0,3,6,9,12)) +\n  labs(title = \"Number of Liberty Nobel Prizes by Countries\",\n       color = NULL,\n       caption = \"Source: The Nobel Prize\\n@_abichat for #TidyTuesday\") +\n  theme_wsj(color = \"gray\") +\n  theme(legend.position = \"bottom\",\n        plot.caption = element_text(size = 10, family = \"Georgia\"),\n        plot.title = element_text(size = 18, family = \"Andale Mono\"),\n        legend.text =  element_text(family = \"Georgia\")\n        )\n\npp1\n\n\n\n# ggsave(\"~/图片/plot_2019-05-14.png\", width = 29, height = 21, units = \"cm\", dpi = \"retina\")\n\nAnimation\nFinally, let’s use gganimate package to add some animation.\n\nlibrary(gganimate)\npp1 +\n  transition_reveal(prize_year)"
  },
  {
    "objectID": "posts/2021-07-04-visualization-for-process-data/index.en.html",
    "href": "posts/2021-07-04-visualization-for-process-data/index.en.html",
    "title": "Visualization for Process Data",
    "section": "",
    "text": "This tutorial aims to explore various types of tools of visualizing the process data.\nBefore diving into the main text, I found one trick to git pull one repo but ignore the local changes is:"
  },
  {
    "objectID": "posts/2021-07-04-visualization-for-process-data/index.en.html#load-packages",
    "href": "posts/2021-07-04-visualization-for-process-data/index.en.html#load-packages",
    "title": "Visualization for Process Data",
    "section": "Load Packages",
    "text": "Load Packages\nlibrary(ProcData)\nlibrary(tidyverse)\nlibrary(RColorBrewer) # for color pallett"
  },
  {
    "objectID": "posts/2021-07-04-visualization-for-process-data/index.en.html#a-little-about-the-toy-data",
    "href": "posts/2021-07-04-visualization-for-process-data/index.en.html#a-little-about-the-toy-data",
    "title": "Visualization for Process Data",
    "section": "A little about the toy data",
    "text": "A little about the toy data\nA dataset containing the response processes and binary response outcomes of 16763 respondents. seqs is an object of class “proc” containing the action sequences and the time sequences of the respondents and responses is binary responses of 16763 respondents. The order of the respondents matches that in seqsß.\nstr(cc_data, max.level = 2)\n## List of 2\n##  $ seqs     :List of 2\n##   ..$ action_seqs:List of 16763\n##   ..$ time_seqs  :List of 16763\n##   ..- attr(*, \"class\")= chr \"proc\"\n##  $ responses: Named int [1:16763] 0 1 1 1 0 0 0 0 0 0 ...\n##   ..- attr(*, \"names\")= chr [1:16763] \"ARE000000200039\" \"ARE000000200051\" \"ARE000000300079\" \"ARE000000400093\" ...\nhead(cc_data$seqs$action_seqs, n = 3)\n## $ARE000000200039\n##  [1] \"start\"    \"0_0_0\"    \"1_2_-2\"   \"2_2_2\"    \"2_2_2\"    \"2_2_2\"   \n##  [7] \"2_2_2\"    \"2_2_2\"    \"2_2_-2\"   \"2_2_-2\"   \"2_-2_-2\"  \"-2_-2_-2\"\n## [13] \"-2_-2_-2\" \"-2_-2_-2\" \"-2_-2_-2\" \"-2_-2_-2\" \"-2_-2_0\"  \"-2_-2_0\" \n## [19] \"-2_-2_0\"  \"-2_0_1\"   \"-2_0_1\"   \"-2_0_1\"   \"-2_0_1\"   \"-2_0_1\"  \n## [25] \"0_0_1\"    \"0_0_1\"    \"0_0_1\"    \"0_0_1\"    \"0_0_1\"    \"0_0_1\"   \n## [31] \"0_0_1\"    \"0_0_1\"    \"0_0_1\"    \"0_0_1\"    \"0_0_1\"    \"end\"     \n## \n## $ARE000000200051\n##  [1] \"start\"    \"reset\"    \"-1_0_0\"   \"-1_-1_0\"  \"-1_-1_-1\" \"-1_0_0\"  \n##  [7] \"-1_0_0\"   \"reset\"    \"2_0_0\"    \"reset\"    \"0_2_0\"    \"reset\"   \n## [13] \"0_0_2\"    \"reset\"    \"0_1_0\"    \"reset\"    \"0_-1_0\"   \"reset\"   \n## [19] \"-1_0_0\"   \"reset\"    \"end\"     \n## \n## $ARE000000300079\n## [1] \"start\" \"1_1_1\" \"reset\" \"0_0_1\" \"reset\" \"0_1_0\" \"reset\" \"1_0_0\" \"end\""
  },
  {
    "objectID": "posts/2021-07-04-visualization-for-process-data/index.en.html#data-transformation",
    "href": "posts/2021-07-04-visualization-for-process-data/index.en.html#data-transformation",
    "title": "Visualization for Process Data",
    "section": "Data Transformation",
    "text": "Data Transformation\n## actions\ndt1 <- cc_data$seqs$action_seqs[1:30]\n## time stamps\ndt2 <- cc_data$seqs$time_seqs[1:30]\n\n## x轴为时间轴，y轴为不同的observations\ndt1_long <- mapply(function(x, y) data.frame(ID = y, action = x) , dt1, names(dt1), SIMPLIFY = FALSE)\ndt1_long <- Reduce(rbind, dt1_long)\n\ndt2_long <- mapply(function(x, y) data.frame(ID = y, time = x) , dt2, names(dt2), SIMPLIFY = FALSE)\ndt2_long <- Reduce(rbind, dt2_long)\n\ndt_full <- cbind(dt1_long, time = dt2_long[,2]) %>% \n  group_by(ID) %>% \n  mutate(time_upper = lead(time)) %>% \n  ungroup() %>% \n  mutate(time_upper = ifelse(is.na(time_upper), time, time_upper), action = as.factor(action))\nhead(dt_full)\n## # A tibble: 6 x 4\n##   ID              action  time time_upper\n##   <chr>           <fct>  <dbl>      <dbl>\n## 1 ARE000000200039 start    0         49.3\n## 2 ARE000000200039 0_0_0   49.3       55.9\n## 3 ARE000000200039 1_2_-2  55.9       61.7\n## 4 ARE000000200039 2_2_2   61.7       62.6\n## 5 ARE000000200039 2_2_2   62.6       63.2\n## 6 ARE000000200039 2_2_2   63.2       63.5"
  },
  {
    "objectID": "posts/2021-07-04-visualization-for-process-data/index.en.html#data-visualization",
    "href": "posts/2021-07-04-visualization-for-process-data/index.en.html#data-visualization",
    "title": "Visualization for Process Data",
    "section": "Data Visualization",
    "text": "Data Visualization\nset.seed(1234)\nn <- 30 # 30 colors\nqual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]\ncol_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))\nline_color = sample(col_vector, n)\n\nggplot(aes(x = time, y = ID, col = action), data = dt_full) +\n  geom_point(size = 2)+\n  geom_linerange(aes(xmin = time, xmax= time_upper), linetype = 1, size = 1.5)+\n  scale_color_manual(values = col_vector, name = \"\") +\n  labs(y = \"\", x = \"Time Length\") +\n  theme(legend.position=\"\") \n\nDr. Jihong Zhang Dr. Jihong Zhang Home Blog More projects About"
  },
  {
    "objectID": "posts/2021-01-31-ppmc-cfa/index.en.html",
    "href": "posts/2021-01-31-ppmc-cfa/index.en.html",
    "title": "[Pre-print] A Model Comparison Approach to Posterior Predictive Model Checks in Bayesian Confirmatory Factor Analysis",
    "section": "",
    "text": "Posterior Predictive Model Checking (PPMC) is frequently used for model fit evaluation in Bayesian Confirmatory Factor Analysis (BCFA). In standard PPMC procedures, model misfit is quantified by the location of a ML-based estimate to the predictive distribution of a statistic for a model. When the ML-based point estimate is far away from the center of the density of the posterior predictive distribution, model fit is poor. One main critique of such standard PPMC procedures is the strong link to the ML-based point estimates of the observed data. Not included in this approach, however, is how variable the ML-based point estimates are and their use in general as the reference point for Bayesian analyses. We propose a new method of PPMC based on the Posterior Predictive distribution of Bayesian saturated model for BCFA models. The method uses the predictive distribution from parameters of the posterior distribution of the saturated model as reference to detect the local misfit of hypothesized models. The results of the simulation study suggest that the saturated model PPMC approach was an accurate method of determining local model misfit and could be used for model comparison. A real example is also provided in this study."
  },
  {
    "objectID": "posts/2021-01-31-ppmc-cfa/index.en.html#citation",
    "href": "posts/2021-01-31-ppmc-cfa/index.en.html#citation",
    "title": "[Pre-print] A Model Comparison Approach to Posterior Predictive Model Checks in Bayesian Confirmatory Factor Analysis",
    "section": "Citation",
    "text": "Citation\nZhang, J., Templin, J., & Mintz, C. E. (2021, February 9). A Model Comparison Approach to Posterior Predictive Model Checks in Bayesian Confirmatory Factor Analysis. https://doi.org/10.31234/osf.io/rf64x"
  },
  {
    "objectID": "posts/2021-01-31-ppmc-cfa/index.en.html#download",
    "href": "posts/2021-01-31-ppmc-cfa/index.en.html#download",
    "title": "[Pre-print] A Model Comparison Approach to Posterior Predictive Model Checks in Bayesian Confirmatory Factor Analysis",
    "section": "Download",
    "text": "Download\nThe document can be viewed and downloaded here."
  },
  {
    "objectID": "posts/2017-11-20-EFA-and-CFA/index.html",
    "href": "posts/2017-11-20-EFA-and-CFA/index.html",
    "title": "EFA v.s. CFA",
    "section": "",
    "text": "I always found exploratory tools and confirmatory tools have distinct fans. The fans of exploratory tools believe the conclusion should be data-driven, nothing else beyond data is needed in order to keep object. On the other hand, some confirmatory fans believe that data could provide nothing without context.\n\nDaniel (1988) stated that factor analysis is “designed to examine the covariance structure of a set of variables and to provide an explanation of the relationships among those variables in terms of a smaller number of unobserved latent variables called factors.”\nRecently, when I was working on my project about Confirmatory Factor Analysis, I found the model indicated very bad model fit (e.g. CFI, TLI, RMSEA, SRMR). Then, should I use modification indices or go back to exploratory factor analysis to find some potential structural issues? Both paths have their own supporters and opposers. EFA path supports claim that EFA could provide some data structure that CFA couldn’t. Allowing cross-loading items, communalities could be calculated. But its disadvantage is that data-driven method are strongly influenced by data. If the data is bad, the EFA will give you wrong answers.\n\n\nCFA is a confirmatory technique - it is theory driven. Therefore, the planning of the analysis is driven by the theoretical relationships among the observed and unobserved variables. When a CFA is conducted, the researcher uses a hypothesized model to estimate a population covariance matrix that is compared with the observed covariance matrix. Technically, the researcher wants to minimize the difference between the estimated and observed matrices.\nCFA model believe that context of the research should be guild line to data. Thus, the model specification should be theory-driven. If the model does not fit the data very well, modification as well as residual variance-covariance matrix could be use to inspect the issues. The problem is that model modification does not lead the final model to true model according to many simulation studies. In that way, CFA models are as similar as EFA."
  },
  {
    "objectID": "posts/2017-11-20-EFA-and-CFA/index.html#which-one-should-be-trust",
    "href": "posts/2017-11-20-EFA-and-CFA/index.html#which-one-should-be-trust",
    "title": "EFA v.s. CFA",
    "section": "Which one should be trust?",
    "text": "Which one should be trust?\nI think it depends on your research project. If your research project has strong theoretical support then CFA should be first step. If your research is new, there’re few related researches about that. Then try EFA first."
  },
  {
    "objectID": "posts/2018-09-11-model-checking-in-dcm/2018-09-11-model-checking-in-dcm.html",
    "href": "posts/2018-09-11-model-checking-in-dcm/2018-09-11-model-checking-in-dcm.html",
    "title": "Introduce Descrepancy Measures",
    "section": "",
    "text": "Descrepancy Measures\n\n\\chi^2 measures for item-pairs (Chen & Thissen, 1997) \nX^2_{jj'}=\\sum_{k=0}^{1} \\sum_{k'=0}^{1} \\frac{(n_{kk'}-E(n_{kk'}))^2}{E(n_{kk'})}\n\n\nG^2 for item pairs\n\nG^2_{jj'}=-2\\sum_{k=0}^{1} \\sum_{k'=0}^{1} \\ln \\frac{E(n_{kk'})}{n_{kk'}}\n\n\nmodel-based covariance (MBC; Reckase, 1997) \nCOV_{jj'} = \\frac{\\sum_{i=1}^{N}(X_{ij}-\\overline{X_j})(X_{ij'}-\\overline{X_{j'}}) }{N} \\\\\nMBC_{jj'} = \\frac{\\sum_{i=1}^{N}(X_{ij}-E(X_{ij}))(X_{ij'}-E(X_{ij'}))}{N}\n\nQ_3 (Yen, 1993) \nQ_{3jj'} = r_{e_{ij}e_{ij'}}\n where r refers to the correlation, e_{ij} = X_{ij} - E(X_{ij}), and E(X_{ij})\nResidual Item Covariance (Fu et al., 2005) \nRESIDCOV_{jj'} = \\frac{[(n_{11})(n_{00})-(n{10})(n_{01})]}{N^2} - \\frac{[E(n_{11})E(n_{00})-E(n_{10})E(n_{01})]}{E(N^2)}\n\nnatural log of the odds ratio (Agresti, 2002) \nLN(OR_{jj'})= \\ln[\\frac{(n_{11})(n_{00})}{(n_{10})(n_{01})}] = \\ln(n_{11}) +\\ln(n_{00})+\\ln(n_{10}) +\\ln(n_{01})\n\nstandardized log odds ratio residual (Chen & Thissen, 1997) \nSTDLN(OR_{jj'})-RESID =  \\frac\n{\\ln[\\frac{n_{11}n_{00}}{n_{10}n_{01}}]-\\ln[\\frac{E(n_{11})E(n_{00})}{E(n_{10})E(n_{01})}]}\n{\\sqrt{\\frac{1}{n_{11}}+\\frac{1}{n_{10}}+\\frac{1}{n_{01}}+\\frac{1}{n_{00}}}}\n\nMantel-Haenszel statistic (MH; Agresti, 2002; Sinharay et al., 2006) \nMH_{jj'} = \\frac{\\sum_rn_{11r}n_{00r}/n_r}{\\sum_rn_{10r}n_{01r}/n_r}\n where counts of examinees with a response pattern are conditional on rest score r, defined as the total test score excluding items j and j’."
  },
  {
    "objectID": "posts/2023-06-10-latent-class-model-batch-mplus-using-r-on-mac/index.en.html#requirement",
    "href": "posts/2023-06-10-latent-class-model-batch-mplus-using-r-on-mac/index.en.html#requirement",
    "title": "Latent Class Model: Batch Mplus using R on Mac",
    "section": "Requirement",
    "text": "Requirement\nTo make sure Mplus can been successfully called in R, the very first thing is checking whether your MacOS can use command-line version of Mplus. Simply type Mplus command in your terminal app on Mac, if you see “Mplus VERSION (Mac)”, then Mplus on MacOS should work and can be called within R. Otherwise, you should check whether you install Mplus software successfully beforehand.\n\nSecond, you should install R + Rstudio (Optional). Rstudio is optional but strongly recommended.\nThird, MplusAutomation package should also been installed in R:\n\nif(!require(MplusAutomation)) install.packages(\"MplusAutomation\")\nlibrary(tidyverse)\nlibrary(purrr) # for map functions\nlibrary(furrr) # for parallel map\n\nIf everything looks good, we are ready to go."
  },
  {
    "objectID": "posts/2023-06-10-latent-class-model-batch-mplus-using-r-on-mac/index.en.html#latent-class-analysis",
    "href": "posts/2023-06-10-latent-class-model-batch-mplus-using-r-on-mac/index.en.html#latent-class-analysis",
    "title": "Latent Class Model: Batch Mplus using R on Mac",
    "section": "Latent Class Analysis",
    "text": "Latent Class Analysis\nA vanilla Mplus input file for latent class model look like followings:\n\nTITLE:\nBatch Analysis of Latent Class Models;\nDATA:\nFILE = \"Code/Mplus/datFile.dat\";\n \nVARIABLE:\nNAMES = Male Age Chinese EduF_Med EduF_High EduM_Med EduM_High EduS_Med EduS_High YM\n     HY SD PSD YASB YRCS YO YCR SEN Subgroup CE1 SC1 SI1 YCDC1 CLDH1; \n MISSING=.;\n \n      CATEGORICAL = Male-SEN;\n      CLASSES = c(10);\n      AUXILIARY = CE1-CLDH1 (R3STEP);\n      \nANALYSIS:\n\n      TYPE = MIXTURE;\n      \nOUTPUT:\nTECH1 TECH8 TECH11;\nSAVEDATA:\n\n      FILE IS model1_savedata.txt;\n      SAVE IS cprob;\n      FORMAT IS free;\n\nIt looks very cumbersome to write one by one line by hand. For example, VARIABLE > NAMES in Mplus input file contains all indicators and auxiliary variables used for latent class modeling. Any typos may give rise to Mplus throwing out error messages in the estimation.\nThankfully, there’s no need to write the Mplus syntax manually in text editor. Instead, you can write R code to automatically compile Mplus input files for you. In the following sections, I will illustrate how to do that using a real example.\nAn example\nThe example makes use of a data set including nine variables of demographic variables of youth, such as gender, age, ethnicity, education levels for father, mother and self etc. The goal is to cluster youth into multiple latent classes based on their demographic characteristics.\n\ndat <- read.csv(\"exampleDat.csv\", row.names = \"X\")\nglimpse(dat)\n\nRows: 2,175\nColumns: 9\n$ Male      <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, …\n$ Age       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Chinese   <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ EduF_Med  <int> 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, …\n$ EduF_High <int> 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, …\n$ EduM_Med  <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ EduM_High <int> 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, …\n$ EduS_Med  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ EduS_High <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nUsing mplusObject function, we can create a R object (or a Mplus model object stored in R), which holds all necessary sections for Mplus input syntax of latent class modeling. As shown in the code chunk below, users specify each Mplus section by assigning text strings to arguments. The only difference is that we don’t have to put variables’ names into a text file, instead, we can assign a R dataframe - dat to this model object directly. Then, it can be read by mplusModeler function later to run a latent class model with 2 latent classes.\nIn other words, we assigned text strings to three arguments -VARIABLE, ANALYSIS, SAVEDATA in mplusObject, which correspond to the sections in Mplus input file. Moreover, the most convenient part of MplusAutomation is allowing users to input variables’ names directly (usevariables = colnames(dat)). That is, rdata and usevariables arguments can be used to specify the variables’ names used for LCA in Mplus, which is equal to NAMES = in vanilla mplus input file.\nAfter we run and extract Mplus results using mplusModeler function, the next step is to parse and extract results from another Mplus model object with results - res_m1. Here, I’m interested in model fit indices of the model, then I can use get_summaries function in R to extract those information of this 2-class latent class model. Pretty neat, right?\n\n#------------#\n# 2-class model\n#------------#\nm1 <- mplusObject(\n  TITLE = \"Latent Class Models using R;\",\n  VARIABLE = \"\n  CATEGORICAL = Male-EduS_High;\n  CLASSES = c(2);\",\n  ANALYSIS = \"\n    TYPE = MIXTURE;\n    ALGORITHM = INTEGRATION;\n    STARTS = 500 20;\n  \",\n  SAVEDATA = \"\n    FILE IS LCA_M1_save.txt;\n    SAVE IS cprob;\n    FORMAT IS free;\n  \",\n  OUTPUT = \"TECH1 TECH8;\",\n  rdata = dat,\n  usevariables = colnames(dat),\n  autov = TRUE\n)\nsuppressWarnings(res_m1 <- mplusModeler(m1, modelout = \"Mplus/model.inp\", run = 1L))\nsummary_m1 <- get_summaries(res_m1, simplify = T)\nkbl(summary_m1, digits = 3) |> \n  kable_material_dark(full_width = F, html_font = \"Maven Pro\") |> \n  kable_styling(bootstrap_options = c(\"condensed\", \"hover\"))\n\n\n\n\n   \n    Model_1 \n  \n\n\n Mplus.version \n    8.7 \n  \n\n Title \n    Latent Class Models using R; \n  \n\n AnalysisType \n    MIXTURE \n  \n\n DataType \n    INDIVIDUAL \n  \n\n Estimator \n    MLR \n  \n\n Observations \n    2175 \n  \n\n NGroups \n    1 \n  \n\n NDependentVars \n    9 \n  \n\n NIndependentVars \n    0 \n  \n\n NContinuousLatentVars \n    0 \n  \n\n NCategoricalLatentVars \n    1 \n  \n\n Parameters \n    19 \n  \n\n ChiSqCategoricalPearson_Value \n    2255.894 \n  \n\n ChiSqCategoricalPearson_DF \n    491 \n  \n\n ChiSqCategoricalPearson_PValue \n    0 \n  \n\n ChiSqCategoricalLRT_Value \n    1669.323 \n  \n\n ChiSqCategoricalLRT_DF \n    491 \n  \n\n ChiSqCategoricalLRT_PValue \n    0 \n  \n\n ChiSqMCARUnrestrictedPearson_Value \n    54.839 \n  \n\n ChiSqMCARUnrestrictedPearson_DF \n    637 \n  \n\n ChiSqMCARUnrestrictedPearson_PValue \n    1 \n  \n\n ChiSqMCARUnrestrictedLRT_Value \n    26.06 \n  \n\n ChiSqMCARUnrestrictedLRT_DF \n    637 \n  \n\n ChiSqMCARUnrestrictedLRT_PValue \n    1 \n  \n\n LL \n    -8527.781 \n  \n\n LLCorrectionFactor \n    1.0086 \n  \n\n AIC \n    17093.562 \n  \n\n BIC \n    17201.573 \n  \n\n aBIC \n    17141.207 \n  \n\n Entropy \n    0.936 \n  \n\n AICC \n    17093.9146682135 \n  \n\n Filename \n    model.out \n  \n\n NLatentClasses \n    2 \n  \n\n\n\n\nThis is a simplistic procedure for one model. What about a bunch of models?\nBatch LCA in R: select number of latent classes\nOne most important step of latent class analysis is to select the number of latent classes, which best summarize the data. This research question can be translated to “when we have multiple alternative latent class models with different number of latent class (C), which one has optimal model fit”. The general rule of model selection is using information criterion such as AIC, BIC. Alternatively, model comparison method such as likelihood ratio test can be used to compare nested models. Here, I created a function to batch run multiple LCA across different number of classes to select the optimal models.\n\nfitMplus <- function(data = dat, class, \n                     uvars = \"Male-EduS_High\", auxvars= NULL, \n                     modelout = NULL, savedata = NULL ) {\n  ## specify the used variables\n  fitIndices <- c(\"LL\", \"AIC\", \"BIC\", \"aBIC\", \"Entropy\", \"T11_LMR_PValue\")\n  \n  if (is.null(savedata)) {\n    savedata = \"Mplus/model_Temp_save.txt\"\n  }\n  \n  if (!is.null(auxvars)) {\n    start_index = which(colnames(data) == str_split(uvars, \"-\")[[1]][1])\n    end_index = which(colnames(data) == str_split(auxvars, \"-\")[[1]][2])\n    modelTEMP <- mplusObject(\n      TITLE = \"Batch Analysis of Latent Class Models;\",\n      VARIABLE = paste0(\"\n      CATEGORICAL = \", uvars, \";\n      CLASSES = c(\", class, \");\n      AUXILIARY = \", auxvars,\" (R3STEP);\n      \"),\n      ANALYSIS = \"\n      TYPE = MIXTURE;\n      \",\n      SAVEDATA = \n      paste0(\"\n      FILE IS \", savedata,\";\n      SAVE IS cprob;\n      FORMAT IS free;\n      \"),\n      OUTPUT = \"TECH1 TECH8 TECH11;\",\n      rdata = data,\n      usevariables = colnames(data[start_index:end_index]),\n      autov = TRUE\n    )\n  }else{\n    start_index = which(colnames(data) == str_split(uvars, \"-\")[[1]][1])\n    end_index = which(colnames(data) == str_split(uvars, \"-\")[[1]][2])\n    modelTEMP <- mplusObject(\n      TITLE = \"Batch Analysis of Latent Class Models;\",\n      VARIABLE = paste0(\"\n      CATEGORICAL = \", uvars, \";\n      CLASSES = c(\", class, \");\n      \"),\n      ANALYSIS = \"\n      TYPE = MIXTURE;\n      \",\n      SAVEDATA = \n      paste0(\"\n      FILE IS \", savedata,\";\n      SAVE IS cprob;\n      FORMAT IS free;\n      \"),\n      OUTPUT = \"TECH1 TECH8 TECH11;\",\n      rdata = data,\n      usevariables = colnames(data[start_index:end_index]),\n      autov = TRUE\n    )\n  }\n  \n  if (!is.null(modelout)) {\n    suppressMessages(resTEMP <- mplusModeler(modelTEMP, modelout = modelout, run = 1L))\n  }else{\n    suppressMessages(resTEMP <- mplusModeler(modelTEMP, modelout = \"Mplus/modelTEMP.inp\", run = 1L))\n  }\n  \n  summaryTEMP <- get_summaries(resTEMP, simplify = T)\n  summaryTEMP <- data.frame(X = unlist(summaryTEMP[rownames(summaryTEMP) %in% fitIndices, ]))\n  colnames(summaryTEMP) = paste0(class, \"-class Model\")\n  \n  # return\n  list(\n    model = resTEMP,\n    summary = t(summaryTEMP)  \n  )\n}\n\nThen, I ran a series of latent class models with different number of classes (from 2 to 7 latent classes):\n\nlcmFit = as.data.frame(Reduce(rbind, future_map(\n  2:7, \\(x) fitMplus(data = dat, class = x, \n                     uvars = \"Male-EduS_High\",\n                     modelout = \"Mplus/model1fit.inp\",\n                     savedata = \"Mplus/model_Temp_save.txt\")$summary\n)))\nknitr::kable(lcmFit, digits = 3) |> \n  kable_material_dark(full_width = F, html_font = \"Maven Pro\") |> \n  kable_styling(bootstrap_options = c(\"condensed\", \"hover\"))\n\n\n\n\n   \n    LL \n    AIC \n    BIC \n    aBIC \n    Entropy \n    T11_LMR_PValue \n  \n\n\n 2-class Model \n    -8527.781 \n    17093.56 \n    17201.57 \n    17141.21 \n    0.936 \n    0 \n  \n\n 3-class Model \n    -8240.625 \n    16539.25 \n    16704.11 \n    16611.97 \n    0.952 \n    0 \n  \n\n 4-class Model \n    -8049.198 \n    16176.40 \n    16398.10 \n    16274.19 \n    0.969 \n    0 \n  \n\n 5-class Model \n    -7978.962 \n    16055.92 \n    16334.48 \n    16178.80 \n    0.951 \n    0 \n  \n\n 6-class Model \n    -7917.136 \n    15952.27 \n    16287.67 \n    16100.22 \n    0.990 \n    0 \n  \n\n 7-class Model \n    -7849.506 \n    15837.01 \n    16229.26 \n    16010.04 \n    0.934 \n    0 \n  \n\n\n\n\nAs the table shown, 7-class model appears to have the best model fit among 6 alternative models (lowest AIC/BIC/aBIC)."
  },
  {
    "objectID": "posts/2023-06-10-latent-class-model-batch-mplus-using-r-on-mac/index.en.html#conclusion",
    "href": "posts/2023-06-10-latent-class-model-batch-mplus-using-r-on-mac/index.en.html#conclusion",
    "title": "Latent Class Model: Batch Mplus using R on Mac",
    "section": "Conclusion",
    "text": "Conclusion\nMplusAutomation + R could be good tools for LCA. However, extracting information from Mplus output file is not so easy. For example, when there are auxiliary variables exists, the regression coefficients regressed on latent classes needed to be parsed and extract manually. For example, following functions can be used to extract the regression coefficients of latent class model using the 3-step approach.\n\n#------------#\n# Extract output regression table from R3Step LCA\n#------------#\nextract_r3step <- function(model_path){\n  # browser()\n  tibble(x = read_lines(model_path)) %>%\n    mutate(row1 = (1:n())[str_detect(x, 'NUMBER OF OBSERVATIONS USED')],\n           row2 = (1:n())[str_detect(x, \n                                     '^ODDS RATIOS FOR TESTS OF CATEGORICAL LATENT VARIABLE')]) %>%\n    slice((.$row1[1] + 2):(.$row2[1] - 1)) %>%\n    mutate(type_comparison = str_detect(x, 'Parameterization using Reference'),\n           type_colname = str_detect(x, 'Estimate'),\n           type_classnum = str_detect(x, 'C#[0-9]+'),\n           type_predictor = str_detect(x, '[\\\\.\\\\-0-9]+[\\\\s]+[\\\\.\\\\-0-9]+')) %>%\n    mutate(class = ifelse(type_classnum, parse_number(x), NA),\n           predictors = ifelse(type_predictor, map(x, parse_predictors), list()),\n           comparison_group = cumsum(type_comparison)) %>%\n    group_by(comparison_group) %>%\n    mutate(class_group = cumsum(type_classnum)) %>%\n    ungroup() %>%\n    mutate(comparison_group = ifelse(comparison_group == 0, \n                                     max(class, na.rm = TRUE), comparison_group)) %>%\n    group_by(comparison_group, class_group) %>%\n    filter(class_group != 0) %>%\n    mutate(class_group2 = class[!is.na(class)]) %>%\n    ungroup() %>%\n    filter(type_predictor) %>%\n    select(comparison_group, class_group2, predictors) %>%\n    unnest() %>%\n    rename(comparison_class = comparison_group,\n           class = class_group2) %>%\n    mutate(estimate = as.numeric(estimate),\n           se = as.numeric(se),\n           tval = as.numeric(tval),\n           pval = as.numeric(pval)) \n}\n  \n#------------#\n# Read in save data from Mplus\n#------------#\nread_saveddata <- function(path_output, path_savedata, ...) {\n  ## extract data and latent classes\n  mplusOuput <- readLines(path_output)\n  top <- which(str_detect(mplusOuput, \"Order of variables\")) # start linenumber\n  bottom <- which(str_detect(mplusOuput, \"Save file format\")) # end linenumber\n  rawVars <- mplusOuput[(top+1):(bottom-1)]\n  savevarnames <- trimws(rawVars[rawVars != \"\"])\n  \n  ## read saved data from Mplus output\n  savedDat <- read.table(path_savedata, na.strings = \"*\", header = FALSE, \n                         col.names = savevarnames, ...)\n  savedDat\n}\n\nHope this is helpful."
  },
  {
    "objectID": "posts/2022-05-12-web-scrapping-grant-fundings-in-r/index.en.html",
    "href": "posts/2022-05-12-web-scrapping-grant-fundings-in-r/index.en.html",
    "title": "Web Scraping Academia Institute’s Grant Fundings using R",
    "section": "",
    "text": "This is an example of how to web scrape grants of active research in college’s official website. Please follow the academia institute’s website robots rules."
  },
  {
    "objectID": "posts/2022-05-12-web-scrapping-grant-fundings-in-r/index.en.html#web-scrapping",
    "href": "posts/2022-05-12-web-scrapping-grant-fundings-in-r/index.en.html#web-scrapping",
    "title": "Web Scraping Academia Institute’s Grant Fundings using R",
    "section": "Web Scrapping",
    "text": "Web Scrapping\n\ntopics = rep(NA, 84)\nfundings = rep(NA, 84)\niter = 0\nfor (page in 1:9) {\n  ## parent webpage\n  scrape_url <- paste0('http://XXXXXXXXXXXXXXXXXXXXXX', page)\n  \n  html_form_page <- read_html(scrape_url)\n  \n  ## find the child web page containing projects' name, total award, topic etc.\n  child_url = html_form_page |> html_elements(\"h3 a[href]\") |> html_attr(\"href\") \n  \n  for (item in 1:length(child_url)) {\n    iter = iter + 1\n    child_html_text <- child_url[item] |> read_html() |> html_elements(\"div[class='study_wrapper']\") |> html_text() \n    topic = child_html_text |> str_extract(pattern = \"Topic\\\\(s\\\\)\\\\: [a-zA-Z]+\\\\b\") |> str_replace(pattern = \"Topic\\\\(s\\\\)\\\\: \", \"\")\n    funding = child_html_text |> str_extract(pattern = \"\\\\$\\\\d+\\\\,\\\\d+\") |> str_replace_all(pattern = \"\\\\$|\\\\,\", \"\") |> as.numeric()\n    topics[iter] = topic\n    fundings[iter] = funding\n  }\n}\n\ndat <- data.frame(topic = topics, funding_amount = fundings) |> \n  add_row(topic = \"Marijuana\", funding_amount = 3743) |> \n  mutate(topic = ifelse(topic == \"TobaccoMarijuana\", \"Tobacco\", topic)) \n\n\n\n\n\n\n\n\n\n topic \n    funding_amount \n  \n\n\n Tobacco \n    1271 \n  \n\n Cancer \n    NA \n  \n\n Other \n    98462 \n  \n\n Other \n    25000 \n  \n\n Other \n    64614 \n  \n\n Other \n    75000 \n  \n\n Other \n    72972 \n  \n\n Cancer \n    329234 \n  \n\n Tobacco \n    3072 \n  \n\n Other \n    49860"
  },
  {
    "objectID": "posts/2022-05-12-web-scrapping-grant-fundings-in-r/index.en.html#visualization-in-ggplot2",
    "href": "posts/2022-05-12-web-scrapping-grant-fundings-in-r/index.en.html#visualization-in-ggplot2",
    "title": "Web Scraping Academia Institute’s Grant Fundings using R",
    "section": "Visualization in ggplot2",
    "text": "Visualization in ggplot2\n\n## funding per project\ndat1 <- dat |> \n  group_by(topic) |> \n  summarise(funding_amount_mean = mean(funding_amount, na.rm = T)) |> \n  mutate(topic = fct_reorder(topic, desc(funding_amount_mean)))\n\nggplot(dat1) +\n  aes(x = topic, y = funding_amount_mean) +\n  geom_col(fill = \"darkblue\") +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\", scale = 1e-6)) +\n  labs(y = \"funding per project\", title = \"Funding for each project during 2019 to 2022\") +\n  theme(legend.position = \"none\", text = element_text(size = 12)) # remove lengend\n\n\n\n\n\n\n\n\n## Total funding amount\ndat2 <- dat |> \n  group_by(topic) |> \n  summarise(\n    funding_amount_sum = sum(funding_amount, na.rm = T), \n    n = n()) |> \n  mutate(\n    topic = fct_reorder(topic, desc(funding_amount_sum)),\n    highlight = ifelse(funding_amount_sum == max(funding_amount_sum), 1, 0) |> as.factor())\n\nggplot(dat2) +\n  aes(x = topic, y = funding_amount_sum, fill = highlight) +\n  geom_col() +\n  geom_text(aes(label = round(funding_amount_sum/ 10^6, 3)), vjust = 0.001, size = 5) +\n  geom_label(aes(label = n), vjust = 0.999, size = 5, color = \"white\") +\n  scale_fill_manual(values = c(\"darkblue\", \"red2\")) +\n  labs(x = \"\", y = \"total amount of funding\", \n       title = \"Total Amount of Funding and Number of Grant Projects during 2019-2022\", \n       subtitle = \"Active research at Health Promotion Center from 2019 to 2022\",\n       caption = \"source: https://healthpromotionresearch.org/Active-Studies/\") +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\", scale = 1e-6)) +\n  theme(legend.position = \"none\", text = element_text(size = 10)) # remove lengend"
  },
  {
    "objectID": "posts/2017-11-23-Latent-Profile-Analysis/index.en.html",
    "href": "posts/2017-11-23-Latent-Profile-Analysis/index.en.html",
    "title": "Latent Profile Analysis using MCLUST (in R)",
    "section": "",
    "text": "Import data and load packages\n\nlibrary(tidyverse)\nlibrary(mclust)\nlibrary(hrbrthemes) # typographic-centric ggplot2 themes\n\n\ndata(\"iris\")\ndf <- select(iris, -Species) # 4 variables\n\nexplore_model_fit <- function(df, n_profiles_range = 1:9, \n                              model_names = c(\"EII\", \"VVI\", \"EEE\", \"VVV\")) {\n    x <- mclustBIC(df, G = n_profiles_range, modelNames = model_names)\n    y <- x %>%\n        as.data.frame.matrix() %>%\n        rownames_to_column(\"n_profiles\") %>%\n        rename(`Constrained variance, fixed covariance` = EII, \n               `Freed variance, fixed covariance` = VVI,\n               `Constrained variance, constrained covariance` = EEE,\n               `Freed variance, freed covariance` = VVV)\n    y\n}\n\nfit_output <- explore_model_fit(df, n_profiles_range = 1:6)\n\nlibrary(forcats)\n\nto_plot <- fit_output %>%\n    gather(`Covariance matrix structure`, val, -n_profiles) %>% \n    mutate(\n      `Covariance matrix structure` = as.factor(`Covariance matrix structure`\n                                                ),\n      val = abs(val)) \n# this is to make the BIC values positive (to align with more common formula / interpretation of BIC)\n\n\nggplot(to_plot, aes(x = n_profiles, y = val, color = `Covariance matrix structure`, group = `Covariance matrix structure`)) +\n    geom_line() +\n    geom_point() +\n    ylab(\"BIC (smaller value is better)\") +\n    theme_ipsum_rc()\n\n\n\n\nFrom red to purple, the models become less constrained (more free). It appears that a two or three profile (mixture component) model with freely-estimated residual variances and covariances, or a four profile model with constrained residual covariances and variances, fit best (based on interpreting the BIC).\nGiven this, we can fit (and inspect) a model, say, the three profile model with freely-estimated residual variance and covariances.\n\ncreate_profiles_mclust <- function(df,\n                                   n_profiles, \n                                   variance_structure = \"freed\",\n                                   covariance_structure = \"freed\"){\n    \n    if (variance_structure == \"constrained\" & covariance_structure == \"fixed\") {\n        \n        model_name <- \"EEI\"\n        \n    } else if (variance_structure == \"freed\" & covariance_structure == \"fixed\") {\n        \n        model_name <- \"VVI\"\n        \n    } else if (variance_structure == \"constrained\" & covariance_structure == \"constrained\") {\n        \n        model_name <- \"EEE\"\n        \n    } else if (variance_structure == \"freed\" & covariance_structure == \"freed\") {\n        \n        model_name <- \"VVV\"\n        \n    } else if (variance_structure == \"fixed\") {\n        \n        stop(\"variance_structure cannot equal 'fixed' using this function; change this to 'constrained' or 'freed' or try one of the models from mclust::Mclust()\")\n        \n    } \n    \n    x <- Mclust(df, G = n_profiles, modelNames = model_name)\n    \n    print(summary(x))\n    \n    dff <- bind_cols(df, classification = x$classification)\n    \n    proc_df <- dff %>%\n        mutate_at(vars(-classification), scale) %>%\n        group_by(classification) %>%\n        summarize_all(funs(mean)) %>%\n        mutate(classification = paste0(\"Profile \", 1:n_profiles)) %>%\n        mutate_at(vars(-classification), function(x) round(x, 3)) %>%\n        rename(profile = classification)\n    \n    return(proc_df)\n    \n}\n\nm3 <- create_profiles_mclust(df, 3, variance_structure = \"freed\", covariance_structure = \"freed\")\n\n---------------------------------------------------- \nGaussian finite mixture model fitted by EM algorithm \n---------------------------------------------------- \n\nMclust VVV (ellipsoidal, varying volume, shape, and orientation) model with 3\ncomponents: \n\n log-likelihood   n df       BIC       ICL\n      -180.1858 150 44 -580.8396 -584.0522\n\nClustering table:\n 1  2  3 \n50 45 55 \n\n\nWe can then plot the mean values for the variables used to estimate the model for each of the two profiles. Of course, there are other models that we may want to inspect with different covariance matrix structures or profile numbers.\n\nm3 %>%\n    gather(key, val, -profile) %>% \n    ggplot(aes(x = profile, y = val, fill = key, group = key)) +\n    geom_col(position = \"dodge\") +\n    ylab(\"Z-score\") +\n    xlab(\"\") +\n    scale_fill_discrete(\"\") +\n    theme_ipsum_rc()\n\n\n\n\nOne big question: Are the residual covariance structures correctly specified? There are a lot of possible specifications (see help file here). I think they are right, based on their definitions, inspecting their covariance matrices, and inspecting their plots. But they might not be."
  },
  {
    "objectID": "posts/2019-11-14-use-r-as-a-bash/2019-11-14-use-r-as-a-bash.html",
    "href": "posts/2019-11-14-use-r-as-a-bash/2019-11-14-use-r-as-a-bash.html",
    "title": "Use R as a bash language",
    "section": "",
    "text": "Below is a simple example which allows to automate create a new blog post: (1) Ask users to type in filename, title and language (2) Create a new markdown file in specific directory (i.e. your local posts saved path) (3) Add some metadata in .md file (4) Open the file using your favorite markdown editor.\ncat('Your filename > ')\nfilename <- scan(file = \"stdin\", what = \"character\", n=1, sep = \"-\")\n\ncat(\"Your post's title > \")\ntitle <- scan(\"stdin\", what = \"character\", n=1, sep = \"-\")\n\ncat(\"language is zh or en > \")\nlang <- scan(\"stdin\", character(), n=1)\n\ndraft = TRUE\n\nmd.metadata =\n  paste0(\"---\ntitle: \", title,\"\ndate: \",Sys.Date(),\"\ndraft: \", tolower(draft) ,\"\ncategories:\n  - blog\ntags:\n  - Blog\n---\")\n\nif (lang == \"zh\"){\n  ## create a file name\n  postname = paste0(Sys.Date(), \"-\",gsub(\" \", \"-\", filename, fixed = TRUE), \".\" ,lang,\".md\")\n  ## Chinese Path\n   filepath = paste0(\n    \"/Users/jihong/Documents/hugo-academic-jihong/content/post/zh/\",\n    postname)\n\n   cmd = paste0(\"cd /Users/jihong/Documents/hugo-academic-jihong/content/post/zh/ && open \", postname)\n} else {\n  postname = paste0(Sys.Date(), \"-\",gsub(\" \", \"-\", filename, fixed = TRUE), \".md\")\n  ## English Path\n  filepath = paste0(\n    \"/Users/jihong/Documents/hugo-academic-jihong/content/post/\",\n    postname)\n\n  cmd = paste0(\"cd /Users/jihong/Documents/hugo-academic-jihong/content/post/ && open \", postname)\n}\n\n\nwrite.table(md.metadata, file = filepath, quote = FALSE, row.names = FALSE,col.names = FALSE)\n\nsystem(cmd)"
  },
  {
    "objectID": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html",
    "href": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html",
    "title": "How to do Data Cleaning in R",
    "section": "",
    "text": "This blog is trying to elaborate steps for cleaning the data. Since datasets varied, this blog could not cover all. Depedent on the data you’re using, different methods should be used."
  },
  {
    "objectID": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#libraries",
    "href": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#libraries",
    "title": "How to do Data Cleaning in R",
    "section": "Libraries",
    "text": "Libraries\nI use tidyverse as my main tool to clean the data. Tidyverse is a very useful package created by Hadley. It includes several sub-packages, such as dplyr (data manipulation), tidyr (data transforming), readr (data import), ggplot2 (data visulization) etc. If you haven’t installed this package yet, please run install.packages(\"tidyverse\") in your R console.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#step-1-import-data",
    "href": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#step-1-import-data",
    "title": "How to do Data Cleaning in R",
    "section": "Step 1: Import Data",
    "text": "Step 1: Import Data\nIf your data is csv format, you could use read.csv() to import the data into R. Be careful to add stringsAsFactors = FALSE argument in the function, or all string variables will automate convert to factor by default. This will lead to some issues when you do further checking. # Configuration of Academic # Documentation: https://sourcethemes.com/academic/ # # This file is formatted using TOML syntax - learn more at https://learnxinyminutes.com/docs/toml/ # Each configuration section is defined by a name in square brackets (e.g. [outputs]).\n\ndat1 <- read.csv(\"nfl_2010-2017.csv\", stringsAsFactors = FALSE)"
  },
  {
    "objectID": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#step-2-initial-check",
    "href": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#step-2-initial-check",
    "title": "How to do Data Cleaning in R",
    "section": "Step 2: Initial Check",
    "text": "Step 2: Initial Check\nPerform some initial check before doing further manipulation. This step is to let you get familiar with you data and have a big picture on what you need to do next.\nStep 2.1: check variables\nstr() is a very useful fuction in R base package which provides you sample sizes, number of variabels, variables names, variabile types and several sample responses. In the sample data, there are 81,525 observations and 23 variables.\n\nstr(dat1)\n\n'data.frame':   81525 obs. of  23 variables:\n $ X           : int  1 2 3 4 5 6 7 8 9 10 ...\n $ name        : chr  \"Duce Staley\" \"Lamar Smith\" \"Tiki Barber\" \"Stephen Davis\" ...\n $ team        : chr  \"PHI\" \"MIA\" \"NYG\" \"WAS\" ...\n $ game_year   : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ game_week   : int  1 1 1 1 1 1 1 1 1 1 ...\n $ rush_att    : int  26 27 13 23 28 27 30 14 15 10 ...\n $ rush_yds    : int  201 145 144 133 124 119 110 109 88 87 ...\n $ rush_avg    : num  7.7 5.4 11.1 5.8 4.4 4.4 3.7 7.8 5.9 8.7 ...\n $ rush_tds    : int  1 1 2 1 1 0 1 0 0 1 ...\n $ rush_fumbles: int  0 1 0 0 1 0 0 0 0 0 ...\n $ rec         : int  4 1 3 4 6 4 6 2 2 NA ...\n $ rec_yds     : int  61 12 25 37 40 32 34 3 20 NA ...\n $ rec_avg     : num  15.3 12 8.3 9.3 6.7 8 5.7 1.5 10 NA ...\n $ rec_tds     : int  0 0 0 0 1 0 1 0 0 NA ...\n $ rec_fumbles : int  0 0 0 0 0 0 0 0 0 NA ...\n $ pass_att    : int  NA NA NA NA NA NA NA NA NA 41 ...\n $ pass_yds    : int  NA NA NA NA NA NA NA NA NA 290 ...\n $ pass_tds    : int  NA NA NA NA NA NA NA NA NA 2 ...\n $ int         : int  NA NA NA NA NA NA NA NA NA 0 ...\n $ sck         : int  NA NA NA NA NA NA NA NA NA 2 ...\n $ pass_fumbles: int  NA NA NA NA NA NA NA NA NA 0 ...\n $ rate        : num  NA NA NA NA NA ...\n $ position    : chr  \"RB\" \"RB\" \"RB\" \"RB\" ...\n\n\nstep 2.2: check missing values and ranges\nMissing values could be checked one by one variables or in case-level. Knowing which one or more variablea have high missing values will help you think about the reasons.\n\nsummary(dat1)\n\n       X             name               team             game_year   \n Min.   :    1   Length:81525       Length:81525       Min.   :2000  \n 1st Qu.:20382   Class :character   Class :character   1st Qu.:2004  \n Median :40763   Mode  :character   Mode  :character   Median :2009  \n Mean   :40763                                         Mean   :2009  \n 3rd Qu.:61144                                         3rd Qu.:2013  \n Max.   :81525                                         Max.   :2017  \n                                                                     \n   game_week         rush_att        rush_yds         rush_avg     \n Min.   : 1.000   Min.   : 0.00   Min.   :-34.00   Min.   :-34.00  \n 1st Qu.: 4.000   1st Qu.: 1.00   1st Qu.:  4.00   1st Qu.:  2.00  \n Median : 9.000   Median : 4.00   Median : 15.00   Median :  3.50  \n Mean   : 8.592   Mean   : 6.96   Mean   : 28.91   Mean   :  4.05  \n 3rd Qu.:13.000   3rd Qu.:10.00   3rd Qu.: 42.00   3rd Qu.:  5.30  \n Max.   :16.000   Max.   :43.00   Max.   :296.00   Max.   : 77.00  \n                  NA's   :47710   NA's   :47710    NA's   :47710   \n    rush_tds      rush_fumbles        rec            rec_yds      \n Min.   :0.00    Min.   :0.00    Min.   : 0.000   Min.   :-22.00  \n 1st Qu.:0.00    1st Qu.:0.00    1st Qu.: 1.000   1st Qu.:  8.00  \n Median :0.00    Median :0.00    Median : 2.000   Median : 21.00  \n Mean   :0.21    Mean   :0.08    Mean   : 2.716   Mean   : 31.23  \n 3rd Qu.:0.00    3rd Qu.:0.00    3rd Qu.: 4.000   3rd Qu.: 45.00  \n Max.   :5.00    Max.   :3.00    Max.   :21.000   Max.   :329.00  \n NA's   :47710   NA's   :47710   NA's   :16722    NA's   :16722   \n    rec_avg          rec_tds       rec_fumbles       pass_att    \n Min.   :-22.00   Min.   :0.000   Min.   :0.000   Min.   : 0.00  \n 1st Qu.:  5.10   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:21.00  \n Median :  9.00   Median :0.000   Median :0.000   Median :30.00  \n Mean   : 10.15   Mean   :0.188   Mean   :0.032   Mean   :27.64  \n 3rd Qu.: 13.50   3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:37.00  \n Max.   : 99.00   Max.   :4.000   Max.   :2.000   Max.   :68.00  \n NA's   :16722    NA's   :16722   NA's   :16722   NA's   :71044  \n    pass_yds        pass_tds          int             sck       \n Min.   :-11.0   Min.   :0.00    Min.   :0.0     Min.   : 0.00  \n 1st Qu.:126.0   1st Qu.:0.00    1st Qu.:0.0     1st Qu.: 1.00  \n Median :204.0   Median :1.00    Median :1.0     Median : 2.00  \n Mean   :193.1   Mean   :1.16    Mean   :0.8     Mean   : 1.88  \n 3rd Qu.:267.0   3rd Qu.:2.00    3rd Qu.:1.0     3rd Qu.: 3.00  \n Max.   :527.0   Max.   :7.00    Max.   :7.0     Max.   :12.00  \n NA's   :71044   NA's   :71044   NA's   :71044   NA's   :71044  \n  pass_fumbles        rate          position        \n Min.   :0.00    Min.   :  0.00   Length:81525      \n 1st Qu.:0.00    1st Qu.: 60.20   Class :character  \n Median :0.00    Median : 82.10   Mode  :character  \n Mean   :0.15    Mean   : 81.57                     \n 3rd Qu.:0.00    3rd Qu.:103.20                     \n Max.   :3.00    Max.   :158.30                     \n NA's   :71044   NA's   :71044                      \n\n\nIn this sample, variables rush_att, rush_yds, rush_avg, rush_tds, rush_fumbles have 47,710 missing values; variables rec, rec_yds, rec_avg, rec_tds, rec_fumbles have 16,722 missing values, variables pass_att, pass_yds, pass_tds, int, sck, pass_fumbles, rate have 71,044 missing values.\nAlso, look at the range (Min., Max.) of variables in summary output, sometimes the responses may exceed expected range. You may have to delete those cases in this situation.\nstep 2.3: check first and last cases\nSometimes you may find the second row of data including some information you don’t want. For example, Qualtrics survey data will put some background log information in row 2. Thus, it’s better to check the head and tail of dataset. You can use functions below:\n\nhead(dat1)\n\n  X           name team game_year game_week rush_att rush_yds rush_avg rush_tds\n1 1    Duce Staley  PHI      2000         1       26      201      7.7        1\n2 2    Lamar Smith  MIA      2000         1       27      145      5.4        1\n3 3    Tiki Barber  NYG      2000         1       13      144     11.1        2\n4 4  Stephen Davis  WAS      2000         1       23      133      5.8        1\n5 5 Edgerrin James  IND      2000         1       28      124      4.4        1\n6 6  Priest Holmes  BAL      2000         1       27      119      4.4        0\n  rush_fumbles rec rec_yds rec_avg rec_tds rec_fumbles pass_att pass_yds\n1            0   4      61    15.3       0           0       NA       NA\n2            1   1      12    12.0       0           0       NA       NA\n3            0   3      25     8.3       0           0       NA       NA\n4            0   4      37     9.3       0           0       NA       NA\n5            1   6      40     6.7       1           0       NA       NA\n6            0   4      32     8.0       0           0       NA       NA\n  pass_tds int sck pass_fumbles rate position\n1       NA  NA  NA           NA   NA       RB\n2       NA  NA  NA           NA   NA       RB\n3       NA  NA  NA           NA   NA       RB\n4       NA  NA  NA           NA   NA       RB\n5       NA  NA  NA           NA   NA       RB\n6       NA  NA  NA           NA   NA       RB\n\ntail(dat1)\n\n          X           name team game_year game_week rush_att rush_yds rush_avg\n81520 81520     Jared Goff   LA      2017        15       NA       NA       NA\n81521 81521    Andy Dalton  CIN      2017        15       NA       NA       NA\n81522 81522 Trevor Siemian  DEN      2017        15       NA       NA       NA\n81523 81523  A.J. McCarron  CIN      2017        15       NA       NA       NA\n81524 81524 Derek Anderson  CAR      2017        16       NA       NA       NA\n81525 81525  Johnny Hekker   LA      2017        16       NA       NA       NA\n      rush_tds rush_fumbles rec rec_yds rec_avg rec_tds rec_fumbles pass_att\n81520       NA           NA  NA      NA      NA      NA          NA       21\n81521       NA           NA  NA      NA      NA      NA          NA       22\n81522       NA           NA  NA      NA      NA      NA          NA        9\n81523       NA           NA  NA      NA      NA      NA          NA        6\n81524       NA           NA  NA      NA      NA      NA          NA        1\n81525       NA           NA  NA      NA      NA      NA          NA        1\n      pass_yds pass_tds int sck pass_fumbles rate position\n81520      120        2   1   2            0 93.4       QB\n81521      113        0   2   3            0 27.3       QB\n81522       67        0   1   2            0 39.8       QB\n81523       19        0   0   0            0 56.9       QB\n81524        0        0   0   0            0 39.6    WR/TE\n81525        0        0   0   0            0 39.6    WR/TE\n\n\nThe R output provide first 6 cases and last 6 case. You can use head(dat1, 10) to output first 10 cases."
  },
  {
    "objectID": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#step-3-select-and-rename-variables",
    "href": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#step-3-select-and-rename-variables",
    "title": "How to do Data Cleaning in R",
    "section": "Step 3: Select and rename Variables",
    "text": "Step 3: Select and rename Variables\nAfter initial checks, some basic data cleaning could be done. You may want to select some variables you want and remove others. You can use select function to do that:\n\ndat2 <- dat1 %>% select(name, team, pass_att)\n\nI selected 3 variables (name, team, pass_att) from the dat1 and assign 3-variables data to “dat2”.\n\nhead(dat2)\n\n            name team pass_att\n1    Duce Staley  PHI       NA\n2    Lamar Smith  MIA       NA\n3    Tiki Barber  NYG       NA\n4  Stephen Davis  WAS       NA\n5 Edgerrin James  IND       NA\n6  Priest Holmes  BAL       NA\n\n\nTo rename the variables’ names, you could use set_names() from purrr packages.\n\ndat2 %>% purrr::set_names(nm = \"Players\", \"Team\", \"Pass_Attribute\") %>% head()\n\n         Players Team Pass_Attribute\n1    Duce Staley  PHI             NA\n2    Lamar Smith  MIA             NA\n3    Tiki Barber  NYG             NA\n4  Stephen Davis  WAS             NA\n5 Edgerrin James  IND             NA\n6  Priest Holmes  BAL             NA\n\ndat2 %>% purrr::set_names(nm = \"V1\", \"V2\", \"V3\") %>% head()\n\n              V1  V2 V3\n1    Duce Staley PHI NA\n2    Lamar Smith MIA NA\n3    Tiki Barber NYG NA\n4  Stephen Davis WAS NA\n5 Edgerrin James IND NA\n6  Priest Holmes BAL NA"
  },
  {
    "objectID": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#step-4-remove-missing-values",
    "href": "posts/2018-09-04-how-to-do-data-cleaning-in-r/index.en.html#step-4-remove-missing-values",
    "title": "How to do Data Cleaning in R",
    "section": "Step 4: Remove missing values",
    "text": "Step 4: Remove missing values\nIf you prefer cases with no missing cases at all. You can use the function below.\n\ndat_complete_cases <- dat2 %>% \n  filter_all(all_vars(!is.na(.)))\n\nsummary(dat_complete_cases)\n\n     name               team              pass_att    \n Length:10481       Length:10481       Min.   : 0.00  \n Class :character   Class :character   1st Qu.:21.00  \n Mode  :character   Mode  :character   Median :30.00  \n                                       Mean   :27.64  \n                                       3rd Qu.:37.00  \n                                       Max.   :68.00  \n\n\nOr if you want remove the cases whose Pass_Attribute is missing, you can use:\n\ndat_partialcomplete_cases <- dat2 %>% \n  filter(!is.na(pass_att))\n\nsummary(dat_complete_cases)\n\n     name               team              pass_att    \n Length:10481       Length:10481       Min.   : 0.00  \n Class :character   Class :character   1st Qu.:21.00  \n Mode  :character   Mode  :character   Median :30.00  \n                                       Mean   :27.64  \n                                       3rd Qu.:37.00  \n                                       Max.   :68.00  \n\n\nTo be continued…"
  },
  {
    "objectID": "posts/2017-11-20-Longitudinal-Effect-of-Motivation/index.html",
    "href": "posts/2017-11-20-Longitudinal-Effect-of-Motivation/index.html",
    "title": "Parental Involvement and Children Motivation",
    "section": "",
    "text": "Parental Involvement"
  },
  {
    "objectID": "posts/2017-11-20-Longitudinal-Effect-of-Motivation/index.html#what-is-parental-involvement",
    "href": "posts/2017-11-20-Longitudinal-Effect-of-Motivation/index.html#what-is-parental-involvement",
    "title": "Parental Involvement and Children Motivation",
    "section": "What is Parental Involvement?",
    "text": "What is Parental Involvement?\nParent involvement is considered as one of the most influential factors in education researches. Parents choose specific forms of involvement in response to the specific requests for involvement from children and the school.\nThe indicators of parent involvement in education vary considerably across studies, most of which treat parental involvement as a unidimensional construct. Some other study identified four dimensions of parental involvement (Sui-Chu, 1996). Some early studies conceived parental involvement as involving parents in school activities; More recent studies have emphasized parents’ actions at home, such as discussing their children’s experiences at school and helping children with their schoolwork.\n\nRelationship with Academic Achievement\nOne meta analysis of parental involvement and students’ academic achievement (Fan, 2001) suggest that the vast proportion of the literature in this area is qualitative and non-empirical. Among the empirical studies that have investigated the issue quantitatively, there appear to be considerable inconsistencies. The study indicates that a small to moderate, and piratically meaningful, relationship between parental involvement and academic achievement. Parental aspiration/expectation for children’s education achievement has the strongest relationship, whereas parental home supervision has the weakest relationship with students’ academic achievement. In addition, the relationship is stronger for global indicator (e.g. GPA) of academic achievement than a subject-specific indicator (e.g., math grade). Some other study also found that parents’ participation at school had a moderate effect on reading achievement, but a negligible effect on mathematics achievement.\n\n\nRelationship with Academic Motivation"
  },
  {
    "objectID": "posts/2017-11-20-Longitudinal-Effect-of-Motivation/index.html#academic-motivation",
    "href": "posts/2017-11-20-Longitudinal-Effect-of-Motivation/index.html#academic-motivation",
    "title": "Parental Involvement and Children Motivation",
    "section": "Academic Motivation",
    "text": "Academic Motivation"
  },
  {
    "objectID": "posts/2018-04-29-updateing-R/index.html",
    "href": "posts/2018-04-29-updateing-R/index.html",
    "title": "Updating R Version Without missing packages",
    "section": "",
    "text": "After updating to new R version (4.5) from old version, you have to re-install all packages by default. However, there’re some solution for that."
  },
  {
    "objectID": "posts/2018-04-29-updateing-R/index.html#unix-macos-linux",
    "href": "posts/2018-04-29-updateing-R/index.html#unix-macos-linux",
    "title": "Updating R Version Without missing packages",
    "section": "Unix (MacOs, Linux)",
    "text": "Unix (MacOs, Linux)\n1.Create a new folder in home directory to store the packages. Sometimes, you need to change the permission level for this folder, or R may not have access to write this folder. Rlibs is a special folder where you can store all you packages.\nsudo mkdir ~/Rlibs\n2.Edit the .Reviron file in your home directory (“~”) (create a new file if you don’t have it). Add the code below to let R know where is the installed Packages. R will read the configuration in the background from the path “~/.Reviron”.\nR_LIBS=~/Rlibs\n3.Re-install you packages. After that you shall see your packages are stored in Rlibs folder."
  },
  {
    "objectID": "posts/2018-09-12-manual-learn-jags-in-r/index.html",
    "href": "posts/2018-09-12-manual-learn-jags-in-r/index.html",
    "title": "[Manual]Using Jags and R2jags in R",
    "section": "",
    "text": "This post is aimed to introduce the basics of using jags in R programming. Jags is a frequently used program for conducting Bayesian statistics.Most of information below is borrowed from Jeromy Anglim’s Blog. I will keep editing this post if I found more resources about jags."
  },
  {
    "objectID": "posts/2018-09-12-manual-learn-jags-in-r/index.html#what-is-jags",
    "href": "posts/2018-09-12-manual-learn-jags-in-r/index.html#what-is-jags",
    "title": "[Manual]Using Jags and R2jags in R",
    "section": "What is JAGS?",
    "text": "What is JAGS?\nJAGS stands for Just Another Gibbs Sampler. To quote the program author, Martyn Plummer, “It is a program for analysis of Bayesian hierarchical models using Markov Chain Monte Carlo (MCMC) simulation…” It uses a dialect of the BUGS language, similar but a little different to OpenBUGS and WinBUGS."
  },
  {
    "objectID": "posts/2018-09-12-manual-learn-jags-in-r/index.html#installation",
    "href": "posts/2018-09-12-manual-learn-jags-in-r/index.html#installation",
    "title": "[Manual]Using Jags and R2jags in R",
    "section": "Installation",
    "text": "Installation\nTo run jags with R, There is an interface with R called rjags. 1. Download and install Jags based on your operating system. 2. Install additional R packages: type install.packages(c(“rjags”,”coda”)) in R console. rjags is to interface with JAGS and coda is to process MCMC output."
  },
  {
    "objectID": "posts/2018-09-12-manual-learn-jags-in-r/index.html#jags-examples",
    "href": "posts/2018-09-12-manual-learn-jags-in-r/index.html#jags-examples",
    "title": "[Manual]Using Jags and R2jags in R",
    "section": "JAGS Examples",
    "text": "JAGS Examples\nThere are a lot of examples online. The following provides links or simple codes to JAGS code.\n\nJustin Esarey\n\nAn entire course on Bayesian Statistics with examples in R and JAGS. It includes 10 lectures and each lecture lasts around 2 hours. The content is designed for a social science audience and it includes a syllabus linking with Simon Jackman’s text. The videos are linked from above or available direclty on YouTube.\n\n\nJeromy Anglim\n\nThe author of this blog also provides a few examples. He shared the codes on his github account\n\n\n\nJohn Myles White\n\nA course on statistical models that is under development with JAGS scripts on github.\nSimple introductory examples of fitting a normal distribution, linear regression, and logistic regression\nA follow-up post demonstrating the use of the coda package with rjags to perform MCMC diagnostics.\n\n\nA simple simulation sample:\n\nFirst, simulate the Data:\n\nlibrary(R2jags)\nn.sim <- 100; set.seed(123)\nx1 <- rnorm(n.sim, mean = 5, sd = 2)\nx2 <- rbinom(n.sim, size = 1, prob = 0.3)\ne <- rnorm(n.sim, mean = 0, sd = 1)\n\nNext, we create the outcome y based on coefficients b_1 and b_2 for the respective predictors and an intercept a:\n\nb1 <- 1.2\nb2 <- -3.1\na <- 1.5\ny <- b1*x1 + b2*x2 + e\n\nNow, we combine the variables into one dataframe for processing later:\n\nsim.dat <- data.frame(y, x1, x2)\n\nAnd we create and summarize a (frequentist) linear model fit on these data:\n\nfreq.mod <- lm(y ~ x1 + x2, data = sim.dat)\nsummary(freq.mod)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = sim.dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3432 -0.6797 -0.1112  0.5367  3.2304 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.34949    0.28810   1.213    0.228    \nx1           1.13511    0.05158  22.005   <2e-16 ***\nx2          -3.09361    0.20650 -14.981   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9367 on 97 degrees of freedom\nMultiple R-squared:  0.8772,    Adjusted R-squared:  0.8747 \nF-statistic: 346.5 on 2 and 97 DF,  p-value: < 2.2e-16\n\n\nBeyesian Model\n\nbayes.mod <- function() {\n for(i in 1:N){\n y[i] ~ dnorm(mu[i], tau)\n mu[i] <- alpha + beta1 * x1[i] + beta2 * x2[i]\n }\n alpha ~ dnorm(0, .01)\n beta1 ~ dunif(-100, 100)\n beta2 ~ dunif(-100, 100)\n tau ~ dgamma(.01, .01)\n}\n\nNow define the vectors of the data matrix for JAGS:\n\ny <- sim.dat$y\nx1 <- sim.dat$x1\nx2 <- sim.dat$x2\nN <- nrow(sim.dat)\n\nRead in the data frame for JAGS\n\nsim.dat.jags <- list(\"y\", \"x1\", \"x2\", \"N\")\n\nDefine the parameters whose posterior distributions you are interested in summarizing later:\n\nbayes.mod.params <- c(\"alpha\", \"beta1\", \"beta2\")\n\nSetting up starting values\n\nbayes.mod.inits <- function(){\n list(\"alpha\" = rnorm(1), \"beta1\" = rnorm(1), \"beta2\" = rnorm(1))\n}\n\n# inits1 <- list(\"alpha\" = 0, \"beta1\" = 0, \"beta2\" = 0)\n# inits2 <- list(\"alpha\" = 1, \"beta1\" = 1, \"beta2\" = 1)\n# inits3 <- list(\"alpha\" = -1, \"beta1\" = -1, \"beta2\" = -1)\n# bayes.mod.inits <- list(inits1, inits2, inits3)\n\nFitting the model\n\nset.seed(123)\nbayes.mod.fit <- jags(data = sim.dat.jags, inits = bayes.mod.inits,\n  parameters.to.save = bayes.mod.params, n.chains = 3, n.iter = 9000,\n  n.burnin = 1000, model.file = bayes.mod)\n\nmodule glm loaded\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 100\n   Unobserved stochastic nodes: 4\n   Total graph size: 511\n\nInitializing model\n\n\nDiagnostics\n\nprint(bayes.mod.fit)\n\nInference for Bugs model at \"/var/folders/9t/ryz7lf_s7ts720p_lwdttfhm0000gn/T//RtmpaqCD4J/modelc9a07e55a3b4.txt\", fit using jags,\n 3 chains, each with 9000 iterations (first 1000 discarded), n.thin = 8\n n.sims = 3000 iterations saved\n         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff\nalpha      0.362   0.293  -0.205   0.166   0.358   0.562   0.958 1.009   250\nbeta1      1.133   0.053   1.025   1.099   1.134   1.169   1.236 1.009   250\nbeta2     -3.090   0.205  -3.496  -3.231  -3.090  -2.950  -2.685 1.002  1700\ndeviance 271.830   2.899 268.167 269.718 271.122 273.198 279.223 1.000  3000\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 4.2 and DIC = 276.0\nDIC is an estimate of expected predictive error (lower deviance is better).\n\n\nplot(bayes.mod.fit)\n\n\n\ntraceplot(bayes.mod.fit)"
  },
  {
    "objectID": "posts/2021-08-30-gradient-descent-via-julia/index.en.html",
    "href": "posts/2021-08-30-gradient-descent-via-julia/index.en.html",
    "title": "Gradient Descent Algorithm via julia",
    "section": "",
    "text": "using RDatasets\nusing DataFrames\nmtcars = dataset(\"datasets\", \"mtcars\")\n\n\n32 rows × 12 columns (omitted printing of 4 columns)\n\n\n\n\n\n\n\n\nModel\n\n\nMPG\n\n\nCyl\n\n\nDisp\n\n\nHP\n\n\nDRat\n\n\nWT\n\n\nQSec\n\n\n\n\n\n\nString\n\n\nFloat64\n\n\nInt64\n\n\nFloat64\n\n\nInt64\n\n\nFloat64\n\n\nFloat64\n\n\nFloat64\n\n\n\n\n\n\n1\n\n\nMazda RX4\n\n\n21.0\n\n\n6\n\n\n160.0\n\n\n110\n\n\n3.9\n\n\n2.62\n\n\n16.46\n\n\n\n\n2\n\n\nMazda RX4 Wag\n\n\n21.0\n\n\n6\n\n\n160.0\n\n\n110\n\n\n3.9\n\n\n2.875\n\n\n17.02\n\n\n\n\n3\n\n\nDatsun 710\n\n\n22.8\n\n\n4\n\n\n108.0\n\n\n93\n\n\n3.85\n\n\n2.32\n\n\n18.61\n\n\n\n\n4\n\n\nHornet 4 Drive\n\n\n21.4\n\n\n6\n\n\n258.0\n\n\n110\n\n\n3.08\n\n\n3.215\n\n\n19.44\n\n\n\n\n5\n\n\nHornet Sportabout\n\n\n18.7\n\n\n8\n\n\n360.0\n\n\n175\n\n\n3.15\n\n\n3.44\n\n\n17.02\n\n\n\n\n6\n\n\nValiant\n\n\n18.1\n\n\n6\n\n\n225.0\n\n\n105\n\n\n2.76\n\n\n3.46\n\n\n20.22\n\n\n\n\n7\n\n\nDuster 360\n\n\n14.3\n\n\n8\n\n\n360.0\n\n\n245\n\n\n3.21\n\n\n3.57\n\n\n15.84\n\n\n\n\n8\n\n\nMerc 240D\n\n\n24.4\n\n\n4\n\n\n146.7\n\n\n62\n\n\n3.69\n\n\n3.19\n\n\n20.0\n\n\n\n\n9\n\n\nMerc 230\n\n\n22.8\n\n\n4\n\n\n140.8\n\n\n95\n\n\n3.92\n\n\n3.15\n\n\n22.9\n\n\n\n\n10\n\n\nMerc 280\n\n\n19.2\n\n\n6\n\n\n167.6\n\n\n123\n\n\n3.92\n\n\n3.44\n\n\n18.3\n\n\n\n\n11\n\n\nMerc 280C\n\n\n17.8\n\n\n6\n\n\n167.6\n\n\n123\n\n\n3.92\n\n\n3.44\n\n\n18.9\n\n\n\n\n12\n\n\nMerc 450SE\n\n\n16.4\n\n\n8\n\n\n275.8\n\n\n180\n\n\n3.07\n\n\n4.07\n\n\n17.4\n\n\n\n\n13\n\n\nMerc 450SL\n\n\n17.3\n\n\n8\n\n\n275.8\n\n\n180\n\n\n3.07\n\n\n3.73\n\n\n17.6\n\n\n\n\n14\n\n\nMerc 450SLC\n\n\n15.2\n\n\n8\n\n\n275.8\n\n\n180\n\n\n3.07\n\n\n3.78\n\n\n18.0\n\n\n\n\n15\n\n\nCadillac Fleetwood\n\n\n10.4\n\n\n8\n\n\n472.0\n\n\n205\n\n\n2.93\n\n\n5.25\n\n\n17.98\n\n\n\n\n16\n\n\nLincoln Continental\n\n\n10.4\n\n\n8\n\n\n460.0\n\n\n215\n\n\n3.0\n\n\n5.424\n\n\n17.82\n\n\n\n\n17\n\n\nChrysler Imperial\n\n\n14.7\n\n\n8\n\n\n440.0\n\n\n230\n\n\n3.23\n\n\n5.345\n\n\n17.42\n\n\n\n\n18\n\n\nFiat 128\n\n\n32.4\n\n\n4\n\n\n78.7\n\n\n66\n\n\n4.08\n\n\n2.2\n\n\n19.47\n\n\n\n\n19\n\n\nHonda Civic\n\n\n30.4\n\n\n4\n\n\n75.7\n\n\n52\n\n\n4.93\n\n\n1.615\n\n\n18.52\n\n\n\n\n20\n\n\nToyota Corolla\n\n\n33.9\n\n\n4\n\n\n71.1\n\n\n65\n\n\n4.22\n\n\n1.835\n\n\n19.9\n\n\n\n\n21\n\n\nToyota Corona\n\n\n21.5\n\n\n4\n\n\n120.1\n\n\n97\n\n\n3.7\n\n\n2.465\n\n\n20.01\n\n\n\n\n22\n\n\nDodge Challenger\n\n\n15.5\n\n\n8\n\n\n318.0\n\n\n150\n\n\n2.76\n\n\n3.52\n\n\n16.87\n\n\n\n\n23\n\n\nAMC Javelin\n\n\n15.2\n\n\n8\n\n\n304.0\n\n\n150\n\n\n3.15\n\n\n3.435\n\n\n17.3\n\n\n\n\n24\n\n\nCamaro Z28\n\n\n13.3\n\n\n8\n\n\n350.0\n\n\n245\n\n\n3.73\n\n\n3.84\n\n\n15.41\n\n\n\n\n25\n\n\nPontiac Firebird\n\n\n19.2\n\n\n8\n\n\n400.0\n\n\n175\n\n\n3.08\n\n\n3.845\n\n\n17.05\n\n\n\n\n26\n\n\nFiat X1-9\n\n\n27.3\n\n\n4\n\n\n79.0\n\n\n66\n\n\n4.08\n\n\n1.935\n\n\n18.9\n\n\n\n\n27\n\n\nPorsche 914-2\n\n\n26.0\n\n\n4\n\n\n120.3\n\n\n91\n\n\n4.43\n\n\n2.14\n\n\n16.7\n\n\n\n\n28\n\n\nLotus Europa\n\n\n30.4\n\n\n4\n\n\n95.1\n\n\n113\n\n\n3.77\n\n\n1.513\n\n\n16.9\n\n\n\n\n29\n\n\nFord Pantera L\n\n\n15.8\n\n\n8\n\n\n351.0\n\n\n264\n\n\n4.22\n\n\n3.17\n\n\n14.5\n\n\n\n\n30\n\n\nFerrari Dino\n\n\n19.7\n\n\n6\n\n\n145.0\n\n\n175\n\n\n3.62\n\n\n2.77\n\n\n15.5\n\n\n\n\n⋮\n\n\n⋮\n\n\n⋮\n\n\n⋮\n\n\n⋮\n\n\n⋮\n\n\n⋮\n\n\n⋮\n\n\n⋮"
  },
  {
    "objectID": "posts/2021-08-30-gradient-descent-via-julia/index.en.html#julia-function-for-gradient-descent",
    "href": "posts/2021-08-30-gradient-descent-via-julia/index.en.html#julia-function-for-gradient-descent",
    "title": "Gradient Descent Algorithm via julia",
    "section": "Julia Function for Gradient Descent",
    "text": "Julia Function for Gradient Descent\n\nlearn_rate: the magnitude of the steps the algorithm takes along the slope of the MSE function\nconv_threshold: threshold for convergence of gradient descent n: number of iternations\nmax_iter: maximum of iteration before the algorithm stopss\n\nfunction gradientDesc(x, y, learn_rate, conv_threshold, n, max_iter)\n    β = rand(Float64, 1)[1]\n    α = rand(Float64, 1)[1]\n    ŷ = α .+ β .* x\n    MSE = sum((y .- ŷ).^2)/n\n    converged = false\n    iterations = 0\n\n    while converged == false\n        # Implement the gradient descent algorithm\n        β_new = β - learn_rate*((1/n)*(sum((ŷ .- y) .* x)))\n        α_new = α - learn_rate*((1/n)*(sum(ŷ .- y)))\n        α = α_new\n        β = β_new\n        ŷ = β.*x .+ α\n        MSE_new = sum((y.-ŷ).^2)/n\n        # decide on whether it is converged or not\n        if (MSE - MSE_new) <= conv_threshold\n            converged = true\n            println(\"Optimal intercept: $α; Optimal slope: $β\")\n        end\n        iterations += 1\n        if iterations > max_iter\n            converged = true\n            println(\"Optimal intercept: $α; Optimal slope: $β\")\n        end\n    end\nend\ngradientDesc (generic function with 1 method)\ngradientDesc(mtcars[:,:Disp], mtcars[:,:MPG], 0.0000293, 0.001, 32, 2500000)\nOptimal intercept: 29.599851506041713; Optimal slope: -0.0412151089535404"
  },
  {
    "objectID": "posts/2021-08-30-gradient-descent-via-julia/index.en.html#compared-to-linear-regression",
    "href": "posts/2021-08-30-gradient-descent-via-julia/index.en.html#compared-to-linear-regression",
    "title": "Gradient Descent Algorithm via julia",
    "section": "Compared to linear regression",
    "text": "Compared to linear regression\nusing GLM\nlinearRegressor = lm(@formula(MPG ~ Disp), mtcars)\nStatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\nMPG ~ 1 + Disp\n\nCoefficients:\n───────────────────────────────────────────────────────────────────────────\n                  Coef.  Std. Error      t  Pr(>|t|)  Lower 95%   Upper 95%\n───────────────────────────────────────────────────────────────────────────\n(Intercept)  29.5999     1.22972     24.07    <1e-20  27.0884    32.1113\nDisp         -0.0412151  0.00471183  -8.75    <1e-09  -0.050838  -0.0315923\n───────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2019-10-08-handout-for-smep-poster/2019-10-08-handout-for-smep-poster.html",
    "href": "posts/2019-10-08-handout-for-smep-poster/2019-10-08-handout-for-smep-poster.html",
    "title": "SMEP 2019 Poster Session Materials",
    "section": "",
    "text": "See the handout and download the poster here."
  },
  {
    "objectID": "posts/2017-11-12-MESUREMENT-INVARIANCE/index.en.html",
    "href": "posts/2017-11-12-MESUREMENT-INVARIANCE/index.en.html",
    "title": "One Example of Measurement Invariance",
    "section": "",
    "text": "Recently, I was asked by my friend why should we use Measurement Invariance in real research. Why not just ignore this complex and tedious process? As far I’m concerned, measurement invariance should be widely used if you have large data scale and figure out what’s going on between groups difference. In this post, I want to elaborate some problems in Measurement Invariance: 1) What is measurement invariance 2) why should we care about measuremnet invariance 3) how to do measurement invariance using R Lavaan Package."
  },
  {
    "objectID": "posts/2017-11-12-MESUREMENT-INVARIANCE/index.en.html#multiple-group-cfa-invariance-example-data-from-brown-charpter-7",
    "href": "posts/2017-11-12-MESUREMENT-INVARIANCE/index.en.html#multiple-group-cfa-invariance-example-data-from-brown-charpter-7",
    "title": "One Example of Measurement Invariance",
    "section": "Multiple Group CFA Invariance Example (data from Brown Charpter 7):",
    "text": "Multiple Group CFA Invariance Example (data from Brown Charpter 7):\nMajor Deression Criteria across Men and Women (n =345)\n9 items rated by clinicians on a scale iof 0 to 8 (0=none, 8 =very severely disturbing/disabling)\n\nDepressed mood\nLoss of interest in usual activities\nWeight/appetite change\nSleep disturbance\nPsychomotor agitation/retardation\nFatigue/loss of energy\nFeelings of worthless/guilt\nConcentration difficulties\nThoughts of death/suicidality\n\nJonathan in his Meansurement Invariance Example elaborated the manual version so that learner could learn what you are doing first. I will show you how to use shortcuts.\nData Import\n\n\n\n\n\n  V1 V2 V3 V4 V5 V6 V7 V8 V9 V10\n1  0  5  4  1  6  5  6  5  4   2\n2  0  5  5  5  5  4  5  4  5   4\n3  0  4  5  4  2  6  6  0  0   0\n4  0  5  5  3  3  5  5  6  4   0\n5  0  5  5  0  5  0  4  6  0   0\n6  0  6  6  4  6  4  6  5  6   2\n\n\nThe sample size of female reference groups is as same as the male. The model for 2 groups should be same and check how many changes are allowed to differ.\nModel Specification\nmodel1.config <- \"\n# Constrain the factor loadings and intercepts of marker variable in ALL groups\n# depress =~ c(L1F, L1M)*item1 + c(L2F, L2M)*item2 + c(L3F, L3M)*item3 +\n#            c(L4F, L4M)*item4 + c(L5F, L5M)*item5 + c(L6F, L6M)*item6 + \n#            c(L7F, L7M)*item7 + c(L8F, L8M)*item8 + c(L9F, L9M)*item9\ndepress =~ item1 + item2 + item3 +\n           item4 + item5 + item6 + \n           item7 + item8 + item9\n\n#Item intercepts all freely estimated in both groups with label for each group\nitem1 ~ 1; item2 ~ 1; item3 ~ 1; \nitem4 ~ 1; item5 ~ 1; item6 ~ 1; \nitem7 ~ 1; item8 ~ 1; item9 ~ 1;\n\n#Redidual variances all freely estimated with label for each group\nitem1 ~~ item1; item2 ~~ item2; item3 ~~ item3; \nitem4 ~~ item4; item5 ~~ item5; item6 ~~ item6; \nitem7 ~~ item7; item8 ~~ item8; item9 ~~ item9;\n\n#Residual covariance freely estimated in both groups with label for each group\nitem1 ~~ item2\n\n#===================================================================================================\n#Factor variance fixed to 1 for identification in each group\ndepress ~~ c(1,NA)*depress\n\n#Factor mean fixed to zero for identification in each group\ndepress ~ c(0,NA)*0\n\"\nModel Options\nConfigural Invariance Model is the first-step model which allows all estimation different for two groups except that mean and variance of factor are fixed to 0 and 1, because the model uses z-score scalling.\nCompared to configural invariance, metic invariance model constrains the factor loadings for two groups equal with each other. To test metric invariance, we could use absolute model fit indices (CFI, TLI, RMSEA, SRMR) and comparable model fit indices (Log-likelihood test). It deserves noting that in metric invariance model, factor means are still constrained to be equal for two groups but the variances of factor are different. The variance of factor for reference group is fixed to 1 but that for other group is free to estimate. Since if we constrain both factor loadings and factor variances to equal, then the residual variances of items will also be equal. This is next step. Freeing one group’s factor variance will let model not too strict to Residual Variance.\nNext model is Scalar Invariance Model, which constrain the intercepts of items to be euqal.\n\nfit.config <- sem(model1.config, data = mddAll, \n                  meanstructure = T , std.lv = T,\n                  estimator = \"MLR\", mimic = \"mplus\",\n                  group = \"sex\",\n                  group.equal = c(\"lv.variances\", \"means\")) # latent variance both equal to 1\n                  \nfit.metric <- sem(model1.config, data = mddAll, \n                  meanstructure = T , std.lv = T,\n                  estimator = \"MLR\", mimic = \"mplus\",\n                  group = \"sex\",\n                  group.equal = c(\"loadings\", \"means\")) # factor mean should be equal to 0\nfit.scalar <- sem(model1.config, data = mddAll, \n                  meanstructure = T , std.lv = T,\n                  estimator = \"MLR\", mimic = \"mplus\",\n                  group = \"sex\",\n                  group.equal = c(\"loadings\",\"intercepts\"))\n# same: factor loadings, item intercepts\n# different: reference factor mean is 1, another factor mean is 0\n\nfit.scalar2 <- sem(model1.config, data = mddAll, \n                  meanstructure = T , std.lv = T,\n                  estimator = \"MLR\", mimic = \"mplus\",\n                  group = \"sex\",\n                  group.equal = c(\"loadings\",\"intercepts\"),\n                  group.partial = c(\"item7~1\"))\n\nfit.strict <- sem(model1.config, data = mddAll, \n                  meanstructure = T , std.lv = T,\n                  estimator = \"MLR\", mimic = \"mplus\",\n                  group = \"sex\",\n                  group.equal = c(\"loadings\",\"intercepts\", \"residuals\"),\n                  group.partial = c(\"item7~1\", \"item7~~item7\"))\nfit.strict.cov <- sem(model1.config, data = mddAll, \n                  meanstructure = T , std.lv = T,\n                  estimator = \"MLR\", mimic = \"mplus\",\n                  group = \"sex\",\n                  group.equal = c(\"loadings\",\"intercepts\", \"residuals\", \n                                  \"residual.covariances\"),\n                  group.partial = c(\"item7~1\", \"item7~~item7\"))\n\nRuning Model\n\nsummary(fit.config, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n\nlavaan 0.6.13 ended normally after 47 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        56\n\n  Number of observations per group:                   \n    Female                                         375\n    Male                                           375\n  Number of missing patterns per group:               \n    Female                                           1\n    Male                                             1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                98.911      94.175\n  Degrees of freedom                                52          52\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.050\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    Female                                      52.954      50.418\n    Male                                        45.957      43.756\n\nModel Test Baseline Model:\n\n  Test statistic                              1343.575    1218.364\n  Degrees of freedom                                72          72\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.103\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.963       0.963\n  Tucker-Lewis Index (TLI)                       0.949       0.949\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.965\n  Robust Tucker-Lewis Index (TLI)                            0.952\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -13706.898  -13706.898\n  Scaling correction factor                                  0.981\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -13657.442  -13657.442\n  Scaling correction factor                                  1.014\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               27525.796   27525.796\n  Bayesian (BIC)                             27784.520   27784.520\n  Sample-size adjusted Bayesian (SABIC)      27606.698   27606.698\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.049       0.047\n  90 Percent confidence interval - lower         0.034       0.031\n  90 Percent confidence interval - upper         0.064       0.061\n  P-value H_0: RMSEA <= 0.050                    0.522       0.636\n  P-value H_0: RMSEA >= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.048\n  90 Percent confidence interval - lower                     0.032\n  90 Percent confidence interval - upper                     0.063\n  P-value H_0: Robust RMSEA <= 0.050                         0.581\n  P-value H_0: Robust RMSEA >= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.039       0.039\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\n\nGroup 1 [Female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1             1.251    0.095   13.155    0.000    1.251    0.730\n    item2             1.385    0.103   13.426    0.000    1.385    0.688\n    item3             0.911    0.104    8.775    0.000    0.911    0.435\n    item4             1.140    0.115    9.874    0.000    1.140    0.516\n    item5             1.015    0.106    9.615    0.000    1.015    0.477\n    item6             1.155    0.103   11.238    0.000    1.155    0.577\n    item7             0.764    0.115    6.618    0.000    0.764    0.371\n    item8             1.224    0.113   10.817    0.000    1.224    0.569\n    item9             0.606    0.094    6.412    0.000    0.606    0.339\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.393    0.166    2.364    0.018    0.393    0.230\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             4.184    0.089   47.258    0.000    4.184    2.440\n   .item2             3.725    0.104   35.848    0.000    3.725    1.851\n   .item3             1.952    0.108   18.058    0.000    1.952    0.933\n   .item4             3.589    0.114   31.458    0.000    3.589    1.624\n   .item5             2.256    0.110   20.522    0.000    2.256    1.060\n   .item6             3.955    0.103   38.237    0.000    3.955    1.975\n   .item7             3.869    0.106   36.382    0.000    3.869    1.879\n   .item8             3.595    0.111   32.331    0.000    3.595    1.670\n   .item9             1.205    0.092   13.053    0.000    1.205    0.674\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             1.375    0.194    7.090    0.000    1.375    0.468\n   .item2             2.132    0.236    9.049    0.000    2.132    0.527\n   .item3             3.551    0.201   17.678    0.000    3.551    0.810\n   .item4             3.583    0.272   13.166    0.000    3.583    0.734\n   .item5             3.501    0.223   15.733    0.000    3.501    0.773\n   .item6             2.677    0.269    9.967    0.000    2.677    0.667\n   .item7             3.658    0.276   13.270    0.000    3.658    0.862\n   .item8             3.137    0.291   10.785    0.000    3.137    0.677\n   .item9             2.831    0.195   14.538    0.000    2.831    0.885\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.532\n    item2             0.473\n    item3             0.190\n    item4             0.266\n    item5             0.227\n    item6             0.333\n    item7             0.138\n    item8             0.323\n    item9             0.115\n\n\nGroup 2 [Male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1             1.024    0.099   10.384    0.000    1.024    0.642\n    item2             1.266    0.112   11.283    0.000    1.266    0.628\n    item3             0.805    0.115    7.011    0.000    0.805    0.385\n    item4             1.193    0.123    9.729    0.000    1.193    0.535\n    item5             0.982    0.113    8.678    0.000    0.982    0.466\n    item6             1.159    0.116   10.010    0.000    1.159    0.549\n    item7             0.784    0.131    5.994    0.000    0.784    0.343\n    item8             1.043    0.121    8.610    0.000    1.043    0.480\n    item9             0.647    0.102    6.359    0.000    0.647    0.362\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.920    0.205    4.499    0.000    0.920    0.479\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             4.171    0.082   50.608    0.000    4.171    2.613\n   .item2             3.685    0.104   35.414    0.000    3.685    1.829\n   .item3             1.739    0.108   16.098    0.000    1.739    0.831\n   .item4             3.357    0.115   29.160    0.000    3.357    1.506\n   .item5             2.235    0.109   20.560    0.000    2.235    1.062\n   .item6             3.661    0.109   33.598    0.000    3.661    1.735\n   .item7             3.421    0.118   29.014    0.000    3.421    1.498\n   .item8             3.517    0.112   31.372    0.000    3.517    1.620\n   .item9             1.259    0.092   13.649    0.000    1.259    0.705\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             1.499    0.216    6.932    0.000    1.499    0.588\n   .item2             2.459    0.274    8.989    0.000    2.459    0.606\n   .item3             3.727    0.205   18.167    0.000    3.727    0.852\n   .item4             3.547    0.291   12.189    0.000    3.547    0.713\n   .item5             3.467    0.236   14.716    0.000    3.467    0.783\n   .item6             3.111    0.296   10.520    0.000    3.111    0.698\n   .item7             4.599    0.279   16.457    0.000    4.599    0.882\n   .item8             3.626    0.296   12.267    0.000    3.626    0.769\n   .item9             2.770    0.208   13.291    0.000    2.770    0.869\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.412\n    item2             0.394\n    item3             0.148\n    item4             0.287\n    item5             0.217\n    item6             0.302\n    item7             0.118\n    item8             0.231\n    item9             0.131\n\nsummary(fit.metric, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n\nlavaan 0.6.13 ended normally after 48 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        57\n  Number of equality constraints                     9\n\n  Number of observations per group:                   \n    Female                                         375\n    Male                                           375\n  Number of missing patterns per group:               \n    Female                                           1\n    Male                                             1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               102.839      99.532\n  Degrees of freedom                                60          60\n  P-value (Chi-square)                           0.000       0.001\n  Scaling correction factor                                  1.033\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    Female                                      54.745      52.985\n    Male                                        48.094      46.547\n\nModel Test Baseline Model:\n\n  Test statistic                              1343.575    1218.364\n  Degrees of freedom                                72          72\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.103\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.966       0.966\n  Tucker-Lewis Index (TLI)                       0.960       0.959\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.968\n  Robust Tucker-Lewis Index (TLI)                            0.961\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -13708.862  -13708.862\n  Scaling correction factor                                  0.834\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -13657.442  -13657.442\n  Scaling correction factor                                  1.014\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               27513.724   27513.724\n  Bayesian (BIC)                             27735.488   27735.488\n  Sample-size adjusted Bayesian (SABIC)      27583.069   27583.069\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.044       0.042\n  90 Percent confidence interval - lower         0.029       0.027\n  90 Percent confidence interval - upper         0.058       0.056\n  P-value H_0: RMSEA <= 0.050                    0.758       0.818\n  P-value H_0: RMSEA >= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.043\n  90 Percent confidence interval - lower                     0.027\n  90 Percent confidence interval - upper                     0.057\n  P-value H_0: Robust RMSEA <= 0.050                         0.785\n  P-value H_0: Robust RMSEA >= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.042       0.042\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\n\nGroup 1 [Female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.180    0.082   14.455    0.000    1.180    0.701\n    item2   (.p2.)    1.386    0.088   15.667    0.000    1.386    0.687\n    item3   (.p3.)    0.888    0.084   10.542    0.000    0.888    0.426\n    item4   (.p4.)    1.202    0.091   13.153    0.000    1.202    0.538\n    item5   (.p5.)    1.035    0.084   12.301    0.000    1.035    0.485\n    item6   (.p6.)    1.191    0.084   14.198    0.000    1.191    0.591\n    item7   (.p7.)    0.792    0.092    8.642    0.000    0.792    0.383\n    item8   (.p8.)    1.186    0.094   12.595    0.000    1.186    0.555\n    item9   (.p9.)    0.647    0.073    8.813    0.000    0.647    0.359\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.439    0.158    2.777    0.005    0.439    0.249\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             4.184    0.089   47.258    0.000    4.184    2.484\n   .item2             3.725    0.104   35.848    0.000    3.725    1.846\n   .item3             1.952    0.108   18.058    0.000    1.952    0.936\n   .item4             3.589    0.114   31.458    0.000    3.589    1.608\n   .item5             2.256    0.110   20.522    0.000    2.256    1.058\n   .item6             3.955    0.103   38.237    0.000    3.955    1.961\n   .item7             3.869    0.106   36.382    0.000    3.869    1.869\n   .item8             3.595    0.111   32.331    0.000    3.595    1.684\n   .item9             1.205    0.092   13.053    0.000    1.205    0.669\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             1.444    0.189    7.646    0.000    1.444    0.509\n   .item2             2.151    0.220    9.794    0.000    2.151    0.528\n   .item3             3.556    0.190   18.738    0.000    3.556    0.818\n   .item4             3.540    0.261   13.543    0.000    3.540    0.710\n   .item5             3.479    0.206   16.850    0.000    3.479    0.765\n   .item6             2.648    0.261   10.140    0.000    2.648    0.651\n   .item7             3.656    0.271   13.482    0.000    3.656    0.853\n   .item8             3.153    0.275   11.465    0.000    3.153    0.692\n   .item9             2.827    0.195   14.492    0.000    2.827    0.871\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.491\n    item2             0.472\n    item3             0.182\n    item4             0.290\n    item5             0.235\n    item6             0.349\n    item7             0.147\n    item8             0.308\n    item9             0.129\n\n\nGroup 2 [Male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.180    0.082   14.455    0.000    1.097    0.675\n    item2   (.p2.)    1.386    0.088   15.667    0.000    1.288    0.638\n    item3   (.p3.)    0.888    0.084   10.542    0.000    0.825    0.393\n    item4   (.p4.)    1.202    0.091   13.153    0.000    1.117    0.506\n    item5   (.p5.)    1.035    0.084   12.301    0.000    0.961    0.458\n    item6   (.p6.)    1.191    0.084   14.198    0.000    1.107    0.529\n    item7   (.p7.)    0.792    0.092    8.642    0.000    0.736    0.324\n    item8   (.p8.)    1.186    0.094   12.595    0.000    1.102    0.503\n    item9   (.p9.)    0.647    0.073    8.813    0.000    0.601    0.339\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.862    0.187    4.610    0.000    0.862    0.463\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             4.171    0.082   50.608    0.000    4.171    2.568\n   .item2             3.685    0.104   35.414    0.000    3.685    1.827\n   .item3             1.739    0.108   16.098    0.000    1.739    0.828\n   .item4             3.357    0.115   29.160    0.000    3.357    1.522\n   .item5             2.235    0.109   20.560    0.000    2.235    1.064\n   .item6             3.661    0.109   33.598    0.000    3.661    1.748\n   .item7             3.421    0.118   29.014    0.000    3.421    1.506\n   .item8             3.517    0.112   31.372    0.000    3.517    1.605\n   .item9             1.259    0.092   13.649    0.000    1.259    0.710\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             1.436    0.203    7.060    0.000    1.436    0.544\n   .item2             2.412    0.245    9.854    0.000    2.412    0.593\n   .item3             3.731    0.196   19.064    0.000    3.731    0.846\n   .item4             3.617    0.258   14.027    0.000    3.617    0.744\n   .item5             3.488    0.216   16.176    0.000    3.488    0.790\n   .item6             3.161    0.270   11.688    0.000    3.161    0.721\n   .item7             4.619    0.260   17.798    0.000    4.619    0.895\n   .item8             3.587    0.276   12.998    0.000    3.587    0.747\n   .item9             2.781    0.208   13.395    0.000    2.781    0.885\n    depress           0.863    0.112    7.728    0.000    1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.456\n    item2             0.407\n    item3             0.154\n    item4             0.256\n    item5             0.210\n    item6             0.279\n    item7             0.105\n    item8             0.253\n    item9             0.115\n\nsummary(fit.scalar, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n\nlavaan 0.6.13 ended normally after 52 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        58\n  Number of equality constraints                    18\n\n  Number of observations per group:                   \n    Female                                         375\n    Male                                           375\n  Number of missing patterns per group:               \n    Female                                           1\n    Male                                             1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               115.309     111.951\n  Degrees of freedom                                68          68\n  P-value (Chi-square)                           0.000       0.001\n  Scaling correction factor                                  1.030\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    Female                                      60.715      58.946\n    Male                                        54.594      53.004\n\nModel Test Baseline Model:\n\n  Test statistic                              1343.575    1218.364\n  Degrees of freedom                                72          72\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.103\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.963       0.962\n  Tucker-Lewis Index (TLI)                       0.961       0.959\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.964\n  Robust Tucker-Lewis Index (TLI)                            0.962\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -13715.097  -13715.097\n  Scaling correction factor                                  0.681\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -13657.442  -13657.442\n  Scaling correction factor                                  1.014\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               27510.194   27510.194\n  Bayesian (BIC)                             27694.997   27694.997\n  Sample-size adjusted Bayesian (SABIC)      27567.981   27567.981\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.043       0.042\n  90 Percent confidence interval - lower         0.029       0.027\n  90 Percent confidence interval - upper         0.056       0.055\n  P-value H_0: RMSEA <= 0.050                    0.794       0.846\n  P-value H_0: RMSEA >= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.042\n  90 Percent confidence interval - lower                     0.028\n  90 Percent confidence interval - upper                     0.056\n  P-value H_0: Robust RMSEA <= 0.050                         0.817\n  P-value H_0: Robust RMSEA >= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.046       0.046\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\n\nGroup 1 [Female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.171    0.081   14.385    0.000    1.171    0.696\n    item2   (.p2.)    1.377    0.089   15.534    0.000    1.377    0.683\n    item3   (.p3.)    0.894    0.084   10.621    0.000    0.894    0.429\n    item4   (.p4.)    1.209    0.091   13.343    0.000    1.209    0.541\n    item5   (.p5.)    1.033    0.084   12.275    0.000    1.033    0.485\n    item6   (.p6.)    1.199    0.083   14.424    0.000    1.199    0.593\n    item7   (.p7.)    0.803    0.091    8.853    0.000    0.803    0.386\n    item8   (.p8.)    1.184    0.094   12.534    0.000    1.184    0.555\n    item9   (.p9.)    0.640    0.074    8.604    0.000    0.640    0.356\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.454    0.159    2.852    0.004    0.454    0.255\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.240    0.077   54.984    0.000    4.240    2.520\n   .item2   (.11.)    3.773    0.092   41.111    0.000    3.773    1.872\n   .item3   (.12.)    1.897    0.087   21.735    0.000    1.897    0.909\n   .item4   (.13.)    3.541    0.096   37.066    0.000    3.541    1.584\n   .item5   (.14.)    2.303    0.090   25.622    0.000    2.303    1.080\n   .item6   (.15.)    3.882    0.091   42.556    0.000    3.882    1.921\n   .item7   (.16.)    3.711    0.087   42.428    0.000    3.711    1.784\n   .item8   (.17.)    3.620    0.094   38.567    0.000    3.620    1.696\n   .item9   (.18.)    1.268    0.072   17.592    0.000    1.268    0.704\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             1.460    0.193    7.576    0.000    1.460    0.516\n   .item2             2.166    0.223    9.726    0.000    2.166    0.533\n   .item3             3.555    0.191   18.619    0.000    3.555    0.816\n   .item4             3.535    0.261   13.520    0.000    3.535    0.708\n   .item5             3.478    0.206   16.880    0.000    3.478    0.765\n   .item6             2.648    0.260   10.183    0.000    2.648    0.648\n   .item7             3.682    0.267   13.767    0.000    3.682    0.851\n   .item8             3.155    0.277   11.377    0.000    3.155    0.692\n   .item9             2.834    0.192   14.790    0.000    2.834    0.874\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.484\n    item2             0.467\n    item3             0.184\n    item4             0.292\n    item5             0.235\n    item6             0.352\n    item7             0.149\n    item8             0.308\n    item9             0.126\n\n\nGroup 2 [Male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.171    0.081   14.385    0.000    1.089    0.671\n    item2   (.p2.)    1.377    0.089   15.534    0.000    1.280    0.635\n    item3   (.p3.)    0.894    0.084   10.621    0.000    0.831    0.395\n    item4   (.p4.)    1.209    0.091   13.343    0.000    1.123    0.509\n    item5   (.p5.)    1.033    0.084   12.275    0.000    0.960    0.457\n    item6   (.p6.)    1.199    0.083   14.424    0.000    1.114    0.531\n    item7   (.p7.)    0.803    0.091    8.853    0.000    0.746    0.327\n    item8   (.p8.)    1.184    0.094   12.534    0.000    1.100    0.502\n    item9   (.p9.)    0.640    0.074    8.604    0.000    0.595    0.336\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.879    0.185    4.754    0.000    0.879    0.468\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.240    0.077   54.984    0.000    4.240    2.611\n   .item2   (.11.)    3.773    0.092   41.111    0.000    3.773    1.870\n   .item3   (.12.)    1.897    0.087   21.735    0.000    1.897    0.902\n   .item4   (.13.)    3.541    0.096   37.066    0.000    3.541    1.604\n   .item5   (.14.)    2.303    0.090   25.622    0.000    2.303    1.097\n   .item6   (.15.)    3.882    0.091   42.556    0.000    3.882    1.850\n   .item7   (.16.)    3.711    0.087   42.428    0.000    3.711    1.625\n   .item8   (.17.)    3.620    0.094   38.567    0.000    3.620    1.653\n   .item9   (.18.)    1.268    0.072   17.592    0.000    1.268    0.715\n    depress          -0.112    0.083   -1.345    0.179   -0.120   -0.120\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             1.451    0.200    7.258    0.000    1.451    0.550\n   .item2             2.431    0.240   10.124    0.000    2.431    0.597\n   .item3             3.730    0.196   19.059    0.000    3.730    0.844\n   .item4             3.611    0.258   13.975    0.000    3.611    0.741\n   .item5             3.489    0.216   16.166    0.000    3.489    0.791\n   .item6             3.161    0.276   11.468    0.000    3.161    0.718\n   .item7             4.658    0.277   16.831    0.000    4.658    0.893\n   .item8             3.588    0.274   13.119    0.000    3.588    0.748\n   .item9             2.788    0.213   13.105    0.000    2.788    0.887\n    depress           0.864    0.112    7.720    0.000    1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.450\n    item2             0.403\n    item3             0.156\n    item4             0.259\n    item5             0.209\n    item6             0.282\n    item7             0.107\n    item8             0.252\n    item9             0.113\n\nsummary(fit.scalar2, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n\nlavaan 0.6.13 ended normally after 53 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        58\n  Number of equality constraints                    17\n\n  Number of observations per group:                   \n    Female                                         375\n    Male                                           375\n  Number of missing patterns per group:               \n    Female                                           1\n    Male                                             1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               109.216     106.031\n  Degrees of freedom                                67          67\n  P-value (Chi-square)                           0.001       0.002\n  Scaling correction factor                                  1.030\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    Female                                      57.897      56.209\n    Male                                        51.318      49.822\n\nModel Test Baseline Model:\n\n  Test statistic                              1343.575    1218.364\n  Degrees of freedom                                72          72\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.103\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.967       0.966\n  Tucker-Lewis Index (TLI)                       0.964       0.963\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.968\n  Robust Tucker-Lewis Index (TLI)                            0.966\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -13712.050  -13712.050\n  Scaling correction factor                                  0.699\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -13657.442  -13657.442\n  Scaling correction factor                                  1.014\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               27506.100   27506.100\n  Bayesian (BIC)                             27695.523   27695.523\n  Sample-size adjusted Bayesian (SABIC)      27565.332   27565.332\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.041       0.039\n  90 Percent confidence interval - lower         0.026       0.025\n  90 Percent confidence interval - upper         0.055       0.053\n  P-value H_0: RMSEA <= 0.050                    0.855       0.896\n  P-value H_0: RMSEA >= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.040\n  90 Percent confidence interval - lower                     0.025\n  90 Percent confidence interval - upper                     0.054\n  P-value H_0: Robust RMSEA <= 0.050                         0.873\n  P-value H_0: Robust RMSEA >= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.044       0.044\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\n\nGroup 1 [Female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.174    0.082   14.377    0.000    1.174    0.698\n    item2   (.p2.)    1.381    0.089   15.564    0.000    1.381    0.685\n    item3   (.p3.)    0.894    0.084   10.598    0.000    0.894    0.428\n    item4   (.p4.)    1.208    0.091   13.309    0.000    1.208    0.540\n    item5   (.p5.)    1.034    0.084   12.287    0.000    1.034    0.485\n    item6   (.p6.)    1.198    0.083   14.364    0.000    1.198    0.592\n    item7   (.p7.)    0.791    0.092    8.603    0.000    0.791    0.382\n    item8   (.p8.)    1.185    0.094   12.561    0.000    1.185    0.555\n    item9   (.p9.)    0.642    0.074    8.630    0.000    0.642    0.356\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.449    0.159    2.825    0.005    0.449    0.253\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.228    0.078   54.510    0.000    4.228    2.512\n   .item2   (.11.)    3.761    0.092   40.840    0.000    3.761    1.865\n   .item3   (.12.)    1.887    0.087   21.651    0.000    1.887    0.904\n   .item4   (.13.)    3.529    0.096   36.780    0.000    3.529    1.578\n   .item5   (.14.)    2.292    0.090   25.462    0.000    2.292    1.075\n   .item6   (.15.)    3.870    0.092   42.207    0.000    3.870    1.915\n   .item7             3.869    0.106   36.382    0.000    3.869    1.869\n   .item8   (.17.)    3.609    0.094   38.382    0.000    3.609    1.690\n   .item9   (.18.)    1.261    0.072   17.570    0.000    1.261    0.700\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             1.455    0.191    7.595    0.000    1.455    0.513\n   .item2             2.160    0.222    9.738    0.000    2.160    0.531\n   .item3             3.557    0.191   18.613    0.000    3.557    0.817\n   .item4             3.539    0.261   13.545    0.000    3.539    0.708\n   .item5             3.478    0.206   16.874    0.000    3.478    0.765\n   .item6             2.651    0.260   10.205    0.000    2.651    0.649\n   .item7             3.658    0.271   13.485    0.000    3.658    0.854\n   .item8             3.154    0.277   11.404    0.000    3.154    0.692\n   .item9             2.832    0.192   14.743    0.000    2.832    0.873\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.487\n    item2             0.469\n    item3             0.183\n    item4             0.292\n    item5             0.235\n    item6             0.351\n    item7             0.146\n    item8             0.308\n    item9             0.127\n\n\nGroup 2 [Male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.174    0.082   14.377    0.000    1.091    0.672\n    item2   (.p2.)    1.381    0.089   15.564    0.000    1.283    0.636\n    item3   (.p3.)    0.894    0.084   10.598    0.000    0.830    0.395\n    item4   (.p4.)    1.208    0.091   13.309    0.000    1.122    0.508\n    item5   (.p5.)    1.034    0.084   12.287    0.000    0.961    0.457\n    item6   (.p6.)    1.198    0.083   14.364    0.000    1.113    0.530\n    item7   (.p7.)    0.791    0.092    8.603    0.000    0.735    0.324\n    item8   (.p8.)    1.185    0.094   12.561    0.000    1.101    0.503\n    item9   (.p9.)    0.642    0.074    8.630    0.000    0.597    0.337\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.872    0.186    4.696    0.000    0.872    0.466\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.228    0.078   54.510    0.000    4.228    2.604\n   .item2   (.11.)    3.761    0.092   40.840    0.000    3.761    1.864\n   .item3   (.12.)    1.887    0.087   21.651    0.000    1.887    0.897\n   .item4   (.13.)    3.529    0.096   36.780    0.000    3.529    1.598\n   .item5   (.14.)    2.292    0.090   25.462    0.000    2.292    1.091\n   .item6   (.15.)    3.870    0.092   42.207    0.000    3.870    1.844\n   .item7             3.493    0.123   28.376    0.000    3.493    1.538\n   .item8   (.17.)    3.609    0.094   38.382    0.000    3.609    1.647\n   .item9   (.18.)    1.261    0.072   17.570    0.000    1.261    0.712\n    depress          -0.090    0.083   -1.087    0.277   -0.097   -0.097\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1             1.445    0.201    7.186    0.000    1.445    0.548\n   .item2             2.423    0.242   10.026    0.000    2.423    0.595\n   .item3             3.733    0.196   19.086    0.000    3.733    0.844\n   .item4             3.615    0.260   13.913    0.000    3.615    0.742\n   .item5             3.488    0.216   16.160    0.000    3.488    0.791\n   .item6             3.166    0.277   11.417    0.000    3.166    0.719\n   .item7             4.620    0.259   17.804    0.000    4.620    0.895\n   .item8             3.587    0.274   13.071    0.000    3.587    0.747\n   .item9             2.787    0.212   13.148    0.000    2.787    0.887\n    depress           0.864    0.112    7.725    0.000    1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.452\n    item2             0.405\n    item3             0.156\n    item4             0.258\n    item5             0.209\n    item6             0.281\n    item7             0.105\n    item8             0.253\n    item9             0.113\n\nsummary(fit.strict, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n\nlavaan 0.6.13 ended normally after 54 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        58\n  Number of equality constraints                    25\n\n  Number of observations per group:                   \n    Female                                         375\n    Male                                           375\n  Number of missing patterns per group:               \n    Female                                           1\n    Male                                             1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               114.059     112.019\n  Degrees of freedom                                75          75\n  P-value (Chi-square)                           0.002       0.004\n  Scaling correction factor                                  1.018\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    Female                                      60.752      59.666\n    Male                                        53.306      52.353\n\nModel Test Baseline Model:\n\n  Test statistic                              1343.575    1218.364\n  Degrees of freedom                                72          72\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.103\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.969       0.968\n  Tucker-Lewis Index (TLI)                       0.971       0.969\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.970\n  Robust Tucker-Lewis Index (TLI)                            0.971\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -13714.472  -13714.472\n  Scaling correction factor                                  0.572\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -13657.442  -13657.442\n  Scaling correction factor                                  1.014\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               27494.944   27494.944\n  Bayesian (BIC)                             27647.406   27647.406\n  Sample-size adjusted Bayesian (SABIC)      27542.618   27542.618\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.037       0.036\n  90 Percent confidence interval - lower         0.022       0.021\n  90 Percent confidence interval - upper         0.051       0.050\n  P-value H_0: RMSEA <= 0.050                    0.942       0.956\n  P-value H_0: RMSEA >= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.037\n  90 Percent confidence interval - lower                     0.021\n  90 Percent confidence interval - upper                     0.050\n  P-value H_0: Robust RMSEA <= 0.050                         0.948\n  P-value H_0: Robust RMSEA >= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.048       0.048\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\n\nGroup 1 [Female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.167    0.082   14.180    0.000    1.167    0.696\n    item2   (.p2.)    1.372    0.089   15.358    0.000    1.372    0.671\n    item3   (.p3.)    0.888    0.083   10.655    0.000    0.888    0.422\n    item4   (.p4.)    1.203    0.090   13.341    0.000    1.203    0.537\n    item5   (.p5.)    1.031    0.084   12.316    0.000    1.031    0.484\n    item6   (.p6.)    1.197    0.083   14.492    0.000    1.197    0.575\n    item7   (.p7.)    0.787    0.092    8.593    0.000    0.787    0.381\n    item8   (.p8.)    1.178    0.093   12.608    0.000    1.178    0.540\n    item9   (.p9.)    0.639    0.074    8.602    0.000    0.639    0.356\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.484    0.160    3.030    0.002    0.484    0.266\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.229    0.078   53.943    0.000    4.229    2.522\n   .item2   (.11.)    3.763    0.093   40.533    0.000    3.763    1.840\n   .item3   (.12.)    1.886    0.087   21.609    0.000    1.886    0.895\n   .item4   (.13.)    3.528    0.096   36.880    0.000    3.528    1.574\n   .item5   (.14.)    2.292    0.090   25.455    0.000    2.292    1.076\n   .item6   (.15.)    3.862    0.091   42.539    0.000    3.862    1.855\n   .item7             3.869    0.106   36.382    0.000    3.869    1.872\n   .item8   (.17.)    3.609    0.094   38.326    0.000    3.609    1.655\n   .item9   (.18.)    1.261    0.071   17.668    0.000    1.261    0.703\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.19.)    1.447    0.145    9.954    0.000    1.447    0.515\n   .item2   (.20.)    2.300    0.177   12.965    0.000    2.300    0.550\n   .item3   (.21.)    3.646    0.143   25.449    0.000    3.646    0.822\n   .item4   (.22.)    3.574    0.197   18.123    0.000    3.574    0.712\n   .item5   (.23.)    3.479    0.161   21.647    0.000    3.479    0.766\n   .item6   (.24.)    2.903    0.199   14.558    0.000    2.903    0.670\n   .item7             3.653    0.271   13.462    0.000    3.653    0.855\n   .item8   (.26.)    3.367    0.207   16.293    0.000    3.367    0.708\n   .item9   (.27.)    2.809    0.143   19.650    0.000    2.809    0.873\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.485\n    item2             0.450\n    item3             0.178\n    item4             0.288\n    item5             0.234\n    item6             0.330\n    item7             0.145\n    item8             0.292\n    item9             0.127\n\n\nGroup 2 [Male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.167    0.082   14.180    0.000    1.097    0.674\n    item2   (.p2.)    1.372    0.089   15.358    0.000    1.289    0.648\n    item3   (.p3.)    0.888    0.083   10.655    0.000    0.834    0.400\n    item4   (.p4.)    1.203    0.090   13.341    0.000    1.130    0.513\n    item5   (.p5.)    1.031    0.084   12.316    0.000    0.968    0.461\n    item6   (.p6.)    1.197    0.083   14.492    0.000    1.124    0.551\n    item7   (.p7.)    0.787    0.092    8.593    0.000    0.739    0.325\n    item8   (.p8.)    1.178    0.093   12.608    0.000    1.107    0.516\n    item9   (.p9.)    0.639    0.074    8.602    0.000    0.600    0.337\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.832    0.151    5.497    0.000    0.832    0.456\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.229    0.078   53.943    0.000    4.229    2.598\n   .item2   (.11.)    3.763    0.093   40.533    0.000    3.763    1.890\n   .item3   (.12.)    1.886    0.087   21.609    0.000    1.886    0.905\n   .item4   (.13.)    3.528    0.096   36.880    0.000    3.528    1.602\n   .item5   (.14.)    2.292    0.090   25.455    0.000    2.292    1.091\n   .item6   (.15.)    3.862    0.091   42.539    0.000    3.862    1.892\n   .item7             3.493    0.123   28.381    0.000    3.493    1.535\n   .item8   (.17.)    3.609    0.094   38.326    0.000    3.609    1.684\n   .item9   (.18.)    1.261    0.071   17.668    0.000    1.261    0.708\n    depress          -0.091    0.084   -1.084    0.279   -0.097   -0.097\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.19.)    1.447    0.145    9.954    0.000    1.447    0.546\n   .item2   (.20.)    2.300    0.177   12.965    0.000    2.300    0.581\n   .item3   (.21.)    3.646    0.143   25.449    0.000    3.646    0.840\n   .item4   (.22.)    3.574    0.197   18.123    0.000    3.574    0.737\n   .item5   (.23.)    3.479    0.161   21.647    0.000    3.479    0.788\n   .item6   (.24.)    2.903    0.199   14.558    0.000    2.903    0.697\n   .item7             4.629    0.260   17.815    0.000    4.629    0.894\n   .item8   (.26.)    3.367    0.207   16.293    0.000    3.367    0.733\n   .item9   (.27.)    2.809    0.143   19.650    0.000    2.809    0.886\n    depress           0.883    0.111    7.936    0.000    1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.454\n    item2             0.419\n    item3             0.160\n    item4             0.263\n    item5             0.212\n    item6             0.303\n    item7             0.106\n    item8             0.267\n    item9             0.114\n\nsummary(fit.strict.cov, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)\n\nlavaan 0.6.13 ended normally after 55 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        58\n  Number of equality constraints                    26\n\n  Number of observations per group:                   \n    Female                                         375\n    Male                                           375\n  Number of missing patterns per group:               \n    Female                                           1\n    Male                                             1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               123.351     119.281\n  Degrees of freedom                                76          76\n  P-value (Chi-square)                           0.000       0.001\n  Scaling correction factor                                  1.034\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    Female                                      65.102      62.954\n    Male                                        58.248      56.327\n\nModel Test Baseline Model:\n\n  Test statistic                              1343.575    1218.364\n  Degrees of freedom                                72          72\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.103\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.963       0.962\n  Tucker-Lewis Index (TLI)                       0.965       0.964\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.965\n  Robust Tucker-Lewis Index (TLI)                            0.967\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -13719.118  -13719.118\n  Scaling correction factor                                  0.534\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -13657.442  -13657.442\n  Scaling correction factor                                  1.014\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               27502.235   27502.235\n  Bayesian (BIC)                             27650.078   27650.078\n  Sample-size adjusted Bayesian (SABIC)      27548.465   27548.465\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.041       0.039\n  90 Percent confidence interval - lower         0.027       0.025\n  90 Percent confidence interval - upper         0.054       0.052\n  P-value H_0: RMSEA <= 0.050                    0.877       0.920\n  P-value H_0: RMSEA >= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.040\n  90 Percent confidence interval - lower                     0.025\n  90 Percent confidence interval - upper                     0.053\n  P-value H_0: Robust RMSEA <= 0.050                         0.897\n  P-value H_0: Robust RMSEA >= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.048       0.048\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\n\nGroup 1 [Female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.164    0.082   14.182    0.000    1.164    0.695\n    item2   (.p2.)    1.355    0.088   15.395    0.000    1.355    0.666\n    item3   (.p3.)    0.883    0.084   10.551    0.000    0.883    0.420\n    item4   (.p4.)    1.200    0.091   13.260    0.000    1.200    0.536\n    item5   (.p5.)    1.031    0.084   12.293    0.000    1.031    0.484\n    item6   (.p6.)    1.191    0.083   14.394    0.000    1.191    0.573\n    item7   (.p7.)    0.782    0.091    8.554    0.000    0.782    0.378\n    item8   (.p8.)    1.173    0.094   12.528    0.000    1.173    0.539\n    item9   (.p9.)    0.637    0.074    8.581    0.000    0.637    0.355\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2   (.28.)    0.671    0.132    5.072    0.000    0.671    0.366\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.231    0.079   53.848    0.000    4.231    2.524\n   .item2   (.11.)    3.767    0.092   40.777    0.000    3.767    1.850\n   .item3   (.12.)    1.886    0.087   21.608    0.000    1.886    0.896\n   .item4   (.13.)    3.528    0.096   36.854    0.000    3.528    1.576\n   .item5   (.14.)    2.292    0.090   25.422    0.000    2.292    1.077\n   .item6   (.15.)    3.862    0.091   42.534    0.000    3.862    1.857\n   .item7             3.869    0.106   36.382    0.000    3.869    1.873\n   .item8   (.17.)    3.610    0.094   38.318    0.000    3.610    1.657\n   .item9   (.18.)    1.261    0.071   17.661    0.000    1.261    0.703\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.19.)    1.455    0.147    9.904    0.000    1.455    0.518\n   .item2   (.20.)    2.309    0.179   12.908    0.000    2.309    0.557\n   .item3   (.21.)    3.648    0.143   25.433    0.000    3.648    0.824\n   .item4   (.22.)    3.570    0.197   18.084    0.000    3.570    0.712\n   .item5   (.23.)    3.470    0.161   21.569    0.000    3.470    0.765\n   .item6   (.24.)    2.906    0.199   14.565    0.000    2.906    0.672\n   .item7             3.658    0.272   13.465    0.000    3.658    0.857\n   .item8   (.26.)    3.368    0.207   16.303    0.000    3.368    0.710\n   .item9   (.27.)    2.808    0.143   19.650    0.000    2.808    0.874\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.482\n    item2             0.443\n    item3             0.176\n    item4             0.288\n    item5             0.235\n    item6             0.328\n    item7             0.143\n    item8             0.290\n    item9             0.126\n\n\nGroup 2 [Male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.164    0.082   14.182    0.000    1.103    0.675\n    item2   (.p2.)    1.355    0.088   15.395    0.000    1.284    0.645\n    item3   (.p3.)    0.883    0.084   10.551    0.000    0.836    0.401\n    item4   (.p4.)    1.200    0.091   13.260    0.000    1.137    0.516\n    item5   (.p5.)    1.031    0.084   12.293    0.000    0.977    0.464\n    item6   (.p6.)    1.191    0.083   14.394    0.000    1.128    0.552\n    item7   (.p7.)    0.782    0.091    8.554    0.000    0.741    0.325\n    item8   (.p8.)    1.173    0.094   12.528    0.000    1.111    0.518\n    item9   (.p9.)    0.637    0.074    8.581    0.000    0.603    0.339\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2   (.28.)    0.671    0.132    5.072    0.000    0.671    0.366\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.231    0.079   53.848    0.000    4.231    2.589\n   .item2   (.11.)    3.767    0.092   40.777    0.000    3.767    1.894\n   .item3   (.12.)    1.886    0.087   21.608    0.000    1.886    0.904\n   .item4   (.13.)    3.528    0.096   36.854    0.000    3.528    1.600\n   .item5   (.14.)    2.292    0.090   25.422    0.000    2.292    1.090\n   .item6   (.15.)    3.862    0.091   42.534    0.000    3.862    1.890\n   .item7             3.493    0.123   28.383    0.000    3.493    1.535\n   .item8   (.17.)    3.610    0.094   38.318    0.000    3.610    1.683\n   .item9   (.18.)    1.261    0.071   17.661    0.000    1.261    0.708\n    depress          -0.091    0.084   -1.086    0.278   -0.097   -0.097\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.19.)    1.455    0.147    9.904    0.000    1.455    0.545\n   .item2   (.20.)    2.309    0.179   12.908    0.000    2.309    0.584\n   .item3   (.21.)    3.648    0.143   25.433    0.000    3.648    0.839\n   .item4   (.22.)    3.570    0.197   18.084    0.000    3.570    0.734\n   .item5   (.23.)    3.470    0.161   21.569    0.000    3.470    0.784\n   .item6   (.24.)    2.906    0.199   14.565    0.000    2.906    0.696\n   .item7             4.630    0.260   17.825    0.000    4.630    0.894\n   .item8   (.26.)    3.368    0.207   16.303    0.000    3.368    0.732\n   .item9   (.27.)    2.808    0.143   19.650    0.000    2.808    0.885\n    depress           0.897    0.113    7.932    0.000    1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.455\n    item2             0.416\n    item3             0.161\n    item4             0.266\n    item5             0.216\n    item6             0.304\n    item7             0.106\n    item8             0.268\n    item9             0.115\n\n\nModel Comparision\n\nmodel_fit <-  function(lavobject) {\n  vars <- c(\"cfi\", \"tli\", \"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\", \"rmsea.pvalue\", \"srmr\")\n  return(fitmeasures(lavobject)[vars] %>% data.frame() %>% round(2) %>% t())\n}\n\ntable_fit <- \n  list(model_fit(fit.config), model_fit(fit.metric), \n       model_fit(fit.scalar), model_fit(fit.scalar2),\n       model_fit(fit.strict), model_fit(fit.strict.cov)) %>% \n  reduce(rbind)\n\nrownames(table_fit) <- c(\"Configural\", \"Metric\", \"Scalar\", \"Scalar2\",\"Strict\",\"Strict+Cov\")\n\ntable_lik.test <- \n  list(anova(fit.config, fit.metric),\n       anova(fit.metric, fit.scalar),\n       anova(fit.scalar, fit.scalar2),\n       anova(fit.scalar2, fit.strict),\n       anova(fit.strict, fit.strict.cov)\n       ) %>%  \n  reduce(rbind) %>% \n  .[-c(3,5,7,9),]\nrownames(table_lik.test) <- c(\"Configural\", \"Metric\", \"Scalar\", \"Scalar2\",\"Strict\",\"Strict+Cov\")\n\nkable(table_fit, caption = \"Model Fit Indices Table\")\n\n\nModel Fit Indices Table\n\n\n\n\n\n\n\n\n\n\n\n\ncfi\ntli\nrmsea\nrmsea.ci.lower\nrmsea.ci.upper\nrmsea.pvalue\nsrmr\n\n\n\nConfigural\n0.96\n0.95\n0.05\n0.03\n0.06\n0.52\n0.04\n\n\nMetric\n0.97\n0.96\n0.04\n0.03\n0.06\n0.76\n0.04\n\n\nScalar\n0.96\n0.96\n0.04\n0.03\n0.06\n0.79\n0.05\n\n\nScalar2\n0.97\n0.96\n0.04\n0.03\n0.05\n0.85\n0.04\n\n\nStrict\n0.97\n0.97\n0.04\n0.02\n0.05\n0.94\n0.05\n\n\nStrict+Cov\n0.96\n0.96\n0.04\n0.03\n0.05\n0.88\n0.05\n\n\n\n\nkable(table_lik.test, caption = \"Model Comparision Table\")\n\n\nModel Comparision Table\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nAIC\nBIC\nChisq\nChisq diff\nDf diff\nPr(>Chisq)\n\n\n\nConfigural\n52\n27525.80\n27784.52\n98.91085\nNA\nNA\nNA\n\n\nMetric\n60\n27513.72\n27735.49\n102.83941\n4.259305\n8\n0.8330029\n\n\nScalar\n68\n27510.19\n27695.00\n115.30933\n12.398256\n8\n0.1342996\n\n\nScalar2\n68\n27510.19\n27695.00\n115.30933\n5.929566\n1\n0.0148889\n\n\nStrict\n75\n27494.94\n27647.41\n114.05887\n5.269043\n8\n0.7284714\n\n\nStrict+Cov\n76\n27502.24\n27650.08\n123.35057\n4.172431\n1\n0.0410868"
  },
  {
    "objectID": "posts/2017-11-12-MESUREMENT-INVARIANCE/index.en.html#structual-invariance-tests",
    "href": "posts/2017-11-12-MESUREMENT-INVARIANCE/index.en.html#structual-invariance-tests",
    "title": "One Example of Measurement Invariance",
    "section": "STRUCTUAL INVARIANCE TESTS",
    "text": "STRUCTUAL INVARIANCE TESTS\nFactor Variance Invariance Model\n\n\nlavaan 0.6.13 ended normally after 54 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        57\n  Number of equality constraints                    25\n\n  Number of observations per group:                   \n    Female                                         375\n    Male                                           375\n  Number of missing patterns per group:               \n    Female                                           1\n    Male                                             1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               114.904     113.113\n  Degrees of freedom                                76          76\n  P-value (Chi-square)                           0.003       0.004\n  Scaling correction factor                                  1.016\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    Female                                      61.213      60.259\n    Male                                        53.691      52.854\n\nModel Test Baseline Model:\n\n  Test statistic                              1343.575    1218.364\n  Degrees of freedom                                72          72\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.103\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.969       0.968\n  Tucker-Lewis Index (TLI)                       0.971       0.969\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.970\n  Robust Tucker-Lewis Index (TLI)                            0.972\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -13714.894  -13714.894\n  Scaling correction factor                                  0.567\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -13657.442  -13657.442\n  Scaling correction factor                                  1.014\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               27493.789   27493.789\n  Bayesian (BIC)                             27641.631   27641.631\n  Sample-size adjusted Bayesian (SABIC)      27540.019   27540.019\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.037       0.036\n  90 Percent confidence interval - lower         0.022       0.021\n  90 Percent confidence interval - upper         0.050       0.049\n  P-value H_0: RMSEA <= 0.050                    0.947       0.958\n  P-value H_0: RMSEA >= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.036\n  90 Percent confidence interval - lower                     0.021\n  90 Percent confidence interval - upper                     0.050\n  P-value H_0: Robust RMSEA <= 0.050                         0.952\n  P-value H_0: Robust RMSEA >= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.050       0.050\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\n\nGroup 1 [Female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.132    0.069   16.495    0.000    1.132    0.685\n    item2   (.p2.)    1.332    0.076   17.634    0.000    1.332    0.660\n    item3   (.p3.)    0.861    0.076   11.269    0.000    0.861    0.411\n    item4   (.p4.)    1.169    0.083   14.123    0.000    1.169    0.526\n    item5   (.p5.)    1.000    0.076   13.226    0.000    1.000    0.473\n    item6   (.p6.)    1.162    0.077   15.167    0.000    1.162    0.564\n    item7   (.p7.)    0.765    0.086    8.889    0.000    0.765    0.371\n    item8   (.p8.)    1.142    0.082   13.922    0.000    1.142    0.528\n    item9   (.p9.)    0.620    0.069    8.931    0.000    0.620    0.347\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.490    0.159    3.077    0.002    0.490    0.268\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.229    0.078   53.980    0.000    4.229    2.558\n   .item2   (.11.)    3.763    0.093   40.555    0.000    3.763    1.864\n   .item3   (.12.)    1.886    0.087   21.616    0.000    1.886    0.900\n   .item4   (.13.)    3.528    0.096   36.887    0.000    3.528    1.588\n   .item5   (.14.)    2.292    0.090   25.463    0.000    2.292    1.083\n   .item6   (.15.)    3.862    0.091   42.543    0.000    3.862    1.873\n   .item7             3.869    0.106   36.382    0.000    3.869    1.879\n   .item8   (.17.)    3.610    0.094   38.348    0.000    3.610    1.670\n   .item9   (.18.)    1.261    0.071   17.671    0.000    1.261    0.706\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.19.)    1.452    0.145    9.988    0.000    1.452    0.531\n   .item2   (.20.)    2.301    0.178   12.925    0.000    2.301    0.565\n   .item3   (.21.)    3.646    0.143   25.467    0.000    3.646    0.831\n   .item4   (.22.)    3.571    0.197   18.119    0.000    3.571    0.723\n   .item5   (.23.)    3.478    0.161   21.626    0.000    3.478    0.777\n   .item6   (.24.)    2.900    0.199   14.536    0.000    2.900    0.682\n   .item7             3.655    0.271   13.480    0.000    3.655    0.862\n   .item8   (.26.)    3.368    0.207   16.280    0.000    3.368    0.721\n   .item9   (.27.)    2.809    0.143   19.649    0.000    2.809    0.880\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.469\n    item2             0.435\n    item3             0.169\n    item4             0.277\n    item5             0.223\n    item6             0.318\n    item7             0.138\n    item8             0.279\n    item9             0.120\n\n\nGroup 2 [Male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.132    0.069   16.495    0.000    1.132    0.685\n    item2   (.p2.)    1.332    0.076   17.634    0.000    1.332    0.660\n    item3   (.p3.)    0.861    0.076   11.269    0.000    0.861    0.411\n    item4   (.p4.)    1.169    0.083   14.123    0.000    1.169    0.526\n    item5   (.p5.)    1.000    0.076   13.226    0.000    1.000    0.473\n    item6   (.p6.)    1.162    0.077   15.167    0.000    1.162    0.564\n    item7   (.p7.)    0.765    0.086    8.889    0.000    0.765    0.335\n    item8   (.p8.)    1.142    0.082   13.922    0.000    1.142    0.528\n    item9   (.p9.)    0.620    0.069    8.931    0.000    0.620    0.347\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.834    0.152    5.483    0.000    0.834    0.456\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.229    0.078   53.980    0.000    4.229    2.558\n   .item2   (.11.)    3.763    0.093   40.555    0.000    3.763    1.864\n   .item3   (.12.)    1.886    0.087   21.616    0.000    1.886    0.900\n   .item4   (.13.)    3.528    0.096   36.887    0.000    3.528    1.588\n   .item5   (.14.)    2.292    0.090   25.463    0.000    2.292    1.083\n   .item6   (.15.)    3.862    0.091   42.543    0.000    3.862    1.873\n   .item7             3.493    0.123   28.386    0.000    3.493    1.530\n   .item8   (.17.)    3.610    0.094   38.348    0.000    3.610    1.670\n   .item9   (.18.)    1.261    0.071   17.671    0.000    1.261    0.706\n    depress          -0.094    0.085   -1.098    0.272   -0.094   -0.094\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.19.)    1.452    0.145    9.988    0.000    1.452    0.531\n   .item2   (.20.)    2.301    0.178   12.925    0.000    2.301    0.565\n   .item3   (.21.)    3.646    0.143   25.467    0.000    3.646    0.831\n   .item4   (.22.)    3.571    0.197   18.119    0.000    3.571    0.723\n   .item5   (.23.)    3.478    0.161   21.626    0.000    3.478    0.777\n   .item6   (.24.)    2.900    0.199   14.536    0.000    2.900    0.682\n   .item7             4.626    0.260   17.771    0.000    4.626    0.888\n   .item8   (.26.)    3.368    0.207   16.280    0.000    3.368    0.721\n   .item9   (.27.)    2.809    0.143   19.649    0.000    2.809    0.880\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.469\n    item2             0.435\n    item3             0.169\n    item4             0.277\n    item5             0.223\n    item6             0.318\n    item7             0.112\n    item8             0.279\n    item9             0.120\n\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n                       Df   AIC   BIC  Chisq Chisq diff Df diff Pr(>Chisq)\nfit.strict             75 27495 27647 114.06                              \nfit.structuralVariance 76 27494 27642 114.90     1.0095       1      0.315\n\n\nFactor Mean Invariance Model\n\n\nlavaan 0.6.13 ended normally after 54 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        56\n  Number of equality constraints                    25\n\n  Number of observations per group:                   \n    Female                                         375\n    Male                                           375\n  Number of missing patterns per group:               \n    Female                                           1\n    Male                                             1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               116.143     114.340\n  Degrees of freedom                                77          77\n  P-value (Chi-square)                           0.003       0.004\n  Scaling correction factor                                  1.016\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    Female                                      61.790      60.831\n    Male                                        54.353      53.509\n\nModel Test Baseline Model:\n\n  Test statistic                              1343.575    1218.364\n  Degrees of freedom                                72          72\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.103\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.969       0.967\n  Tucker-Lewis Index (TLI)                       0.971       0.970\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.970\n  Robust Tucker-Lewis Index (TLI)                            0.972\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -13715.514  -13715.514\n  Scaling correction factor                                  0.559\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -13657.442  -13657.442\n  Scaling correction factor                                  1.014\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               27493.027   27493.027\n  Bayesian (BIC)                             27636.250   27636.250\n  Sample-size adjusted Bayesian (SABIC)      27537.813   27537.813\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.037       0.036\n  90 Percent confidence interval - lower         0.022       0.021\n  90 Percent confidence interval - upper         0.050       0.049\n  P-value H_0: RMSEA <= 0.050                    0.950       0.961\n  P-value H_0: RMSEA >= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.036\n  90 Percent confidence interval - lower                     0.021\n  90 Percent confidence interval - upper                     0.050\n  P-value H_0: Robust RMSEA <= 0.050                         0.954\n  P-value H_0: Robust RMSEA >= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.050       0.050\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\n\nGroup 1 [Female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.135    0.068   16.637    0.000    1.135    0.686\n    item2   (.p2.)    1.336    0.075   17.802    0.000    1.336    0.661\n    item3   (.p3.)    0.860    0.077   11.228    0.000    0.860    0.411\n    item4   (.p4.)    1.168    0.083   14.063    0.000    1.168    0.526\n    item5   (.p5.)    1.001    0.076   13.194    0.000    1.001    0.473\n    item6   (.p6.)    1.161    0.077   15.096    0.000    1.161    0.563\n    item7   (.p7.)    0.766    0.086    8.914    0.000    0.766    0.372\n    item8   (.p8.)    1.144    0.082   13.946    0.000    1.144    0.529\n    item9   (.p9.)    0.622    0.069    9.001    0.000    0.622    0.348\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.485    0.159    3.047    0.002    0.485    0.266\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.176    0.060   69.282    0.000    4.176    2.525\n   .item2   (.11.)    3.702    0.074   50.291    0.000    3.702    1.833\n   .item3   (.12.)    1.845    0.077   24.121    0.000    1.845    0.881\n   .item4   (.13.)    3.473    0.081   42.797    0.000    3.473    1.563\n   .item5   (.14.)    2.245    0.077   29.048    0.000    2.245    1.061\n   .item6   (.15.)    3.808    0.075   50.564    0.000    3.808    1.846\n   .item7             3.842    0.104   37.048    0.000    3.842    1.866\n   .item8   (.17.)    3.556    0.079   45.035    0.000    3.556    1.644\n   .item9   (.18.)    1.232    0.065   18.878    0.000    1.232    0.689\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.19.)    1.447    0.145    9.949    0.000    1.447    0.529\n   .item2   (.20.)    2.295    0.178   12.893    0.000    2.295    0.563\n   .item3   (.21.)    3.649    0.143   25.557    0.000    3.649    0.831\n   .item4   (.22.)    3.576    0.197   18.172    0.000    3.576    0.724\n   .item5   (.23.)    3.478    0.161   21.617    0.000    3.478    0.776\n   .item6   (.24.)    2.906    0.199   14.596    0.000    2.906    0.683\n   .item7             3.654    0.271   13.478    0.000    3.654    0.862\n   .item8   (.26.)    3.368    0.207   16.275    0.000    3.368    0.720\n   .item9   (.27.)    2.807    0.143   19.666    0.000    2.807    0.879\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.471\n    item2             0.437\n    item3             0.169\n    item4             0.276\n    item5             0.224\n    item6             0.317\n    item7             0.138\n    item8             0.280\n    item9             0.121\n\n\nGroup 2 [Male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  depress =~                                                            \n    item1   (.p1.)    1.135    0.068   16.637    0.000    1.135    0.686\n    item2   (.p2.)    1.336    0.075   17.802    0.000    1.336    0.661\n    item3   (.p3.)    0.860    0.077   11.228    0.000    0.860    0.411\n    item4   (.p4.)    1.168    0.083   14.063    0.000    1.168    0.526\n    item5   (.p5.)    1.001    0.076   13.194    0.000    1.001    0.473\n    item6   (.p6.)    1.161    0.077   15.096    0.000    1.161    0.563\n    item7   (.p7.)    0.766    0.086    8.914    0.000    0.766    0.336\n    item8   (.p8.)    1.144    0.082   13.946    0.000    1.144    0.529\n    item9   (.p9.)    0.622    0.069    9.001    0.000    0.622    0.348\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .item1 ~~                                                              \n   .item2             0.829    0.152    5.448    0.000    0.829    0.455\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.10.)    4.176    0.060   69.282    0.000    4.176    2.525\n   .item2   (.11.)    3.702    0.074   50.291    0.000    3.702    1.833\n   .item3   (.12.)    1.845    0.077   24.121    0.000    1.845    0.881\n   .item4   (.13.)    3.473    0.081   42.797    0.000    3.473    1.563\n   .item5   (.14.)    2.245    0.077   29.048    0.000    2.245    1.061\n   .item6   (.15.)    3.808    0.075   50.564    0.000    3.808    1.846\n   .item7             3.448    0.116   29.819    0.000    3.448    1.510\n   .item8   (.17.)    3.556    0.079   45.035    0.000    3.556    1.644\n   .item9   (.18.)    1.232    0.065   18.878    0.000    1.232    0.689\n    depress           0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .item1   (.19.)    1.447    0.145    9.949    0.000    1.447    0.529\n   .item2   (.20.)    2.295    0.178   12.893    0.000    2.295    0.563\n   .item3   (.21.)    3.649    0.143   25.557    0.000    3.649    0.831\n   .item4   (.22.)    3.576    0.197   18.172    0.000    3.576    0.724\n   .item5   (.23.)    3.478    0.161   21.617    0.000    3.478    0.776\n   .item6   (.24.)    2.906    0.199   14.596    0.000    2.906    0.683\n   .item7             4.625    0.260   17.769    0.000    4.625    0.887\n   .item8   (.26.)    3.368    0.207   16.275    0.000    3.368    0.720\n   .item9   (.27.)    2.807    0.143   19.666    0.000    2.807    0.879\n    depress           1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    item1             0.471\n    item2             0.437\n    item3             0.169\n    item4             0.276\n    item5             0.224\n    item6             0.317\n    item7             0.113\n    item8             0.280\n    item9             0.121\n\n\nModel Comparision\n\n\n\nModel Fit Indices Table\n\n\n\n\n\n\n\n\n\n\n\n\ncfi\ntli\nrmsea\nrmsea.ci.lower\nrmsea.ci.upper\nrmsea.pvalue\nsrmr\n\n\n\nConfigural\n0.96\n0.95\n0.05\n0.03\n0.06\n0.52\n0.04\n\n\nstructuralVariance\n0.97\n0.97\n0.04\n0.02\n0.05\n0.95\n0.05\n\n\nstructuralMean\n0.97\n0.97\n0.04\n0.02\n0.05\n0.95\n0.05\n\n\n\n\n\n\nModel Comparision Table\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nAIC\nBIC\nChisq\nChisq diff\nDf diff\nPr(>Chisq)\n\n\n\nConfigural\n52\n27525.80\n27784.52\n98.91085\nNA\nNA\nNA\n\n\nstructuralVariance\n76\n27493.79\n27641.63\n114.90425\n16.993054\n24\n0.8489582\n\n\nstructuralMean\n77\n27493.03\n27636.25\n116.14270\n1.225188\n1\n0.2683450"
  },
  {
    "objectID": "posts/2021-07-06-health-care-data-analysis-with-apple-watch/index.en.html",
    "href": "posts/2021-07-06-health-care-data-analysis-with-apple-watch/index.en.html",
    "title": "Health Care Data Analysis with Apple Watch",
    "section": "",
    "text": "You can find more details about exporting data from How to Export Health Data form iPhone and How to Export, Parse and Explore Your Apple Health Data with Python."
  },
  {
    "objectID": "posts/2021-07-06-health-care-data-analysis-with-apple-watch/index.en.html#load-required-packages",
    "href": "posts/2021-07-06-health-care-data-analysis-with-apple-watch/index.en.html#load-required-packages",
    "title": "Health Care Data Analysis with Apple Watch",
    "section": "0. Load Required Packages",
    "text": "0. Load Required Packages\n\n\n\n\nrm(list = ls(all = TRUE))\n\nif(!require(XML)) install.packages(\"XML\")\nif(!require(tidyverse)) install.packages(\"tidyverse\")\nif(!require(lubridate)) install.packages(\"lubridate\")\nif(!require(scales)) install.packages(\"scales\")\nif(!require(ggthemes)) remotes::install_github(c(\"hadley/ggplot2\", \"jrnold/ggthemes\"))\nif(!require(ggridges)) remotes::install_github(\"wilkelab/ggridges\")\nif(!require(rpart)) install.packages(\"rpart\")\nif(!require(kableExtra)) install.packages(\"kableExtra\")"
  },
  {
    "objectID": "posts/2021-07-06-health-care-data-analysis-with-apple-watch/index.en.html#read-in-xml-data",
    "href": "posts/2021-07-06-health-care-data-analysis-with-apple-watch/index.en.html#read-in-xml-data",
    "title": "Health Care Data Analysis with Apple Watch",
    "section": "1. Read in XML data",
    "text": "1. Read in XML data\nThe .xml file could be downloaded and exported directly from iphone’s health app. To read in the XML file and transform it into data frame, XML R package will help.\n\nloc<-\"导出.xml\" # enter file path location of export.xml file here #\n\nxml <- xmlParse(loc)\n\nrc <-  data.frame(XML:::xmlAttrsToDataFrame(xml[\"//Record\"]), stringsAsFactors = F)\nsaveRDS(rc, \"export_health_care.rds\")\n\n\nrc <- readRDS(\"export_health_care.rds\")\n\n## Filter useful data\napple_watch <- rc %>% filter(grepl(\"JZ\",sourceName), unit == 'count/min', \n                             type == \"HKQuantityTypeIdentifierRestingHeartRate\")\n\n# Adjusting to Local Timezone\napple_watch_dt <- apple_watch %>%\n  mutate(cdt=as_datetime(creationDate, tz=\"US/Central\"),\n         stm=as_datetime(startDate, tz=\"US/Central\"),\n         etm=as_datetime(endDate, tz=\"US/Central\"),\n         dst=as.numeric(as.character(value))) \n\n# %>%\n#   group_by(creationDate) %>%\n#   mutate(TotalTime=cumsum(value)) %>% # cumulative distance covered #\n#   mutate(hr=hour(stm), min=minute(stm)) %>%\n#   mutate(elt=as.numeric(etm-mntm)) %>% # total elapsed time #\n#   mutate(dtm=as.numeric(etm-lag(etm))) %>%\n#   ungroup()\n\nhead(apple_watch_dt[,-1]) %>% \n  select(sourceName, unit, cdt, stm, etm, dst) %>% \n  kbl() %>% \n  kable_material_dark(full_width = F, html_font = \"Maven Pro\") |> \n  kable_styling(font_size = 10)\n\n\n\n\n sourceName \n    unit \n    cdt \n    stm \n    etm \n    dst \n  \n\n\n JZ’sApple Watch \n    count/min \n    2020-07-27 22:42:32 \n    2020-07-27 08:45:05 \n    2020-07-27 22:37:26 \n    60 \n  \n\n JZ’sApple Watch \n    count/min \n    2020-07-28 19:43:28 \n    2020-07-28 00:03:04 \n    2020-07-28 19:40:28 \n    59 \n  \n\n JZ’sApple Watch \n    count/min \n    2020-07-29 14:22:15 \n    2020-07-29 08:40:16 \n    2020-07-29 14:18:28 \n    54 \n  \n\n JZ’sApple Watch \n    count/min \n    2020-07-30 17:44:05 \n    2020-07-30 09:06:24 \n    2020-07-30 17:41:27 \n    54 \n  \n\n JZ’sApple Watch \n    count/min \n    2020-07-31 17:36:00 \n    2020-07-31 08:55:46 \n    2020-07-31 17:27:30 \n    52 \n  \n\n JZ’sApple Watch \n    count/min \n    2020-08-01 12:17:02 \n    2020-08-01 00:03:31 \n    2020-08-01 12:14:41 \n    60"
  },
  {
    "objectID": "posts/2021-07-06-health-care-data-analysis-with-apple-watch/index.en.html#other-materials",
    "href": "posts/2021-07-06-health-care-data-analysis-with-apple-watch/index.en.html#other-materials",
    "title": "Health Care Data Analysis with Apple Watch",
    "section": "Other materials",
    "text": "Other materials\nThere a decent blog illustrating how to handle with apple watch export file."
  },
  {
    "objectID": "posts/2019-02-22-Play-With-gganimate/2019-02-22-Play-With-gganimate.html",
    "href": "posts/2019-02-22-Play-With-gganimate/2019-02-22-Play-With-gganimate.html",
    "title": "Introduce gganimate for Psychometric",
    "section": "",
    "text": "A new R packge (gganimate ) provides some new features for animation in R. Its big advantage is it could make use of ggplot API and embeded into ggplot. Next, I will use a sample data to show the example. Then I will use some real educational data to explore a little bit what we can do in psychometric area."
  },
  {
    "objectID": "posts/2019-02-22-Play-With-gganimate/2019-02-22-Play-With-gganimate.html#load-the-packages-requried",
    "href": "posts/2019-02-22-Play-With-gganimate/2019-02-22-Play-With-gganimate.html#load-the-packages-requried",
    "title": "Introduce gganimate for Psychometric",
    "section": "1.0 Load the packages requried",
    "text": "1.0 Load the packages requried"
  },
  {
    "objectID": "posts/2019-02-22-Play-With-gganimate/2019-02-22-Play-With-gganimate.html#prepare-the-data",
    "href": "posts/2019-02-22-Play-With-gganimate/2019-02-22-Play-With-gganimate.html#prepare-the-data",
    "title": "Introduce gganimate for Psychometric",
    "section": "1.1 prepare the data",
    "text": "1.1 prepare the data\n\ndata(\"austres\")\ndt <- data.frame(x=as.matrix(austres), date=time(austres))\ndt$y <- rnorm(nrow(dt))\ndt$date  <- as.numeric(dt$date)\n\n\np <- ggplot(dt,\n            aes(y = y, x =x)) +\n  geom_line(alpha = 0.7) +\n  geom_point()\np\n\n\n\n\n\ntransition_reveal: gradually reveal the data\n\np + transition_reveal(date)\n\n\n\n\n\ndt$g <- rep( c(\"red\", \"green\", \"blue\"), length.out = nrow(dt))\n\n\np_bygroup <- ggplot(dt,\n            aes(y = y, x =x, col = g)) +\n  geom_line(alpha = 0.7) +\n  geom_point()\np_bygroup\n\n\n\n\n\np_bygroup + transition_reveal(date)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jihong Zhang",
    "section": "",
    "text": "Jihong Zhang is a postdoctoral fellow in the school of social science, the Chinese University of Hong Kong. He likes to play with advanced statistical modeling such as machine learning, Bayesian network etc. His doctoral training was about Educational Measurement and Statistics (EMS) program at University of Iowa, where he mainly focused on Bayesian latent variable modeling, Item response theory modeling, and other psychometric modeling. His research (currently) tries to help with other social science researchers understanding their data and correctly interpret, and to wisely use the powerful tools of statistics."
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "Jihong Zhang",
    "section": "Interests",
    "text": "Interests\n\nBayesian Psychometric Modeling\nMachine Learning and data mining in Education\nDiagnostic Classification Models"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jihong Zhang",
    "section": "Education",
    "text": "Education\n\nPh.D. | Educational Measurement & Statistics | 2019 - 2022\nM.S. | Educational Psychology | 2015 - 2019\nB.S. | Applied Psychology | 2009 - 2013"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Jihong Zhang",
    "section": "Recent posts",
    "text": "Recent posts\n\n\n\n\n\n\n\n\n\n\nMoving my website to Quarto\n\n\n\nJun 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Conversation between R and Python on Data Analysis and Machine Learning\n\n\n\nJun 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLatent Class Model: Batch Mplus using R on Mac\n\n\n\nJun 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDissertation Defence\n\n\n\nOct 23, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nNSF Grant on Bayesian Cognitive Diagnosis\n\n\n\nMay 21, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nWeb Scraping Academia Institute’s Grant Fundings using R\n\n\n\nMay 12, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nPower Analysis for Structural Equation Modeling\n\n\n\nApr 29, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[Workshop] Creating Academic Blog via R\n\n\n\nApr 24, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nHealth Care Data Analysis with Apple Watch\n\n\n\nJul 6, 2021\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n[Pre-print] A Model Comparison Approach to Posterior Predictive Model Checks in Bayesian Confirmatory Factor Analysis\n\n\n\nJan 31, 2021\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy Notes: gt package and format table\n\n\n\nMay 25, 2020\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nIntroduction to Latent Attribute Network Analysis\n\n\n\nOct 20, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nWhich Country own the most Liberty Nobel Prizes? France? Ireland?\n\n\n\nMay 20, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nMake a Game in R\n\n\n\nApr 19, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nIntroduce gganimate for Psychometric\n\n\n\nFeb 22, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nLasso Regression Example using glmnet package in R\n\n\n\nFeb 19, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisuliaztion of Item Information Curves In R\n\n\n\nJan 10, 2019\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n[Manual]Using Jags and R2jags in R\n\n\n\nSep 12, 2018\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nIntroduce Descrepancy Measures\n\n\n\nSep 11, 2018\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nHow to do Data Cleaning in R\n\n\n\nSep 4, 2018\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nMy New Shiny App Cut Score Consistency\n\n\n\nMar 10, 2018\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nLatent Profile Analysis using MCLUST (in R)\n\n\n\nNov 23, 2017\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nSimulation Study of Linking using mirt\n\n\n\nNov 16, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne Example of Measurement Invariance\n\n\n\nNov 12, 2017\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nHow to use Lavaan for Confirmatory Factor Analysis\n\n\n\nOct 19, 2017\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\nSee all"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jihong Zhang",
    "section": "Experience",
    "text": "Experience\n\nPostdoctoral Fellow\n\nThe Chinese University of Hong Kong\nDec 2022 - June 2023\n\nAssociate Researcher\n\nStanford Research Institute (SRI)\nJune 2021 - Jan 2022"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Jun 25, 2023\n\n\nJihong Zhang\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nblog\n\n\nR\n\n\nPyTorch\n\n\nDeep Learning\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2023\n\n\nJihong Zhang\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nblog\n\n\nLCM\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nJihong Zhang\n\n\n\n\n\n\n  \n\n\n\n\n\nTITLE: A novel method for model selection in Bayesian Diagnostic Classification Modeling\n\n\n\n\n\n\n\n\n\nOct 23, 2022\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData visualization using ggplot2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2022\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\nWeb Scrapping\n\n\n\n\nHow to use R for web scrapping\n\n\n\n\n\n\nMay 12, 2022\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShowcase current software used for power analysis of Structural Equation Modeling\n\n\n\n\nR\n\n\nrshiny\n\n\nwebpower\n\n\nlavaan\n\n\nblog\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nApr 29, 2022\n\n\nJihong Zhang\n\n\n\n\n\n\n  \n\n\n\n\n\nThis post reviews the procedure of creating Github Pages Website using distill package and Github Pages in a step-to-step way.\n\n\n\n\nR\n\n\nGithub\n\n\nRstudio\n\n\nWorkshop\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2022\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis tutorial illustrate how to use julia to conduct a gradient descent algorithm\n\n\n\n\njulia\n\n\nalgorithm\n\n\n\n\n\n\n\n\n\n\n\nAug 30, 2021\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\nR\n\n\nhealth\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2021\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nJul 4, 2021\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2021\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\nMay 25, 2020\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2019\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2019\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\nNetwork\n\n\nDCM\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2019\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2019\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvisualization\n\n\nblog\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2019\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2019\n\n\njihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2019\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nmanual\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2019\n\n\nJihong Zhang\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2019\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nManual\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2018\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2018\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\nR\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2018\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nApr 29, 2018\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShiny\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2018\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2018\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2017\n\n\nJihong Zhang\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2017\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2017\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nmirt\n\n\nlinking\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2017\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nNov 12, 2017\n\n\nJihong Zhang\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nSEM\n\n\nlavaan\n\n\n\n\n\n\n\n\n\n\n\nNov 12, 2017\n\n\nJihong Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nManual\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2017\n\n\nJihong\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2015\n\n\nJihong Zhang\n\n\n\n\n\n\nNo matching items"
  }
]