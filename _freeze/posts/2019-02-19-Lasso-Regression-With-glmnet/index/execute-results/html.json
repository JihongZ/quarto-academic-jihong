{
  "hash": "c2b52e4969c00cef5c78af948d097398",
  "result": {
    "markdown": "---\ntitle: Lasso Regression Example using glmnet package in R\nauthor: Jihong Zhang\ndate: '2019-02-19'\ncategories:\n  - R\n  - manual\ntags:\n  - Lasso\n  - glmnet\noutput: html_document\n---\n\n\n\n\nMore details please refer to the link below:\n(https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html#lin)\n\n\nThis post shows how to use `glmnet` package to fit lasso regression and how to visualize the output.\nThe description of data is shown in [here](http://myweb.uiowa.edu/pbreheny/data/whoari.html).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt <- readRDS(url(\"https://s3.amazonaws.com/pbreheny-data-sets/whoari.rds\"))\nattach(dt)\nfit <- glmnet(X, y)\n```\n:::\n\n\n## Visualize the coefficients\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n### Label the path\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit, label = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nThe summary table below shows from left to right the number of nonzero coefficients (DF), the percent (of null) deviance explained (%dev) and the value of $\\lambda$ (`Lambda`). \n\nWe can get the actual coefficients at a specific $\\lambda$ whin the range of sequence:\n\n::: {.cell}\n\n```{.r .cell-code}\ncoeffs <- coef(fit, s = 0.1) \ncoeffs.dt <- data.frame(name = coeffs@Dimnames[[1]][coeffs@i + 1], coefficient = coeffs@x) \n\n# reorder the variables in term of coefficients\ncoeffs.dt[order(coeffs.dt$coefficient, decreasing = T),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          name   coefficient\n1  (Intercept)  3.010501e+00\n7          hfa  4.634502e-01\n12         aro  2.139111e-01\n9          inc  1.298769e-01\n6       convul  9.284738e-02\n16         whz  9.018865e-02\n14         afe  8.749033e-02\n10         lcw  7.538421e-02\n15        absu  5.758727e-02\n13         qcr  2.952464e-02\n11         str  2.298848e-02\n3         temp  9.842032e-03\n5           rr  7.309241e-03\n8          hfe  4.870858e-03\n2         wght -3.138053e-05\n4          age -8.724823e-03\n```\n:::\n:::\n\n\nAlso, it can allow people to make predictions at specific $\\lambda$ with new input data:\n\n::: {.cell}\n\n```{.r .cell-code}\nnx = matrix(rnorm(nrow(dt$X)*ncol(dt$X)), nrow = nrow(dt$X), ncol = ncol(dt$X))\npred <- predict(fit, newx = nx, s = c(0.1, 0.05)) \nhead(pred, 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            s1         s2\n [1,] 3.465773  1.5135872\n [2,] 3.088525  1.3815177\n [3,] 3.587867  1.4431828\n [4,] 3.771435  1.5411323\n [5,] 3.595251  1.8061536\n [6,] 3.419286  1.3059683\n [7,] 3.195521  1.4421734\n [8,] 1.612829 -1.5908158\n [9,] 2.536198  0.1630636\n[10,] 3.244446  0.5152836\n[11,] 2.967109  1.5045971\n[12,] 2.723644  1.0691778\n[13,] 3.313086  0.9604486\n[14,] 3.126201  0.9068035\n[15,] 2.826930  0.1012069\n[16,] 3.241242  0.2246355\n[17,] 3.752990  2.2036950\n[18,] 2.811372  1.0081468\n[19,] 4.364803  3.1690336\n[20,] 4.497694  3.1981861\n```\n:::\n:::\n\n\n`cv.glmnet` is the function to do cross-validation here.\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- dt$X\ny <- dt$y\ncv.fit <- cv.glmnet(X, y)\n```\n:::\n\n\nPlotting the object gives the selected $\\lambda$ and corresponding Mean-Square Error.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(cv.fit)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\nWe can view the selected $\\lambda$'s and the corresponding coefficients, For example,\n\n::: {.cell}\n\n```{.r .cell-code}\ncv.fit$lambda.min\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02081079\n```\n:::\n\n```{.r .cell-code}\ncv.fit$lambda.1se\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1011946\n```\n:::\n:::\n\n\n`lambda.min` returns the value of $\\lambda$ that gives minimum mean cross-validated error. The other $\\lambda$ saved is `lambda.lse`, which gives the most regularized model such that error is within one standard error of the minimum. To use that, we only need to replace `lambda.min` with `lambda.lse` above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a function to transform coefficient of glmnet and cvglmnet to data.frame\ncoeff2dt <- function(fitobject, s) {\n  coeffs <- coef(fitobject, s) \n  coeffs.dt <- data.frame(name = coeffs@Dimnames[[1]][coeffs@i + 1], coefficient = coeffs@x) \n\n  # reorder the variables in term of coefficients\n  return(coeffs.dt[order(coeffs.dt$coefficient, decreasing = T),])\n}\n\ncoeff2dt(fitobject = cv.fit, s = \"lambda.min\") %>% head(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     name coefficient\n22    str  0.67960398\n37    whz  0.58664385\n12    hfa  0.53643828\n11 convul  0.39597719\n28    aro  0.33919548\n39 puskin  0.28612411\n14    fde  0.23064257\n41    oab  0.20502318\n30    afe  0.16702394\n18    inc  0.14657295\n13    hfe  0.12027053\n5    temp  0.08881899\n20    lcw  0.08607789\n38   smi2  0.06967305\n29    qcr  0.05343341\n9    omph  0.03806023\n19    sr1  0.03314876\n32    crs  0.03202430\n23    gru  0.02295646\n36    hyp  0.01462041\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoeffs.table <- coeff2dt(fitobject = cv.fit, s = \"lambda.min\")\nggplot(data = coeffs.table) +\n  geom_col(aes(x = name, y = coefficient, fill = {coefficient > 0})) +\n  xlab(label = \"\") +\n  ggtitle(expression(paste(\"Lasso Coefficients with \", lambda, \" = 0.0275\"))) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## Elastic net\nAs an example, we can set $\\alpha=0.2$\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- glmnet(X, y, alpha = 0.2, weights = c(rep(1, 716), rep(2, 100)), nlambda = 20)\n\nprint(fit2, digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:  glmnet(x = X, y = y, weights = c(rep(1, 716), rep(2, 100)), alpha = 0.2,      nlambda = 20) \n\n   Df  %Dev Lambda\n1   0  0.00 3.2500\n2   7 14.02 2.0000\n3  12 26.98 1.2300\n4  13 33.81 0.7590\n5  18 38.03 0.4670\n6  23 41.35 0.2880\n7  29 43.24 0.1770\n8  39 45.05 0.1090\n9  47 46.17 0.0672\n10 52 46.82 0.0414\n11 57 47.15 0.0255\n12 58 47.29 0.0157\n13 60 47.35 0.0097\n14 60 47.38 0.0060\n15 64 47.39 0.0037\n16 65 47.39 0.0023\n17 66 47.40 0.0014\n18 66 47.40 0.0009\n19 66 47.40 0.0005\n```\n:::\n:::\n\n\nAccording to the default internal settings, the computations stop if either the fractional change in deviance down the path is less than $10^{-5}$ or the fraction of explained deviance reaches 0.999.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit2, xvar = \"lambda\", label = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# plot against %deviance\nplot(fit2, xvar = \"dev\", label = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit2, newx = X[1:5, ], type = \"response\", s = 0.03)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           s1\n[1,] 3.170055\n[2,] 4.869413\n[3,] 4.255960\n[4,] 5.018313\n[5,] 2.945014\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}