{
  "hash": "5ef9f2182d8540dd5c83ae28973095cc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 06\"\nsubtitle: \"Generalized Measurement Models: An Introduction\"\nauthor: \"Jihong Zhang\"\ninstitute: \"Educational Statistics and Research Methods\"\ntitle-slide-attributes:\n  data-background-image: ../Images/title_image.png\n  data-background-size: contain\n  data-background-opacity: \"0.9\"\nexecute: \n  echo: true\nformat: \n  revealjs:\n    logo: ../Images/UA_Logo_Horizontal.png\n    incremental: true  # choose \"false \"if want to show all together\n    theme: [serif, ../pp.scss]\n    footer:  <https://jihongzhang.org/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553>\n    transition: slide\n    background-transition: fade\n    slide-number: true\n    chalkboard: true\n    number-sections: false\n    code-line-numbers: true\n    code-link: true\n    code-annotations: hover\n    code-copy: true\n    highlight-style: arrow\n    code-block-border-left: true\n    code-block-background: \"#b22222\"\n    mermaid:\n      theme: neutral\n#bibliography: references.bib\n---\n\n\n## Today's Lecture Objectives\n\n1.  Introduce measurement (psychometric) models in general\n\n2.  Describe the steps needed in a psychometric model analysis\n\n3.  Dive deeper into the observed-variables modeling aspect\n\n# Measurement Model in general\n\n## Measurement Model Analysis Steps\n\n\n```{mermaid}\n%%| echo: false\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nsubgraph \"Measurement Procedure\"\n  subgraph Modeling\n  direction LR\n  Start --> id1\n  id1([Specify model]) --> id2([\"`Specify scale identification \n  method for latent variables`\"])\n  id2 --> id3([Estimate model])\n  id3 --> id4{Adequate fit indices}\n  id4 -- No --> id1\n  end\n  Modeling -- Model fit acceptable --> one\n  subgraph one[\"Evaluation: Measurement Model with Auxiliary Components\"]\n    direction LR\n    id5([\"Score estimation \n    and secondary analyses with scores\"]) --> id6([Item evaluation])\n    id6 --> id7([Scale construction])\n    id7 --> id8([Equating])\n    id8 --> id9([Measure Invariance/Differential item functioning])\n    id9 --> End\n  end\nend\nstyle Start fill:#f9f,stroke:#333,stroke-width:5px\nstyle End fill:#bbf,stroke:#333,stroke-width:5px\n```\n\n\n## Components of a Measurement Model\n\nThere are two components of a measurement model\n\n**Theory (what we cannot see but assume its existence):**\n\n::: nonincremental\n-   Latent variable(s)\n\n-   Other effects as needed by a model\n\n    ::: nonincremental\n    -   Random effects (e.g., initial status and slopes in Latent Growth Model)\n\n    -   Testlet effects (e.g., a group-level variation among items)\n\n    -   Effects of observed variables (e.g., gender differences, DIF, Measurement Invariance)\n    :::\n:::\n\n**Data (what we can see and we assume generated by theory):**\n\n::: nonincremental\n-   Outcomes\n\n    -   An assumed distribution for each outcome\n\n    -   A key statistic of outcome for the model (e.g., mean, sd)\n\n    -   A link function\n:::\n\n------------------------------------------------------------------------\n\n### General form for measurement model (SEM, IRT):\n\n$$\nf(E(\\mathbf{Y}\\mid\\Theta)) = \\boldsymbol{\\mu} +\\Theta\\Lambda^T\n$$\n\nand\n\n$$\n\\Lambda_j = Q \\odot \\boldsymbol{\\lambda_j}\n$$\n\nAssume N as sample size, P as number of factors, J as number of items. Then,\n\n::: nonincremental\n-   $f()$: link function. CFA: identity link; IRT: logistic/probit link\n-   $E(\\mathbf{Y}\\mid\\Theta)$: Expected/Predicted values of outcomes\n-   $\\Theta$: latent factor scores matrix (N $\\times$ P)\n-   $\\Lambda$: A factor loading matrix (J $\\times$ P)\n    -   $\\Lambda_j$: $j$th row vector of factor loading matrix\n\n    -   $\\textbf{Q}$: Q-matrix represents the connections between items and latent variables\n\n    -   $\\boldsymbol{\\lambda}_j$: a vector of factor loading vectors for item $j$\n-   $\\mu$: item intercepts (J $\\times$ 1)\n:::\n\n------------------------------------------------------------------------\n\n### Example 1 with general form\n\n::: columns\n::: {.column width=\"70%\"}\nLet's consider a measurement model with only one latent variable and five items:\n\n\n```{mermaid}\n%%| echo: false\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart TD\n  id1((θ)) --> id2[\"Y1\"]\n  id1 --> id3[\"Y2\"]\n  id1 --> id4[\"Y3\"]\n  id1 --> id5[\"Y4\"]\n  id1 --> id6[\"Y5\"]\n```\n\n\nThe model shows:\n\n::: nonincremental\n-   One latent variable ($\\theta$)\n\n-   Five observed variables ($\\mathbf{Y} = \\{Y_1, Y_2, Y_3, Y_4, Y_5\\}$)\n:::\n:::\n\n::: {.column width=\"30%\"}\nThen,\n\n-   $\\Theta$ = $\\begin{bmatrix} \\theta_1, \\\\\\theta_2,\\\\ \\cdots,\\\\ \\theta_N \\end{bmatrix}$\n\n-   $\\Lambda^T$ = $\\begin{bmatrix}\\lambda_1, \\lambda_2, ..., \\lambda_5 \\end{bmatrix}$\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Example 2 with general form\n\n::: columns\n::: {.column width=\"70%\"}\nLet's consider a measurement model with only two latent variables and five items:\n\n\n```{mermaid}\n%%| echo: false\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart TD\n  theta1((θ1)) --> id2[\"Y1\"]\n  theta1 --> id3[\"Y2\"]\n  theta1 --> id4[\"Y3\"]\n  theta1 --> id5[\"Y4\"]\n  theta1 --> id6[\"Y5\"]\n  theta2((θ2)) --> id2[\"Y1\"]\n  theta2 --> id3[\"Y2\"]\n  theta2 --> id4[\"Y3\"]\n  theta2 --> id5[\"Y4\"]\n  theta2 --> id6[\"Y5\"]\n```\n\n\nThe model shows:\n\n::: nonincremental\n-   Two latent variables ($\\theta_1$, $\\theta_2$)\n\n-   Five observed variables ($\\mathbf{Y} = \\{Y_1, Y_2, Y_3, Y_4, Y_5\\}$)\n:::\n:::\n\n::: {.column width=\"30%\"}\nThen,\n\n-   $\\Theta$ = $\\begin{bmatrix} \\theta_{1,1}, \\theta_{1,2}\\\\\\theta_{2,1}, \\theta_{2,2}\\\\ \\cdots,\\cdots \\\\ \\theta_{N, 1}, \\theta_{N,2} \\end{bmatrix}$ $\\sim [0, \\Sigma]$\n\n-   $\\Lambda^T$ = $\\begin{bmatrix}\\lambda_{1,1}, \\lambda_{1,2}, ..., \\lambda_{1,5}\\\\\\lambda_{2,1}, \\lambda_{2,2}, ..., \\lambda_{2,5}\\end{bmatrix}$\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Example 3 with general form\n\n::: columns\n::: {.column width=\"70%\"}\nLet's consider a measurement model with only two latent variables and five items:\n\n\n```{mermaid}\n%%| echo: false\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart TD\n  theta1((θ1)) --> id2[\"Y1\"]\n  theta1 --> id3[\"Y2\"]\n  theta1 --> id4[\"Y3\"]\n  theta2((θ2)) --> id4[\"Y3\"]\n  theta2 --> id5[\"Y4\"]\n  theta2 --> id6[\"Y5\"]\n```\n\n\nThe model shows:\n\n::: nonincremental\n-   Two latent variables ($\\theta_1$, $\\theta_2$)\n\n-   Five observed variables ($\\mathbf{Y} = \\{Y_1, Y_2, Y_3, Y_4, Y_5\\}$)\n:::\n:::\n\n::: {.column width=\"30%\"}\nThen,\n\n-   $\\Theta$ = $\\begin{bmatrix} \\theta_{1,1}, \\theta_{1,2}\\\\\\theta_{2,1}, \\theta_{2,2}\\\\ \\cdots,\\cdots \\\\ \\theta_{N, 1}, \\theta_{N,2} \\end{bmatrix}$ $\\sim [0, \\Sigma]$\n\n-   $\\Lambda^T$ = $\\begin{bmatrix}\\lambda_{1,1}, \\lambda_{1,2}, \\lambda_{1,3}, 0,0\\\\ 0, 0, \\lambda_{2,3}, \\lambda_{2,4}, \\lambda_{2,5}\\end{bmatrix}$\n\n-   Note that we only limit our model to main-effect models. Interaction effects of factors introduce more complexity.\n\n-   It is difficulty to specify factor loadings with $0$s directly\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Item-specific form\n\nFor each item j:\n\n$$\n\\mathbf{Y_j} \\sim N(\\mu_j+ \\boldsymbol{\\lambda}_{j}Q_j\\Theta, \\psi_j)\n$$\n\n## Bayesian view: latent variables\n\nLatent variables in Bayesian are built by following specification:\n\n1.  What are their distributions? (normal distribution or others)\n\n    -   For example, $\\theta_i$ values for one person and $\\theta$ values for samples. Factor score $\\theta$ is a mixture distribution of distributions of each individual's factor score $\\theta_i$\n\n    -   But, in MLE/WSLMV, we do not estimate mean and sd of each individual's factor score for model to be converged\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nset.seed(12)\nN = 15\nndraws = 200\nFS = matrix(NA, nrow = N, ndraws)\nFS_p = rnorm(N)\nFS_p = FS_p[order(FS_p)]\nfor (i in 1:N) {\n  FS[i,] = rnorm(ndraws, mean = FS_p[i], sd = 1)\n}\nFS_plot <- as.data.frame(t(FS))\ncolnames(FS_plot) <- paste0(\"Person\", 1:N)\nFS_plot <- FS_plot |> pivot_longer(everything(), names_to = \"Person\", values_to = \"Factor Score\")\nFS_plot$Person <- factor(FS_plot$Person, levels = paste0(\"Person\", 1:N))\nggplot() +\n  geom_density(aes(x = `Factor Score`, fill = Person, col = Person ), alpha = .5, data = FS_plot)  +\n  geom_density(aes(x = FS_p))\n```\n\n::: {.cell-output-display}\n![](Lecture06_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n2.  Multidimensionality\n    -   How many factors to be measured?\n    -   If $\\geq$ 2 factors, we specify mean vectors and variance-covariance matrix\n    -   To link latent variables with observed variables, we need to create a indicator matrix of coefficient/effects of latent variable on items.\n        -   In diagnostic modeling and multidimensional IRT, we call it Q-matrix\n\n## Simulation Study 1\n\nThe model specification is a two-factor with each measured by 3 items. In total, there are 6 items with continuous responses. Sample size is 1000.\n\n![Model Specification](simulation_model1.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Data Simulation\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# One-factor model without cross-loadings\nlibrary(tidyverse)\nlibrary(cmdstanr)\nset.seed(1234)\nN <- 1000\nJ <- 6\n# parameters\npsi <- .3 # factor correlation\nsigma <- .1 # residual varaince\nFS <- mvtnorm::rmvnorm(N, mean = c(0, 0), \n                       sigma = matrix(c(1, psi, psi, 1), \n                                      2, 2, byrow = T))\nLambda <- matrix(\n  c(\n    0.7, 0,\n    0.5, 0,\n    0.3, 0,\n    0, 0.7,\n    0, 0.5,\n    0, 0.3\n  ), 6, 2,\n  byrow = T\n)\nmu <- matrix(rep(0.1, J), nrow = 1, byrow = T)\nresidual <- mvtnorm::rmvnorm(N, mean = rep(0, J), sigma = diag(sigma, J))\nY <- t(apply(FS %*% t(Lambda), 1, \\(x) x + mu)) + residual\nhead(Y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]        [,2]       [,3]       [,4]        [,5]       [,6]\n[1,] -1.0136367 -0.50699773 -0.2803124  0.5407292 -0.37811988 -0.2033511\n[2,]  0.0508203  0.62021463  0.1737470 -1.9893740 -1.23623703 -0.8609000\n[3,]  0.5446843  0.52674674 -0.1523788  0.8198787  0.53021452  0.3435667\n[4,] -0.2721033 -0.08877619  0.2124482 -0.5066111 -0.19928765  0.7955025\n[5,] -0.7291450 -0.15306919 -0.5626197 -0.5083901 -0.07438493 -0.9338468\n[6,] -0.5210657  0.50114831 -0.3317205 -1.0916717 -0.28489250 -0.4464051\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Strategies for Stan Code for Model 1: factor loadings\n\n::: nonincremental\n-   We will iterate over item response function across each item\n-   To benefit from the efficiency of vectorization, we specify a vector of factor loadings with length 6\n    -   $\\{\\lambda_1, \\lambda_2, \\cdots, \\lambda_6 \\}$\n\n    -   Optionally, a matrix with number of items by number of factor for $\\lambda$s can be specified like $\\lambda_{11}$ and $\\lambda_{62}$, that introduces flexibility but complexity\n-   We should have a location table telling `stan` the information about which factor each factor loading belong to\n    -   For example, $\\lambda_{1}$ belongs to factor 1 and $\\lambda_4$ belong to factor 2\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkableExtra::kable(as.data.frame(loc)) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Item </th>\n   <th style=\"text-align:right;\"> Theta </th>\n   <th style=\"text-align:right;\"> q </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Strategies for Stan Code for Model 1: prior distribution and hyperparameters\n\n::: columns\n::: {.column width=\"80%\"}\n::: incremental\n-   residual variances for items: $\\sigma \\sim \\text{exponential}(sigmaRate)$\n    -   sigmaRate is set to 1\n-   item intercepts: $\\mu \\sim \\text{MVN}(meanMu, covMu)$\n    -   meanMu is set to a vector of 0s with length 6\n\n    -   covMu is set to a diagonol matrix of 1000 with 6 $\\times$ 6\n-   factor scores: $\\Theta \\sim \\text{MVN}(meanTheta, corrTheta)$\n    -   meanTheta is set to a vector of 0s with length 2\n\n    -   $corrTheta \\sim lkj\\_corr(eta)$ and eta is set to 1\n\n    -   Optionally, $L \\sim lkj\\_corr\\_cholesky(eta)$ and corrTheta = LL'\n-   factor loadings: $\\Lambda \\sim \\text{MVN}(meanLambda, covLambda)$\n    -   meanLambda is set to a vector of 0s with length 6 (number of items)\n\n    -   covLambdais set to a matrix of $\\begin{pmatrix}1000, 0,\\cdots,0\\\\ \\cdots\\\\0, 0, \\cdots1000\\end{pmatrix}$\n:::\n:::\n\n::: {.column width=\"20%\"}\n**Question: what about factor correlation** $\\psi$? See [this blog](http://stla.github.io/stlapblog/posts/StanLKJprior.html) and [Stan's reference](https://mc-stan.org/docs/functions-reference/cholesky-lkj-correlation-distribution.html) for Choleskey decomposition\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Data Structure\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell filename='Lecture06.R'}\n\n```{.r .cell-code}\ndata_list <- list(\n  N = 1000, # number of subjects/observations\n  J = J, # number of items\n  K = 2, # number of latent variables,\n  Y = Y,\n  Q = Q,\n  # location of lambda\n  kk = loc[,2],\n  #hyperparameter\n  sigmaRate = .01,\n  meanMu = rep(0, J),\n  covMu = diag(1000, J),\n  meanTheta = rep(0, 2),\n  covTheta = matrix(c(1, 0.3, 0.3, 1), 2, 2, byrow = T),\n  meanLambda = rep(0, J),\n  covLambda = diag(1000, J)\n)\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell output.var='display' filename='simulation_loc.stan'}\n\n```{.stan .cell-code}\ndata {\n  int<lower=0> N; // number of observations\n  int<lower=0> J; // number of items\n  int<lower=0> K; // number of latent variables\n  matrix[N, J] Y; // item responses\n  array[J] int<lower=0> kk; // Index of theta\n  //hyperparameter\n  real<lower=0> sigmaRate; // rate parameters for residual variance components\n  vector[J] meanMu;\n  matrix[J, J] covMu;      // prior covariance matrix for coefficients\n  vector[K] meanTheta;     // prior mean vector for latent factors\n  matrix[K, K] covTheta;      // prior covariance matrix for latent factors\n  vector[J] meanLambda;    // prior mean vector for factor loadings\n  matrix[J, J] covLambda;      // prior covariance matrix for factor loadings\n}\n```\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n### MCMC Results with Stan\n\n::: columns\n::: {.column width=\"50%\"}\nBenchmark model using `lavaan`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lavaan\nlibrary(lavaan)\nmod <- \"\nF1 =~ I1 + I2 + I3\nF2 =~ I4 + I5 + I6\n\"\ndat <- as.data.frame(Y)\ncolnames(dat) <- paste0('I', 1:6)\nfit <- cfa(mod, data = dat, std.lv = TRUE)\nlavaan::parameterestimates(fit) |> filter(op == \"=~\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  lhs op rhs   est    se      z pvalue ci.lower ci.upper\n1  F1 =~  I1 0.724 0.021 34.229      0    0.682    0.765\n2  F1 =~  I2 0.521 0.017 31.478      0    0.489    0.554\n3  F1 =~  I3 0.321 0.013 25.484      0    0.296    0.345\n4  F2 =~  I4 0.666 0.020 33.504      0    0.627    0.705\n5  F2 =~  I5 0.487 0.016 30.775      0    0.456    0.518\n6  F2 =~  I6 0.306 0.013 24.022      0    0.281    0.331\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nModel 1 using `Stan`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_cfa_twofactor$summary(\"lambda\") |> select(variable,mean, median, sd, q5, q95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  variable   mean median     sd    q5   q95\n  <chr>     <dbl>  <dbl>  <dbl> <dbl> <dbl>\n1 lambda[1] 0.726  0.726 0.0211 0.691 0.761\n2 lambda[2] 0.522  0.522 0.0167 0.495 0.550\n3 lambda[3] 0.321  0.321 0.0129 0.300 0.342\n4 lambda[4] 0.668  0.668 0.0196 0.636 0.701\n5 lambda[5] 0.489  0.488 0.0156 0.463 0.514\n6 lambda[6] 0.307  0.307 0.0127 0.287 0.328\n```\n\n\n:::\n:::\n\n:::\n:::\n\n## Wrapping up\n\nThe three lectures using linear models was built to show nearly all parts needed in a Bayesian analysis\n\n-   MCMC specifications\n\n-   Prior specifications\n\n-   Assessing MCMC convergence\n\n-   Reporting MCMC results\n\n-   Determining if a model fits the data (absolute fit)\n\n-   Determining which model fits the data better (relative fit)\n\nAll of these topics will be with us when we start model complicated models in our future lecture.\n\n------------------------------------------------------------------------\n\n## Next Class\n\n1.  Generalized measurement models\n\n## Other materials\n\n1.  [Jonathan Templin's Website](https://jonathantemplin.github.io/Bayesian-Psychometric-Modeling-Course-Fall2022/lectures/lecture04b/04b_Modeling_Observed_Data)\n2.  [Winston-Salem's Website](https://medewitt.github.io/resources/stan_cfa.html)\n3.  [Rick Farouni's Website](https://rfarouni.github.io/assets/projects/BayesianFactorAnalysis/BayesianFactorAnalysis.html)\n\n## Reference\n",
    "supporting": [
      "Lecture06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}